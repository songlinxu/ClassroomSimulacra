uid,data_type,xy_type,school,student_id,course_name,group,test_type,question_id,slide_id,correctness,student_answer,correct_answer,question_content,course_content
9e92cb9f-2f45-4e5a-802d-a7110e13042b,test,past,elementary school,u1,6,group 1,post test,3,6,1,Full connections,B,"In an ART network, the interface layer activates the category layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
d792ab09-03a5-4703-b825-a0ba47faffbf,test,past,elementary school,u1,6,group 1,post test,4,3,1,Cluster,cluster/classification,Please write another name for “grouping” in unsupervised learning. <please input your answer>,"Grouping. An unsupervised learning neural network can group similar inputs. Grouping is also called clustering classification or categorization. E.g., grouping images of cats and images of dogs. The picture contains an example of grouping."
f32b3931-7dfa-4a30-9de1-ccd2969b6cc1,test,past,elementary school,u1,6,group 1,post test,1,6,1,Interface layer;Category layer,BC,"In an ART network, resonance is introduced to realize stable category formation. Resonance is established between which two layers? <please select the answer> A. Input layer B. Interface layer C. Category layer",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
c6442e41-39f3-4589-81fc-c7162eda3471,test,future,elementary school,u1,6,group 1,post test,8,10,1,True,T,"True or False: The clustering of K-means is that for each sample point, find the closest center point to it. <please select the best answer> True or False",The process of k-means clustering. Step 2: For each sample point find the center point closest to it and the points closest to the same center point is a class. Thus completing a clustering. Closest to green! Closest to red! Closest to blue! It contains a picture of an example of step 2.
83fa78d1-9943-4595-abf3-9316681345c9,test,future,elementary school,u1,6,group 1,post test,9,12,1,False,F,"True or False: After each clustering, there is no need to recalculate the center points. <please select the best answer> True or False",The process of k-means clustering. Step 4: for the sample points in each category calculate the center point of these sample points as the new center points. Continue to step 2. It contains a picture of an example of step 4.
09860b87-c959-42a6-bcb8-d80cb88e08cc,test,past,elementary school,u1,6,group 1,post test,2,6,1,One-to-one connections,A,"In an ART network, the input layer sends signals to the interface layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
3a81f82c-1c02-4bc4-9e3b-4c11a244c74d,test,future,elementary school,u1,6,group 1,post test,6,16,1,Smaller,B,The unsupervised ANN that can compress usually has a middle layer that has a much ____ number of neurons. <please select the best answer> A. larger B. smaller,Unsupervised ANNs that compress. These networks usually have a middle layer that has a much smaller number of neurons making an hourglass-structure. These networks usually compress the inputs and reproduce the inputs. It contains a picture of the structure of unsupervised ANNs and a picture of biscuits.
c60d8dc7-dbfe-4053-8858-896b98af5fd4,test,past,elementary school,u1,6,group 1,post test,5,4,1,Stephen Grossberg,B,Which person created Adaptive resonance theory1 (ART1)? <please select the best answer> A. David Hubel B. Stephen Grossberg C. Teuvo Kohonen,Adaptive resonance theory 1 (ART1). Adaptive resonance theory 1: an example of a neural network that performs grouping. Created by cognitive scientist Stephen Grossberg and mathematician Gail Carpenter. It contains a picture of Stephen.
c652409e-d438-4ffa-9811-11bfae5c0a38,test,future,elementary school,u1,6,group 1,post test,10,11,1,The categories of sample points before and after the clustering are the same.,The categories of sample points before and after the clustering are the same,What is the end condition of the K-means algorithm? <please input your answer>,"The process of k-means clustering. Step 3: determine whether the categories of the samples points before and after the clustering are the same. If they are the same, the algorithm terminates. Otherwise, enter step 4. In this example the sample points before and after are different then we enter step 4. It contains a picture of an example of step 3."
ef314710-2ef9-4191-b032-d92eddad7ae1,test,future,elementary school,u1,6,group 1,post test,7,9,1,False,F,True or False: The k center points are selected from sample points. <please select the best answer> True or False,"The process of k-means clustering. Step 1: select the number k of categories to be clustered and select k center points. E.g., k=3. The k center points are randomly selected on the plane. It contains a picture of an example of step 1."
666d2274-ae86-4dc1-a9e0-8b979b9e76bb,train,past,elementary school,u16,6,group 1,post test,3,6,1,Full connections,B,"In an ART network, the interface layer activates the category layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
7ca8dcfa-b71f-4f38-a14a-b2387b510303,train,past,elementary school,u16,6,group 1,post test,4,3,1,Cluster,cluster/classification,Please write another name for “grouping” in unsupervised learning. <please input your answer>,"Grouping. An unsupervised learning neural network can group similar inputs. Grouping is also called clustering classification or categorization. E.g., grouping images of cats and images of dogs. The picture contains an example of grouping."
6813f48e-7720-452c-a7d8-d95885cd3fc5,train,past,elementary school,u16,6,group 1,post test,1,6,1,Interface layer;Category layer,BC,"In an ART network, resonance is introduced to realize stable category formation. Resonance is established between which two layers? <please select the answer> A. Input layer B. Interface layer C. Category layer",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
ee2aa46f-19fa-4fde-80ed-f9e9611ee836,train,future,elementary school,u16,6,group 1,post test,8,10,1,True,T,"True or False: The clustering of K-means is that for each sample point, find the closest center point to it. <please select the best answer> True or False",The process of k-means clustering. Step 2: For each sample point find the center point closest to it and the points closest to the same center point is a class. Thus completing a clustering. Closest to green! Closest to red! Closest to blue! It contains a picture of an example of step 2.
9137b907-b4a9-4ca3-bd2a-07234c8cb484,train,future,elementary school,u16,6,group 1,post test,9,12,1,False,F,"True or False: After each clustering, there is no need to recalculate the center points. <please select the best answer> True or False",The process of k-means clustering. Step 4: for the sample points in each category calculate the center point of these sample points as the new center points. Continue to step 2. It contains a picture of an example of step 4.
df07f577-f7e7-44a8-808e-b705ad077ed6,train,past,elementary school,u16,6,group 1,post test,2,6,1,One-to-one connections,A,"In an ART network, the input layer sends signals to the interface layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
bb092721-65b4-4380-937c-6342777133ef,train,future,elementary school,u16,6,group 1,post test,6,16,1,Smaller,B,The unsupervised ANN that can compress usually has a middle layer that has a much ____ number of neurons. <please select the best answer> A. larger B. smaller,Unsupervised ANNs that compress. These networks usually have a middle layer that has a much smaller number of neurons making an hourglass-structure. These networks usually compress the inputs and reproduce the inputs. It contains a picture of the structure of unsupervised ANNs and a picture of biscuits.
8228f6fd-0fa7-4880-b159-f096e0fb192a,train,past,elementary school,u16,6,group 1,post test,5,4,1,Stephen Grossberg,B,Which person created Adaptive resonance theory1 (ART1)? <please select the best answer> A. David Hubel B. Stephen Grossberg C. Teuvo Kohonen,Adaptive resonance theory 1 (ART1). Adaptive resonance theory 1: an example of a neural network that performs grouping. Created by cognitive scientist Stephen Grossberg and mathematician Gail Carpenter. It contains a picture of Stephen.
08714269-967e-4195-8a75-8fc7ce7e9bec,train,future,elementary school,u16,6,group 1,post test,10,11,1, The categories of sample points before and after the clustering are the same.,The categories of sample points before and after the clustering are the same,What is the end condition of the K-means algorithm? <please input your answer>,"The process of k-means clustering. Step 3: determine whether the categories of the samples points before and after the clustering are the same. If they are the same, the algorithm terminates. Otherwise, enter step 4. In this example the sample points before and after are different then we enter step 4. It contains a picture of an example of step 3."
c1d5f7f0-c1f0-493e-a97b-cdc1b9493ceb,train,future,elementary school,u16,6,group 1,post test,7,9,1,False,F,True or False: The k center points are selected from sample points. <please select the best answer> True or False,"The process of k-means clustering. Step 1: select the number k of categories to be clustered and select k center points. E.g., k=3. The k center points are randomly selected on the plane. It contains a picture of an example of step 1."
ee6ffa99-7995-4a0a-99fb-c1f32bca5a06,train,past,elementary school,u4,6,group 1,post test,3,6,0,One-to-one connections,B,"In an ART network, the interface layer activates the category layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
2aa41fff-1821-419b-8aa4-44ec4a47e5dd,train,past,elementary school,u4,6,group 1,post test,4,3,1,cluster,cluster/classification,Please write another name for “grouping” in unsupervised learning. <please input your answer>,"Grouping. An unsupervised learning neural network can group similar inputs. Grouping is also called clustering classification or categorization. E.g., grouping images of cats and images of dogs. The picture contains an example of grouping."
f45df7e1-d8c0-45ac-a1cc-83b7fa88b605,train,past,elementary school,u4,6,group 1,post test,1,6,1,Interface layer;Category layer,BC,"In an ART network, resonance is introduced to realize stable category formation. Resonance is established between which two layers? <please select the answer> A. Input layer B. Interface layer C. Category layer",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
5dbc58f9-3818-4727-9f2b-a64c404645fb,train,future,elementary school,u4,6,group 1,post test,8,10,1,True,T,"True or False: The clustering of K-means is that for each sample point, find the closest center point to it. <please select the best answer> True or False",The process of k-means clustering. Step 2: For each sample point find the center point closest to it and the points closest to the same center point is a class. Thus completing a clustering. Closest to green! Closest to red! Closest to blue! It contains a picture of an example of step 2.
38b4796c-1730-4ae6-b9a3-b37bd3f46429,train,future,elementary school,u4,6,group 1,post test,9,12,1,False,F,"True or False: After each clustering, there is no need to recalculate the center points. <please select the best answer> True or False",The process of k-means clustering. Step 4: for the sample points in each category calculate the center point of these sample points as the new center points. Continue to step 2. It contains a picture of an example of step 4.
29b18261-b49c-4d78-bee8-546f2618c013,train,past,elementary school,u4,6,group 1,post test,2,6,1,One-to-one connections,A,"In an ART network, the input layer sends signals to the interface layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
8a7965fc-25b0-4c39-b8bc-afbb5296c307,train,future,elementary school,u4,6,group 1,post test,6,16,1,Smaller,B,The unsupervised ANN that can compress usually has a middle layer that has a much ____ number of neurons. <please select the best answer> A. larger B. smaller,Unsupervised ANNs that compress. These networks usually have a middle layer that has a much smaller number of neurons making an hourglass-structure. These networks usually compress the inputs and reproduce the inputs. It contains a picture of the structure of unsupervised ANNs and a picture of biscuits.
e1529aa3-12ef-432a-bcf6-de264754e992,train,past,elementary school,u4,6,group 1,post test,5,4,1,Stephen Grossberg,B,Which person created Adaptive resonance theory1 (ART1)? <please select the best answer> A. David Hubel B. Stephen Grossberg C. Teuvo Kohonen,Adaptive resonance theory 1 (ART1). Adaptive resonance theory 1: an example of a neural network that performs grouping. Created by cognitive scientist Stephen Grossberg and mathematician Gail Carpenter. It contains a picture of Stephen.
a4140d6f-e192-4cf9-937c-4aacd79729aa,train,future,elementary school,u4,6,group 1,post test,10,11,0,before and after the cluster,The categories of sample points before and after the clustering are the same,What is the end condition of the K-means algorithm? <please input your answer>,"The process of k-means clustering. Step 3: determine whether the categories of the samples points before and after the clustering are the same. If they are the same, the algorithm terminates. Otherwise, enter step 4. In this example the sample points before and after are different then we enter step 4. It contains a picture of an example of step 3."
2dc82cfc-b84d-4219-8341-50d790c25a4d,train,future,elementary school,u4,6,group 1,post test,7,9,1,False,F,True or False: The k center points are selected from sample points. <please select the best answer> True or False,"The process of k-means clustering. Step 1: select the number k of categories to be clustered and select k center points. E.g., k=3. The k center points are randomly selected on the plane. It contains a picture of an example of step 1."
3a9d432b-3b90-41ba-9ba5-7304a195f084,test,past,elementary school,u5,6,group 2,post test,3,6,1,Full connections,B,"In an ART network, the interface layer activates the category layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
21bae0cc-f09d-43c1-9210-e00727c8b5e5,test,past,elementary school,u5,6,group 2,post test,4,3,1,clustering,cluster/classification,Please write another name for “grouping” in unsupervised learning. <please input your answer>,"Grouping. An unsupervised learning neural network can group similar inputs. Grouping is also called clustering classification or categorization. E.g., grouping images of cats and images of dogs. The picture contains an example of grouping."
d0df2b06-4f3d-4eeb-8de6-90b1861e2458,test,past,elementary school,u5,6,group 2,post test,1,6,0,Input layer;Interface layer,BC,"In an ART network, resonance is introduced to realize stable category formation. Resonance is established between which two layers? <please select the answer> A. Input layer B. Interface layer C. Category layer",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
1cb75f8f-4acd-45af-bff1-a96df17d66aa,test,future,elementary school,u5,6,group 2,post test,8,10,1,True,T,"True or False: The clustering of K-means is that for each sample point, find the closest center point to it. <please select the best answer> True or False",The process of k-means clustering. Step 2: For each sample point find the center point closest to it and the points closest to the same center point is a class. Thus completing a clustering. Closest to green! Closest to red! Closest to blue! It contains a picture of an example of step 2.
8e510ccf-dc30-4ead-9e25-4c5eeda1d8f1,test,future,elementary school,u5,6,group 2,post test,9,12,0,True,F,"True or False: After each clustering, there is no need to recalculate the center points. <please select the best answer> True or False",The process of k-means clustering. Step 4: for the sample points in each category calculate the center point of these sample points as the new center points. Continue to step 2. It contains a picture of an example of step 4.
eded5b9a-193a-4be1-89c9-4868ae54ce0b,test,past,elementary school,u5,6,group 2,post test,2,6,1,One-to-one connections,A,"In an ART network, the input layer sends signals to the interface layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
0803500a-3565-4922-bd68-d938ee098d06,test,future,elementary school,u5,6,group 2,post test,6,16,0,Larger,B,The unsupervised ANN that can compress usually has a middle layer that has a much ____ number of neurons. <please select the best answer> A. larger B. smaller,Unsupervised ANNs that compress. These networks usually have a middle layer that has a much smaller number of neurons making an hourglass-structure. These networks usually compress the inputs and reproduce the inputs. It contains a picture of the structure of unsupervised ANNs and a picture of biscuits.
c6885d8c-8228-4148-8fd8-4b2e6292d5fc,test,past,elementary school,u5,6,group 2,post test,5,4,1,Stephen Grossberg,B,Which person created Adaptive resonance theory1 (ART1)? <please select the best answer> A. David Hubel B. Stephen Grossberg C. Teuvo Kohonen,Adaptive resonance theory 1 (ART1). Adaptive resonance theory 1: an example of a neural network that performs grouping. Created by cognitive scientist Stephen Grossberg and mathematician Gail Carpenter. It contains a picture of Stephen.
b46a88b6-e621-4086-a7d2-e11c8f2b38f1,test,future,elementary school,u5,6,group 2,post test,10,11,0,,The categories of sample points before and after the clustering are the same,What is the end condition of the K-means algorithm? <please input your answer>,"The process of k-means clustering. Step 3: determine whether the categories of the samples points before and after the clustering are the same. If they are the same, the algorithm terminates. Otherwise, enter step 4. In this example the sample points before and after are different then we enter step 4. It contains a picture of an example of step 3."
f94cadfb-2de3-4f50-9f1c-cee8360246a8,test,future,elementary school,u5,6,group 2,post test,7,9,1,False,F,True or False: The k center points are selected from sample points. <please select the best answer> True or False,"The process of k-means clustering. Step 1: select the number k of categories to be clustered and select k center points. E.g., k=3. The k center points are randomly selected on the plane. It contains a picture of an example of step 1."
25765456-ec15-4b1b-bbca-10e0603bb796,train,past,elementary school,u7,6,group 2,post test,3,6,1,Full connections,B,"In an ART network, the interface layer activates the category layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
28aa1dc2-63ff-4f3b-bbe5-74a93024e2e1,train,past,elementary school,u7,6,group 2,post test,4,3,1,Cluster,cluster/classification,Please write another name for “grouping” in unsupervised learning. <please input your answer>,"Grouping. An unsupervised learning neural network can group similar inputs. Grouping is also called clustering classification or categorization. E.g., grouping images of cats and images of dogs. The picture contains an example of grouping."
12da4490-83de-4e29-8681-413508da0c63,train,past,elementary school,u7,6,group 2,post test,1,6,1,Interface layer;Category layer,BC,"In an ART network, resonance is introduced to realize stable category formation. Resonance is established between which two layers? <please select the answer> A. Input layer B. Interface layer C. Category layer",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
cfb44963-552b-4cc1-98aa-f229273f21a5,train,future,elementary school,u7,6,group 2,post test,8,10,1,True,T,"True or False: The clustering of K-means is that for each sample point, find the closest center point to it. <please select the best answer> True or False",The process of k-means clustering. Step 2: For each sample point find the center point closest to it and the points closest to the same center point is a class. Thus completing a clustering. Closest to green! Closest to red! Closest to blue! It contains a picture of an example of step 2.
8d98cbb1-67aa-49c8-9582-896eea487c06,train,future,elementary school,u7,6,group 2,post test,9,12,1,False,F,"True or False: After each clustering, there is no need to recalculate the center points. <please select the best answer> True or False",The process of k-means clustering. Step 4: for the sample points in each category calculate the center point of these sample points as the new center points. Continue to step 2. It contains a picture of an example of step 4.
22c12ee6-eb71-44c8-a516-200772577160,train,past,elementary school,u7,6,group 2,post test,2,6,1,One-to-one connections,A,"In an ART network, the input layer sends signals to the interface layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
d72ef958-fc3e-4cc5-b600-fcc62ae96714,train,future,elementary school,u7,6,group 2,post test,6,16,1,Smaller,B,The unsupervised ANN that can compress usually has a middle layer that has a much ____ number of neurons. <please select the best answer> A. larger B. smaller,Unsupervised ANNs that compress. These networks usually have a middle layer that has a much smaller number of neurons making an hourglass-structure. These networks usually compress the inputs and reproduce the inputs. It contains a picture of the structure of unsupervised ANNs and a picture of biscuits.
16b551ae-174e-40dc-82d1-e5ca4841e999,train,past,elementary school,u7,6,group 2,post test,5,4,0,David Hubel,B,Which person created Adaptive resonance theory1 (ART1)? <please select the best answer> A. David Hubel B. Stephen Grossberg C. Teuvo Kohonen,Adaptive resonance theory 1 (ART1). Adaptive resonance theory 1: an example of a neural network that performs grouping. Created by cognitive scientist Stephen Grossberg and mathematician Gail Carpenter. It contains a picture of Stephen.
8003f97a-c7fa-464f-b7cc-2e274365705e,train,future,elementary school,u7,6,group 2,post test,10,11,0,The,The categories of sample points before and after the clustering are the same,What is the end condition of the K-means algorithm? <please input your answer>,"The process of k-means clustering. Step 3: determine whether the categories of the samples points before and after the clustering are the same. If they are the same, the algorithm terminates. Otherwise, enter step 4. In this example the sample points before and after are different then we enter step 4. It contains a picture of an example of step 3."
c80cd914-375a-4956-9840-6259a5cf1d43,train,future,elementary school,u7,6,group 2,post test,7,9,1,False,F,True or False: The k center points are selected from sample points. <please select the best answer> True or False,"The process of k-means clustering. Step 1: select the number k of categories to be clustered and select k center points. E.g., k=3. The k center points are randomly selected on the plane. It contains a picture of an example of step 1."
777685e8-91e2-49dd-84dd-7365c61d708f,test,past,elementary school,u6,6,group 2,post test,3,6,1,Full connections,B,"In an ART network, the interface layer activates the category layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
f4d1770d-3b24-4a3c-b3e7-469adc8a19da,test,past,elementary school,u6,6,group 2,post test,4,3,1,clustering,cluster/classification,Please write another name for “grouping” in unsupervised learning. <please input your answer>,"Grouping. An unsupervised learning neural network can group similar inputs. Grouping is also called clustering classification or categorization. E.g., grouping images of cats and images of dogs. The picture contains an example of grouping."
6223dda9-a181-4c3f-9a69-5afcc33c47f1,test,past,elementary school,u6,6,group 2,post test,1,6,1,Interface layer;Category layer,BC,"In an ART network, resonance is introduced to realize stable category formation. Resonance is established between which two layers? <please select the answer> A. Input layer B. Interface layer C. Category layer",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
65d8fa9a-7bc5-4962-94cc-e81fc539aabd,test,future,elementary school,u6,6,group 2,post test,8,10,1,True,T,"True or False: The clustering of K-means is that for each sample point, find the closest center point to it. <please select the best answer> True or False",The process of k-means clustering. Step 2: For each sample point find the center point closest to it and the points closest to the same center point is a class. Thus completing a clustering. Closest to green! Closest to red! Closest to blue! It contains a picture of an example of step 2.
c760115a-84d8-46f1-b05e-313dadda2f82,test,future,elementary school,u6,6,group 2,post test,9,12,0,True,F,"True or False: After each clustering, there is no need to recalculate the center points. <please select the best answer> True or False",The process of k-means clustering. Step 4: for the sample points in each category calculate the center point of these sample points as the new center points. Continue to step 2. It contains a picture of an example of step 4.
b3b09933-092f-4b99-8ff2-f702f9e092fb,test,past,elementary school,u6,6,group 2,post test,2,6,1,One-to-one connections,A,"In an ART network, the input layer sends signals to the interface layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
9b6a1960-ba1f-4b8b-bf27-d6e9a6eea9bc,test,future,elementary school,u6,6,group 2,post test,6,16,1,Smaller,B,The unsupervised ANN that can compress usually has a middle layer that has a much ____ number of neurons. <please select the best answer> A. larger B. smaller,Unsupervised ANNs that compress. These networks usually have a middle layer that has a much smaller number of neurons making an hourglass-structure. These networks usually compress the inputs and reproduce the inputs. It contains a picture of the structure of unsupervised ANNs and a picture of biscuits.
7860bc92-f314-4534-81d8-b6a2d3397cc4,test,past,elementary school,u6,6,group 2,post test,5,4,1,Stephen Grossberg,B,Which person created Adaptive resonance theory1 (ART1)? <please select the best answer> A. David Hubel B. Stephen Grossberg C. Teuvo Kohonen,Adaptive resonance theory 1 (ART1). Adaptive resonance theory 1: an example of a neural network that performs grouping. Created by cognitive scientist Stephen Grossberg and mathematician Gail Carpenter. It contains a picture of Stephen.
fe1e0728-c8bd-4c6e-b57d-716e2567a0ca,test,future,elementary school,u6,6,group 2,post test,10,11,0,,The categories of sample points before and after the clustering are the same,What is the end condition of the K-means algorithm? <please input your answer>,"The process of k-means clustering. Step 3: determine whether the categories of the samples points before and after the clustering are the same. If they are the same, the algorithm terminates. Otherwise, enter step 4. In this example the sample points before and after are different then we enter step 4. It contains a picture of an example of step 3."
f851df6e-5c5e-4b56-80d9-c51a082e73be,test,future,elementary school,u6,6,group 2,post test,7,9,0,True,F,True or False: The k center points are selected from sample points. <please select the best answer> True or False,"The process of k-means clustering. Step 1: select the number k of categories to be clustered and select k center points. E.g., k=3. The k center points are randomly selected on the plane. It contains a picture of an example of step 1."
7262f57f-592f-459b-9fb1-40b1f004d8f5,train,past,elementary school,u9,6,group 3,post test,3,6,1,Full connections,B,"In an ART network, the interface layer activates the category layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
a40616e0-87b7-4f1c-9e32-8ba6c5abf848,train,past,elementary school,u9,6,group 3,post test,4,3,0,?,cluster/classification,Please write another name for “grouping” in unsupervised learning. <please input your answer>,"Grouping. An unsupervised learning neural network can group similar inputs. Grouping is also called clustering classification or categorization. E.g., grouping images of cats and images of dogs. The picture contains an example of grouping."
7730c0ee-8f42-4781-93d7-01958920c6b7,train,past,elementary school,u9,6,group 3,post test,1,6,1,Interface layer;Category layer,BC,"In an ART network, resonance is introduced to realize stable category formation. Resonance is established between which two layers? <please select the answer> A. Input layer B. Interface layer C. Category layer",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
fb2b870a-c990-4d86-9a01-7c46b35cc99b,train,future,elementary school,u9,6,group 3,post test,8,10,1,True,T,"True or False: The clustering of K-means is that for each sample point, find the closest center point to it. <please select the best answer> True or False",The process of k-means clustering. Step 2: For each sample point find the center point closest to it and the points closest to the same center point is a class. Thus completing a clustering. Closest to green! Closest to red! Closest to blue! It contains a picture of an example of step 2.
069328ea-e1a2-48bf-b503-7abb2aa83591,train,future,elementary school,u9,6,group 3,post test,9,12,1,False,F,"True or False: After each clustering, there is no need to recalculate the center points. <please select the best answer> True or False",The process of k-means clustering. Step 4: for the sample points in each category calculate the center point of these sample points as the new center points. Continue to step 2. It contains a picture of an example of step 4.
ecc7ce0e-5399-41bb-a421-a6e2a4cb5c21,train,past,elementary school,u9,6,group 3,post test,2,6,0,Full connections,A,"In an ART network, the input layer sends signals to the interface layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
450ac97e-d8b7-43be-b67a-035ed5401304,train,future,elementary school,u9,6,group 3,post test,6,16,1,Smaller,B,The unsupervised ANN that can compress usually has a middle layer that has a much ____ number of neurons. <please select the best answer> A. larger B. smaller,Unsupervised ANNs that compress. These networks usually have a middle layer that has a much smaller number of neurons making an hourglass-structure. These networks usually compress the inputs and reproduce the inputs. It contains a picture of the structure of unsupervised ANNs and a picture of biscuits.
7e73066c-3eb9-4389-a706-87bcc38dfb59,train,past,elementary school,u9,6,group 3,post test,5,4,1,Stephen Grossberg,B,Which person created Adaptive resonance theory1 (ART1)? <please select the best answer> A. David Hubel B. Stephen Grossberg C. Teuvo Kohonen,Adaptive resonance theory 1 (ART1). Adaptive resonance theory 1: an example of a neural network that performs grouping. Created by cognitive scientist Stephen Grossberg and mathematician Gail Carpenter. It contains a picture of Stephen.
a93069af-4658-4091-9fad-ebfcc21146a8,train,future,elementary school,u9,6,group 3,post test,10,11,0,?,The categories of sample points before and after the clustering are the same,What is the end condition of the K-means algorithm? <please input your answer>,"The process of k-means clustering. Step 3: determine whether the categories of the samples points before and after the clustering are the same. If they are the same, the algorithm terminates. Otherwise, enter step 4. In this example the sample points before and after are different then we enter step 4. It contains a picture of an example of step 3."
b1acd063-d2df-48e0-bc07-fd8e1dcb8cad,train,future,elementary school,u9,6,group 3,post test,7,9,0,True,F,True or False: The k center points are selected from sample points. <please select the best answer> True or False,"The process of k-means clustering. Step 1: select the number k of categories to be clustered and select k center points. E.g., k=3. The k center points are randomly selected on the plane. It contains a picture of an example of step 1."
b3183f70-5216-4a08-ad00-e595486446e9,train,past,elementary school,u17,6,group 3,post test,3,6,1,Full connections,B,"In an ART network, the interface layer activates the category layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
75f4b58c-9873-4bd6-8219-003d7f65e6b5,train,past,elementary school,u17,6,group 3,post test,4,3,1,Clustering,cluster/classification,Please write another name for “grouping” in unsupervised learning. <please input your answer>,"Grouping. An unsupervised learning neural network can group similar inputs. Grouping is also called clustering classification or categorization. E.g., grouping images of cats and images of dogs. The picture contains an example of grouping."
3032611e-6795-4d11-ac47-84fe60af14c1,train,past,elementary school,u17,6,group 3,post test,1,6,1,Interface layer;Category layer,BC,"In an ART network, resonance is introduced to realize stable category formation. Resonance is established between which two layers? <please select the answer> A. Input layer B. Interface layer C. Category layer",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
63d55d54-a382-4f47-b40c-84fb805008e0,train,future,elementary school,u17,6,group 3,post test,8,10,1,True,T,"True or False: The clustering of K-means is that for each sample point, find the closest center point to it. <please select the best answer> True or False",The process of k-means clustering. Step 2: For each sample point find the center point closest to it and the points closest to the same center point is a class. Thus completing a clustering. Closest to green! Closest to red! Closest to blue! It contains a picture of an example of step 2.
8c392369-9c14-485c-80d0-fc2dbe25882a,train,future,elementary school,u17,6,group 3,post test,9,12,1,False,F,"True or False: After each clustering, there is no need to recalculate the center points. <please select the best answer> True or False",The process of k-means clustering. Step 4: for the sample points in each category calculate the center point of these sample points as the new center points. Continue to step 2. It contains a picture of an example of step 4.
badbc9f7-8887-46dd-8cf4-c11d57320115,train,past,elementary school,u17,6,group 3,post test,2,6,1,One-to-one connections,A,"In an ART network, the input layer sends signals to the interface layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
476f1894-6234-4a8f-a992-153f16d008ed,train,future,elementary school,u17,6,group 3,post test,6,16,1,Smaller,B,The unsupervised ANN that can compress usually has a middle layer that has a much ____ number of neurons. <please select the best answer> A. larger B. smaller,Unsupervised ANNs that compress. These networks usually have a middle layer that has a much smaller number of neurons making an hourglass-structure. These networks usually compress the inputs and reproduce the inputs. It contains a picture of the structure of unsupervised ANNs and a picture of biscuits.
bc4f45e8-dcae-43c3-8b69-88eb74a32006,train,past,elementary school,u17,6,group 3,post test,5,4,1,Stephen Grossberg,B,Which person created Adaptive resonance theory1 (ART1)? <please select the best answer> A. David Hubel B. Stephen Grossberg C. Teuvo Kohonen,Adaptive resonance theory 1 (ART1). Adaptive resonance theory 1: an example of a neural network that performs grouping. Created by cognitive scientist Stephen Grossberg and mathematician Gail Carpenter. It contains a picture of Stephen.
0b00979d-7c45-4d7e-ae75-9b5a7c34be72,train,future,elementary school,u17,6,group 3,post test,10,11,0, The categories of sample points are the same in the beginning and end,The categories of sample points before and after the clustering are the same,What is the end condition of the K-means algorithm? <please input your answer>,"The process of k-means clustering. Step 3: determine whether the categories of the samples points before and after the clustering are the same. If they are the same, the algorithm terminates. Otherwise, enter step 4. In this example the sample points before and after are different then we enter step 4. It contains a picture of an example of step 3."
60eb9ac7-db86-4c36-ab26-7de6f40d5cd6,train,future,elementary school,u17,6,group 3,post test,7,9,1,False,F,True or False: The k center points are selected from sample points. <please select the best answer> True or False,"The process of k-means clustering. Step 1: select the number k of categories to be clustered and select k center points. E.g., k=3. The k center points are randomly selected on the plane. It contains a picture of an example of step 1."
4768224d-ab41-43c9-be6d-b78d47691a81,test,past,elementary school,u10,6,group 3,post test,3,6,1,Full connections,B,"In an ART network, the interface layer activates the category layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
f9542bb8-5399-4034-906d-92414e8ffad3,test,past,elementary school,u10,6,group 3,post test,4,3,0,compreesing,cluster/classification,Please write another name for “grouping” in unsupervised learning. <please input your answer>,"Grouping. An unsupervised learning neural network can group similar inputs. Grouping is also called clustering classification or categorization. E.g., grouping images of cats and images of dogs. The picture contains an example of grouping."
c6490a3c-6701-4f99-9f05-f68bc46dd55d,test,past,elementary school,u10,6,group 3,post test,1,6,0,Input layer;Interface layer,BC,"In an ART network, resonance is introduced to realize stable category formation. Resonance is established between which two layers? <please select the answer> A. Input layer B. Interface layer C. Category layer",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
2cf0f40a-ad5c-42aa-b3b0-40487eeeea23,test,future,elementary school,u10,6,group 3,post test,8,10,1,True,T,"True or False: The clustering of K-means is that for each sample point, find the closest center point to it. <please select the best answer> True or False",The process of k-means clustering. Step 2: For each sample point find the center point closest to it and the points closest to the same center point is a class. Thus completing a clustering. Closest to green! Closest to red! Closest to blue! It contains a picture of an example of step 2.
54e93178-2c0c-4a26-9b5f-b0cd65db21c5,test,future,elementary school,u10,6,group 3,post test,9,12,1,False,F,"True or False: After each clustering, there is no need to recalculate the center points. <please select the best answer> True or False",The process of k-means clustering. Step 4: for the sample points in each category calculate the center point of these sample points as the new center points. Continue to step 2. It contains a picture of an example of step 4.
fb9bc870-8b9c-45cd-a008-65ea69396aa4,test,past,elementary school,u10,6,group 3,post test,2,6,1,One-to-one connections,A,"In an ART network, the input layer sends signals to the interface layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
129a2bea-7b1f-462e-8919-887b223ded3c,test,future,elementary school,u10,6,group 3,post test,6,16,0,Larger,B,The unsupervised ANN that can compress usually has a middle layer that has a much ____ number of neurons. <please select the best answer> A. larger B. smaller,Unsupervised ANNs that compress. These networks usually have a middle layer that has a much smaller number of neurons making an hourglass-structure. These networks usually compress the inputs and reproduce the inputs. It contains a picture of the structure of unsupervised ANNs and a picture of biscuits.
8214768b-39b0-4aa8-a76a-9f3e226ea78e,test,past,elementary school,u10,6,group 3,post test,5,4,1,Stephen Grossberg,B,Which person created Adaptive resonance theory1 (ART1)? <please select the best answer> A. David Hubel B. Stephen Grossberg C. Teuvo Kohonen,Adaptive resonance theory 1 (ART1). Adaptive resonance theory 1: an example of a neural network that performs grouping. Created by cognitive scientist Stephen Grossberg and mathematician Gail Carpenter. It contains a picture of Stephen.
fa731359-d1ae-4592-b579-40a96854f5e0,test,future,elementary school,u10,6,group 3,post test,10,11,0,compress,The categories of sample points before and after the clustering are the same,What is the end condition of the K-means algorithm? <please input your answer>,"The process of k-means clustering. Step 3: determine whether the categories of the samples points before and after the clustering are the same. If they are the same, the algorithm terminates. Otherwise, enter step 4. In this example the sample points before and after are different then we enter step 4. It contains a picture of an example of step 3."
9fe89cbf-da9e-45bc-b64c-2f9c695ac5ba,test,future,elementary school,u10,6,group 3,post test,7,9,0,True,F,True or False: The k center points are selected from sample points. <please select the best answer> True or False,"The process of k-means clustering. Step 1: select the number k of categories to be clustered and select k center points. E.g., k=3. The k center points are randomly selected on the plane. It contains a picture of an example of step 1."
95f316b0-3eea-4fb4-a0b8-88ccb268fa30,test,past,elementary school,u11,6,group 3,post test,3,6,1,Full connections,B,"In an ART network, the interface layer activates the category layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
09a67939-7168-4983-a238-95f8d7b5c35c,test,past,elementary school,u11,6,group 3,post test,4,3,1,Cluster,cluster/classification,Please write another name for “grouping” in unsupervised learning. <please input your answer>,"Grouping. An unsupervised learning neural network can group similar inputs. Grouping is also called clustering classification or categorization. E.g., grouping images of cats and images of dogs. The picture contains an example of grouping."
d2d5d030-af5d-45fb-9f68-a1876e4042f9,test,past,elementary school,u11,6,group 3,post test,1,6,0,Input layer;Category layer,BC,"In an ART network, resonance is introduced to realize stable category formation. Resonance is established between which two layers? <please select the answer> A. Input layer B. Interface layer C. Category layer",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
ef607126-c732-4138-a81d-12fc04cf587b,test,future,elementary school,u11,6,group 3,post test,8,10,1,True,T,"True or False: The clustering of K-means is that for each sample point, find the closest center point to it. <please select the best answer> True or False",The process of k-means clustering. Step 2: For each sample point find the center point closest to it and the points closest to the same center point is a class. Thus completing a clustering. Closest to green! Closest to red! Closest to blue! It contains a picture of an example of step 2.
947eb54d-df0d-4c52-b860-509b037d28b1,test,future,elementary school,u11,6,group 3,post test,9,12,1,False,F,"True or False: After each clustering, there is no need to recalculate the center points. <please select the best answer> True or False",The process of k-means clustering. Step 4: for the sample points in each category calculate the center point of these sample points as the new center points. Continue to step 2. It contains a picture of an example of step 4.
93453d03-6416-42ee-bfc1-91edfac6c20e,test,past,elementary school,u11,6,group 3,post test,2,6,1,One-to-one connections,A,"In an ART network, the input layer sends signals to the interface layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
82d12579-2ee1-4c7c-a796-c01fa9d48ecc,test,future,elementary school,u11,6,group 3,post test,6,16,0,Larger,B,The unsupervised ANN that can compress usually has a middle layer that has a much ____ number of neurons. <please select the best answer> A. larger B. smaller,Unsupervised ANNs that compress. These networks usually have a middle layer that has a much smaller number of neurons making an hourglass-structure. These networks usually compress the inputs and reproduce the inputs. It contains a picture of the structure of unsupervised ANNs and a picture of biscuits.
51ac2c95-ad51-4f22-bf5e-134402b39376,test,past,elementary school,u11,6,group 3,post test,5,4,1,Stephen Grossberg,B,Which person created Adaptive resonance theory1 (ART1)? <please select the best answer> A. David Hubel B. Stephen Grossberg C. Teuvo Kohonen,Adaptive resonance theory 1 (ART1). Adaptive resonance theory 1: an example of a neural network that performs grouping. Created by cognitive scientist Stephen Grossberg and mathematician Gail Carpenter. It contains a picture of Stephen.
33c5ef8c-1c21-48f5-a7c9-1008b64f658d,test,future,elementary school,u11,6,group 3,post test,10,11,0,???,The categories of sample points before and after the clustering are the same,What is the end condition of the K-means algorithm? <please input your answer>,"The process of k-means clustering. Step 3: determine whether the categories of the samples points before and after the clustering are the same. If they are the same, the algorithm terminates. Otherwise, enter step 4. In this example the sample points before and after are different then we enter step 4. It contains a picture of an example of step 3."
8c9ccc28-49c8-4b95-90a9-de64ce87f0db,test,future,elementary school,u11,6,group 3,post test,7,9,0,True,F,True or False: The k center points are selected from sample points. <please select the best answer> True or False,"The process of k-means clustering. Step 1: select the number k of categories to be clustered and select k center points. E.g., k=3. The k center points are randomly selected on the plane. It contains a picture of an example of step 1."
8de4a714-63e7-4dc9-9f1d-9fcd6654d392,train,past,elementary school,u12,6,group 3,post test,3,6,1,Full connections,B,"In an ART network, the interface layer activates the category layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
7a872703-98e2-44c0-9840-a11dbc336cdd,train,past,elementary school,u12,6,group 3,post test,4,3,1,Cluster,cluster/classification,Please write another name for “grouping” in unsupervised learning. <please input your answer>,"Grouping. An unsupervised learning neural network can group similar inputs. Grouping is also called clustering classification or categorization. E.g., grouping images of cats and images of dogs. The picture contains an example of grouping."
096526f7-e1df-4e11-9b6d-3181565a181d,train,past,elementary school,u12,6,group 3,post test,1,6,1,Interface layer;Category layer,BC,"In an ART network, resonance is introduced to realize stable category formation. Resonance is established between which two layers? <please select the answer> A. Input layer B. Interface layer C. Category layer",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
16ba7e72-75a0-40a4-b9ac-e35e2d7c468b,train,future,elementary school,u12,6,group 3,post test,8,10,0,False,T,"True or False: The clustering of K-means is that for each sample point, find the closest center point to it. <please select the best answer> True or False",The process of k-means clustering. Step 2: For each sample point find the center point closest to it and the points closest to the same center point is a class. Thus completing a clustering. Closest to green! Closest to red! Closest to blue! It contains a picture of an example of step 2.
a742114d-c5b8-496c-997e-07bc04d635bf,train,future,elementary school,u12,6,group 3,post test,9,12,0,True,F,"True or False: After each clustering, there is no need to recalculate the center points. <please select the best answer> True or False",The process of k-means clustering. Step 4: for the sample points in each category calculate the center point of these sample points as the new center points. Continue to step 2. It contains a picture of an example of step 4.
221eb526-e5b0-4428-b13f-9223ef5fc90a,train,past,elementary school,u12,6,group 3,post test,2,6,1,One-to-one connections,A,"In an ART network, the input layer sends signals to the interface layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
44bf9d46-0060-4091-8b06-0886c97d7755,train,future,elementary school,u12,6,group 3,post test,6,16,1,Smaller,B,The unsupervised ANN that can compress usually has a middle layer that has a much ____ number of neurons. <please select the best answer> A. larger B. smaller,Unsupervised ANNs that compress. These networks usually have a middle layer that has a much smaller number of neurons making an hourglass-structure. These networks usually compress the inputs and reproduce the inputs. It contains a picture of the structure of unsupervised ANNs and a picture of biscuits.
f9aa8c67-64b7-43ec-864e-b9b52837e9b3,train,past,elementary school,u12,6,group 3,post test,5,4,1,Stephen Grossberg,B,Which person created Adaptive resonance theory1 (ART1)? <please select the best answer> A. David Hubel B. Stephen Grossberg C. Teuvo Kohonen,Adaptive resonance theory 1 (ART1). Adaptive resonance theory 1: an example of a neural network that performs grouping. Created by cognitive scientist Stephen Grossberg and mathematician Gail Carpenter. It contains a picture of Stephen.
a7d3b4f2-454e-4d4d-96f6-dcc7d22c10c6,train,future,elementary school,u12,6,group 3,post test,10,11,0, ,The categories of sample points before and after the clustering are the same,What is the end condition of the K-means algorithm? <please input your answer>,"The process of k-means clustering. Step 3: determine whether the categories of the samples points before and after the clustering are the same. If they are the same, the algorithm terminates. Otherwise, enter step 4. In this example the sample points before and after are different then we enter step 4. It contains a picture of an example of step 3."
278a6634-5ea0-4786-8a4d-8269a4bf891a,train,future,elementary school,u12,6,group 3,post test,7,9,1,False,F,True or False: The k center points are selected from sample points. <please select the best answer> True or False,"The process of k-means clustering. Step 1: select the number k of categories to be clustered and select k center points. E.g., k=3. The k center points are randomly selected on the plane. It contains a picture of an example of step 1."
61b6159c-ae4e-4d48-b101-01ffc1743567,train,past,elementary school,u14,6,group 3,post test,3,6,1,Full connections,B,"In an ART network, the interface layer activates the category layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
d126b05d-e0ab-4ad8-9265-f81739d55191,train,past,elementary school,u14,6,group 3,post test,4,3,1,cluster,cluster/classification,Please write another name for “grouping” in unsupervised learning. <please input your answer>,"Grouping. An unsupervised learning neural network can group similar inputs. Grouping is also called clustering classification or categorization. E.g., grouping images of cats and images of dogs. The picture contains an example of grouping."
ea1e20e2-9843-4ce7-92c8-013a5957e809,train,past,elementary school,u14,6,group 3,post test,1,6,1,Interface layer;Category layer,BC,"In an ART network, resonance is introduced to realize stable category formation. Resonance is established between which two layers? <please select the answer> A. Input layer B. Interface layer C. Category layer",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
b7c0b23d-8191-45fd-8a44-dedcf064d058,train,future,elementary school,u14,6,group 3,post test,8,10,1,True,T,"True or False: The clustering of K-means is that for each sample point, find the closest center point to it. <please select the best answer> True or False",The process of k-means clustering. Step 2: For each sample point find the center point closest to it and the points closest to the same center point is a class. Thus completing a clustering. Closest to green! Closest to red! Closest to blue! It contains a picture of an example of step 2.
82207c94-e75d-4890-98f2-99d45a650a50,train,future,elementary school,u14,6,group 3,post test,9,12,1,False,F,"True or False: After each clustering, there is no need to recalculate the center points. <please select the best answer> True or False",The process of k-means clustering. Step 4: for the sample points in each category calculate the center point of these sample points as the new center points. Continue to step 2. It contains a picture of an example of step 4.
f26be875-b873-4046-8c13-d79519df0c29,train,past,elementary school,u14,6,group 3,post test,2,6,1,One-to-one connections,A,"In an ART network, the input layer sends signals to the interface layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
b2aa3e43-a555-48f7-843c-ee72f9366f08,train,future,elementary school,u14,6,group 3,post test,6,16,1,Smaller,B,The unsupervised ANN that can compress usually has a middle layer that has a much ____ number of neurons. <please select the best answer> A. larger B. smaller,Unsupervised ANNs that compress. These networks usually have a middle layer that has a much smaller number of neurons making an hourglass-structure. These networks usually compress the inputs and reproduce the inputs. It contains a picture of the structure of unsupervised ANNs and a picture of biscuits.
35c608bd-c4ad-4456-b421-2449e7b62bb1,train,past,elementary school,u14,6,group 3,post test,5,4,1,Stephen Grossberg,B,Which person created Adaptive resonance theory1 (ART1)? <please select the best answer> A. David Hubel B. Stephen Grossberg C. Teuvo Kohonen,Adaptive resonance theory 1 (ART1). Adaptive resonance theory 1: an example of a neural network that performs grouping. Created by cognitive scientist Stephen Grossberg and mathematician Gail Carpenter. It contains a picture of Stephen.
eb89c601-f856-4cc8-afe2-c1261a7c6a90,train,future,elementary school,u14,6,group 3,post test,10,11,1,The categories of sample points before and after the clustering are the same.,The categories of sample points before and after the clustering are the same,What is the end condition of the K-means algorithm? <please input your answer>,"The process of k-means clustering. Step 3: determine whether the categories of the samples points before and after the clustering are the same. If they are the same, the algorithm terminates. Otherwise, enter step 4. In this example the sample points before and after are different then we enter step 4. It contains a picture of an example of step 3."
1f7f1df8-2802-435d-9aaf-8f6d728aa097,train,future,elementary school,u14,6,group 3,post test,7,9,1,False,F,True or False: The k center points are selected from sample points. <please select the best answer> True or False,"The process of k-means clustering. Step 1: select the number k of categories to be clustered and select k center points. E.g., k=3. The k center points are randomly selected on the plane. It contains a picture of an example of step 1."
a4f8afc9-4fb4-4258-b6d7-0228bab0543f,train,past,elementary school,u15,6,group 3,post test,3,6,1,Full connections,B,"In an ART network, the interface layer activates the category layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
7a7f79fc-0943-4b30-8141-08bd734c71d1,train,past,elementary school,u15,6,group 3,post test,4,3,1,Classification,cluster/classification,Please write another name for “grouping” in unsupervised learning. <please input your answer>,"Grouping. An unsupervised learning neural network can group similar inputs. Grouping is also called clustering classification or categorization. E.g., grouping images of cats and images of dogs. The picture contains an example of grouping."
ff50cbc6-3816-49f0-8ed6-ebc6fc3db153,train,past,elementary school,u15,6,group 3,post test,1,6,1,Interface layer;Category layer,BC,"In an ART network, resonance is introduced to realize stable category formation. Resonance is established between which two layers? <please select the answer> A. Input layer B. Interface layer C. Category layer",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
9dccefc8-d787-4dc7-bbb8-53fb8f46c489,train,future,elementary school,u15,6,group 3,post test,8,10,1,True,T,"True or False: The clustering of K-means is that for each sample point, find the closest center point to it. <please select the best answer> True or False",The process of k-means clustering. Step 2: For each sample point find the center point closest to it and the points closest to the same center point is a class. Thus completing a clustering. Closest to green! Closest to red! Closest to blue! It contains a picture of an example of step 2.
4ea9603f-7db2-49c5-aa94-3be850a1768a,train,future,elementary school,u15,6,group 3,post test,9,12,1,False,F,"True or False: After each clustering, there is no need to recalculate the center points. <please select the best answer> True or False",The process of k-means clustering. Step 4: for the sample points in each category calculate the center point of these sample points as the new center points. Continue to step 2. It contains a picture of an example of step 4.
3b08d930-5781-4b41-be86-97d6867e1415,train,past,elementary school,u15,6,group 3,post test,2,6,1,One-to-one connections,A,"In an ART network, the input layer sends signals to the interface layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
3bbeb9a8-4a47-47ee-88f4-9874bc32b20f,train,future,elementary school,u15,6,group 3,post test,6,16,1,Smaller,B,The unsupervised ANN that can compress usually has a middle layer that has a much ____ number of neurons. <please select the best answer> A. larger B. smaller,Unsupervised ANNs that compress. These networks usually have a middle layer that has a much smaller number of neurons making an hourglass-structure. These networks usually compress the inputs and reproduce the inputs. It contains a picture of the structure of unsupervised ANNs and a picture of biscuits.
ac8fc7bc-604b-4406-ba82-b14329d402ad,train,past,elementary school,u15,6,group 3,post test,5,4,1,Stephen Grossberg,B,Which person created Adaptive resonance theory1 (ART1)? <please select the best answer> A. David Hubel B. Stephen Grossberg C. Teuvo Kohonen,Adaptive resonance theory 1 (ART1). Adaptive resonance theory 1: an example of a neural network that performs grouping. Created by cognitive scientist Stephen Grossberg and mathematician Gail Carpenter. It contains a picture of Stephen.
fa9c3ac7-543b-4015-938a-96b733ffe707,train,future,elementary school,u15,6,group 3,post test,10,11,0,"If after repeating steps, the result stays the same, it is time to end the algorithm",The categories of sample points before and after the clustering are the same,What is the end condition of the K-means algorithm? <please input your answer>,"The process of k-means clustering. Step 3: determine whether the categories of the samples points before and after the clustering are the same. If they are the same, the algorithm terminates. Otherwise, enter step 4. In this example the sample points before and after are different then we enter step 4. It contains a picture of an example of step 3."
ff5bcc7f-d95e-4e7a-b91a-c6f171fcb3f5,train,future,elementary school,u15,6,group 3,post test,7,9,0,True,F,True or False: The k center points are selected from sample points. <please select the best answer> True or False,"The process of k-means clustering. Step 1: select the number k of categories to be clustered and select k center points. E.g., k=3. The k center points are randomly selected on the plane. It contains a picture of an example of step 1."
ffb32cca-67fe-4638-98da-16ffec089cb9,test,past,elementary school,u19,10,group 1,post test,3,12,1,C,C,The CNN is a method can be classified as: <please select the best answer> A. Reinforcement learning B. Unsupervised learning C. Supervised learning D. Federated learning,"Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
a8e48169-6f8c-412f-b84d-525d61b4c2f1,test,past,elementary school,u19,10,group 1,post test,4,12,1,D,D,"To train a CNN that tells what is in a picture, what kind of pictures are needed? <please select the best answer> A. Pictures collected from the Internet without further information B. Pictures collected from the Internet with the data captured C. Images collected from the Internet with the geographic information D. Images collected from the Internet with category information","Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
189b95c8-94fd-4eb2-b041-e65f03ec5399,test,past,elementary school,u19,10,group 1,post test,1,8,1,A,A,Which of the following options comprises digital images stored in computers? <please select the best answer> A. Pixels B. Frames C. Videos,"Images are stored as pixels. When zooming in a picture real close, we find it is composed of mosaics. These small squares are pixels. We fill each pixel with color and then we get a picture! A picture showing the effect of zooming in a picture will get mosaics or pixels."
622005a6-d5ad-480c-9b7c-3a6b1e26982e,test,future,elementary school,u19,10,group 1,post test,8,17,1,C,C,"The table below is a small region to apply a pooling operation. What is the correct result after an average pooling? The region where average pooling is to be applied: 3,9,6,2. <please select the best answer> A. 4 B. 5 C. 9 D. 6",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
04694675-8b73-4bd7-ab6f-c40cfb6f7cfa,test,future,elementary school,u19,10,group 1,post test,9,15,1,2,2,"Recall the operations in a convolution layer. When given an image and a kernel as follows, which of the following is the correct answer for the missing value in the output from the layer? The image: [[1,1,1,1],[0,0,1,0],[0,1,0,0],[1,0,0,0]]. The kernel: [[0,1],[1,0]].The output. '_' is the missing value: [[1,1,2],[0,_,0],[2,0,0]] <please input your answer>","Convolution layer in animation and why we convolutes?Dr. Hubel and Dr. Wiesel found that some neurons fired very rapidly by watching the lines at specific angles, while other neurons responded best to the lines at different angles. The kernels (smaller matrix) are similar to the neurons: some produce larger output when given certain features like horizontal edges, while some respond to vertical edges. An animation of convolution computation."
8c10527e-bab1-447c-886c-9b06f28aba89,test,past,elementary school,u19,10,group 1,post test,2,9,1,D,D,"What are the three primary colors that computers use to represent other colors introduced in the lecture? <please select the best answer> A. Red, orange and yellow B. Red, green and purple C. Blue, orange and purple D. Red, green and blue","What exactly is stored in computer? Red, green and blue are three primary colors. When blend together, they can generate a full range of colors. The computer actually stores the colors of each pixel, and in our case, the value of red, green and blue. A picture showing RGB are the primary colors. A picture of a traffic sign and its corresponding pixel values representation."
5df4141f-9c6a-477f-8ad7-1c895c07ccdd,test,future,elementary school,u19,10,group 1,post test,6,16,1,C,C,"The output from a convolution layer is shown below. How many values will be changed after a ReLU layer is applied? The output from a convolution layer: 1, 7, 3, -2, -4, 5, 4, 1, 2. <please select the best answer> A. 0 B. 1 C. 2 D. 3","ReLU, a math transformation. Rectified Linear Unit. output = input if input > 0, 0 otherwise. output = max(input, 0). Mimics the way how biological neurons are triggered! A picture of different numbers and their output after ReLU."
64455249-6672-4901-bc71-b7675d32434c,test,past,elementary school,u19,10,group 1,post test,5,14,1,B,B,What does the convolution layer do? <please select the best answer> A. It condenses the output of small regions into a single output B. It slides through the images and sums up the products of numbers C. It mimics the way neurons are only triggered by strong stimuli D. It tells what is in an image based on the information from hidden layers,"Convolution layer. The convolution layer is the core building block of the CNN. This layer performs a dot product (one-to-one) between two matrices (ordered numbers). One is the image, and the other is called kernel, mimicing the way human visual system works. A picture showing the computation process of convolution."
2738eaff-b3c6-4f44-8f72-2ad2b046dab6,test,future,elementary school,u19,10,group 1,post test,10,19,1,B,B,"If the correct category of an image is “train”, which of the following will be considered as correct under the definition of top-3 error? (From the left to the right, the probability of the answer decreases.) <please select the best answer> A. [“plane”, “motorcycle”, “bird”, “snake”, “train”] B. [“plane”, “motorcycle”, “train”, “bird”, “snake”] C. [“motorcycle”, “plane”, “snake”, “train”, “bird”] D. [“motorcycle”, “plane”, “car”, “bird”, “snake”]","AlexNet: A CNN model follows previous pattern. AlexNet won the 2012 ImageNet competition, where computers should tell what is in the picture, with a top-5 error rate of 15.3%, compared to the second place top-5 error rate of 26.2%. top-5 error: predicting 5 categories and if all are wrong, it counts as an error. A picture of AlexNet architecture. A bar graph of classification error rate vs different method groups"
4b80b78e-1115-4747-b559-ba28b7a2e513,test,future,elementary school,u19,10,group 1,post test,7,17,1,B,B,"The table below is a small region to apply a pooling operation. What is the correct result after max pooling? The region where max pooling is to be applied: 3,9,6,2. <please select the best answer> A. 4 B. 9 C. 10 D. 6",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
7bae54e0-dc81-4032-b1ee-0c9a99c00721,test,past,elementary school,u5,10,group 2,post test,3,12,1,C,C,The CNN is a method can be classified as: <please select the best answer> A. Reinforcement learning B. Unsupervised learning C. Supervised learning D. Federated learning,"Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
5f4b1df5-014b-4133-80b2-22041b1339e0,test,past,elementary school,u5,10,group 2,post test,4,12,1,D,D,"To train a CNN that tells what is in a picture, what kind of pictures are needed? <please select the best answer> A. Pictures collected from the Internet without further information B. Pictures collected from the Internet with the data captured C. Images collected from the Internet with the geographic information D. Images collected from the Internet with category information","Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
2a0d4cf6-8725-4659-8c25-c4a219573cb3,test,past,elementary school,u5,10,group 2,post test,1,8,0,B,A,Which of the following options comprises digital images stored in computers? <please select the best answer> A. Pixels B. Frames C. Videos,"Images are stored as pixels. When zooming in a picture real close, we find it is composed of mosaics. These small squares are pixels. We fill each pixel with color and then we get a picture! A picture showing the effect of zooming in a picture will get mosaics or pixels."
19e501ea-4311-45d3-aacb-9e7abeb3892d,test,future,elementary school,u5,10,group 2,post test,8,17,1,C,C,"The table below is a small region to apply a pooling operation. What is the correct result after an average pooling? The region where average pooling is to be applied: 3,9,6,2. <please select the best answer> A. 4 B. 5 C. 9 D. 6",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
62a191d8-8699-4d6e-a0c7-e6506f28c6ad,test,future,elementary school,u5,10,group 2,post test,9,15,1,2,2,"Recall the operations in a convolution layer. When given an image and a kernel as follows, which of the following is the correct answer for the missing value in the output from the layer? The image: [[1,1,1,1],[0,0,1,0],[0,1,0,0],[1,0,0,0]]. The kernel: [[0,1],[1,0]].The output. '_' is the missing value: [[1,1,2],[0,_,0],[2,0,0]] <please input your answer>","Convolution layer in animation and why we convolutes?Dr. Hubel and Dr. Wiesel found that some neurons fired very rapidly by watching the lines at specific angles, while other neurons responded best to the lines at different angles. The kernels (smaller matrix) are similar to the neurons: some produce larger output when given certain features like horizontal edges, while some respond to vertical edges. An animation of convolution computation."
c8f63aaa-9eab-4928-b919-4c868fa5b55d,test,past,elementary school,u5,10,group 2,post test,2,9,1,D,D,"What are the three primary colors that computers use to represent other colors introduced in the lecture? <please select the best answer> A. Red, orange and yellow B. Red, green and purple C. Blue, orange and purple D. Red, green and blue","What exactly is stored in computer? Red, green and blue are three primary colors. When blend together, they can generate a full range of colors. The computer actually stores the colors of each pixel, and in our case, the value of red, green and blue. A picture showing RGB are the primary colors. A picture of a traffic sign and its corresponding pixel values representation."
f55f4df5-d15f-44cb-b381-59df78c6b2e3,test,future,elementary school,u5,10,group 2,post test,6,16,1,C,C,"The output from a convolution layer is shown below. How many values will be changed after a ReLU layer is applied? The output from a convolution layer: 1, 7, 3, -2, -4, 5, 4, 1, 2. <please select the best answer> A. 0 B. 1 C. 2 D. 3","ReLU, a math transformation. Rectified Linear Unit. output = input if input > 0, 0 otherwise. output = max(input, 0). Mimics the way how biological neurons are triggered! A picture of different numbers and their output after ReLU."
6c370899-60a6-46d6-ad86-25cac4eb4cfc,test,past,elementary school,u5,10,group 2,post test,5,14,0,A,B,What does the convolution layer do? <please select the best answer> A. It condenses the output of small regions into a single output B. It slides through the images and sums up the products of numbers C. It mimics the way neurons are only triggered by strong stimuli D. It tells what is in an image based on the information from hidden layers,"Convolution layer. The convolution layer is the core building block of the CNN. This layer performs a dot product (one-to-one) between two matrices (ordered numbers). One is the image, and the other is called kernel, mimicing the way human visual system works. A picture showing the computation process of convolution."
df48a664-3e1e-4692-a184-a0f8d7c821fc,test,future,elementary school,u5,10,group 2,post test,10,19,0,A,B,"If the correct category of an image is “train”, which of the following will be considered as correct under the definition of top-3 error? (From the left to the right, the probability of the answer decreases.) <please select the best answer> A. [“plane”, “motorcycle”, “bird”, “snake”, “train”] B. [“plane”, “motorcycle”, “train”, “bird”, “snake”] C. [“motorcycle”, “plane”, “snake”, “train”, “bird”] D. [“motorcycle”, “plane”, “car”, “bird”, “snake”]","AlexNet: A CNN model follows previous pattern. AlexNet won the 2012 ImageNet competition, where computers should tell what is in the picture, with a top-5 error rate of 15.3%, compared to the second place top-5 error rate of 26.2%. top-5 error: predicting 5 categories and if all are wrong, it counts as an error. A picture of AlexNet architecture. A bar graph of classification error rate vs different method groups"
8c01fa14-b366-4aa4-a938-49f7e8939d78,test,future,elementary school,u5,10,group 2,post test,7,17,1,B,B,"The table below is a small region to apply a pooling operation. What is the correct result after max pooling? The region where max pooling is to be applied: 3,9,6,2. <please select the best answer> A. 4 B. 9 C. 10 D. 6",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
8e11b7b2-58a3-473a-bdc5-e4962d765d21,train,past,elementary school,u7,10,group 2,post test,3,12,1,C,C,The CNN is a method can be classified as: <please select the best answer> A. Reinforcement learning B. Unsupervised learning C. Supervised learning D. Federated learning,"Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
6f302e3a-a0bd-41c2-ab6e-ab93f7cb7319,train,past,elementary school,u7,10,group 2,post test,4,12,1,D,D,"To train a CNN that tells what is in a picture, what kind of pictures are needed? <please select the best answer> A. Pictures collected from the Internet without further information B. Pictures collected from the Internet with the data captured C. Images collected from the Internet with the geographic information D. Images collected from the Internet with category information","Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
33810f25-fa9d-44b1-a62f-31937d7af8c9,train,past,elementary school,u7,10,group 2,post test,1,8,1,A,A,Which of the following options comprises digital images stored in computers? <please select the best answer> A. Pixels B. Frames C. Videos,"Images are stored as pixels. When zooming in a picture real close, we find it is composed of mosaics. These small squares are pixels. We fill each pixel with color and then we get a picture! A picture showing the effect of zooming in a picture will get mosaics or pixels."
952fb5bf-f5aa-4db5-b4c1-60c711e01e6f,train,future,elementary school,u7,10,group 2,post test,8,17,1,C,C,"The table below is a small region to apply a pooling operation. What is the correct result after an average pooling? The region where average pooling is to be applied: 3,9,6,2. <please select the best answer> A. 4 B. 5 C. 9 D. 6",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
037da7e5-2c08-408e-b563-d5a0b8aaf5d3,train,future,elementary school,u7,10,group 2,post test,9,15,1,2,2,"Recall the operations in a convolution layer. When given an image and a kernel as follows, which of the following is the correct answer for the missing value in the output from the layer? The image: [[1,1,1,1],[0,0,1,0],[0,1,0,0],[1,0,0,0]]. The kernel: [[0,1],[1,0]].The output. '_' is the missing value: [[1,1,2],[0,_,0],[2,0,0]] <please input your answer>","Convolution layer in animation and why we convolutes?Dr. Hubel and Dr. Wiesel found that some neurons fired very rapidly by watching the lines at specific angles, while other neurons responded best to the lines at different angles. The kernels (smaller matrix) are similar to the neurons: some produce larger output when given certain features like horizontal edges, while some respond to vertical edges. An animation of convolution computation."
ba1082c6-6f72-4878-8613-8df25b7e6939,train,past,elementary school,u7,10,group 2,post test,2,9,1,D,D,"What are the three primary colors that computers use to represent other colors introduced in the lecture? <please select the best answer> A. Red, orange and yellow B. Red, green and purple C. Blue, orange and purple D. Red, green and blue","What exactly is stored in computer? Red, green and blue are three primary colors. When blend together, they can generate a full range of colors. The computer actually stores the colors of each pixel, and in our case, the value of red, green and blue. A picture showing RGB are the primary colors. A picture of a traffic sign and its corresponding pixel values representation."
ea66f71b-f835-4fa7-a780-31ddbed402ae,train,future,elementary school,u7,10,group 2,post test,6,16,1,C,C,"The output from a convolution layer is shown below. How many values will be changed after a ReLU layer is applied? The output from a convolution layer: 1, 7, 3, -2, -4, 5, 4, 1, 2. <please select the best answer> A. 0 B. 1 C. 2 D. 3","ReLU, a math transformation. Rectified Linear Unit. output = input if input > 0, 0 otherwise. output = max(input, 0). Mimics the way how biological neurons are triggered! A picture of different numbers and their output after ReLU."
f9bf4a41-7df1-4b3f-a13b-b57f647250b5,train,past,elementary school,u7,10,group 2,post test,5,14,1,B,B,What does the convolution layer do? <please select the best answer> A. It condenses the output of small regions into a single output B. It slides through the images and sums up the products of numbers C. It mimics the way neurons are only triggered by strong stimuli D. It tells what is in an image based on the information from hidden layers,"Convolution layer. The convolution layer is the core building block of the CNN. This layer performs a dot product (one-to-one) between two matrices (ordered numbers). One is the image, and the other is called kernel, mimicing the way human visual system works. A picture showing the computation process of convolution."
2ea22810-ce21-442a-b757-1d4b03c72972,train,future,elementary school,u7,10,group 2,post test,10,19,1,B,B,"If the correct category of an image is “train”, which of the following will be considered as correct under the definition of top-3 error? (From the left to the right, the probability of the answer decreases.) <please select the best answer> A. [“plane”, “motorcycle”, “bird”, “snake”, “train”] B. [“plane”, “motorcycle”, “train”, “bird”, “snake”] C. [“motorcycle”, “plane”, “snake”, “train”, “bird”] D. [“motorcycle”, “plane”, “car”, “bird”, “snake”]","AlexNet: A CNN model follows previous pattern. AlexNet won the 2012 ImageNet competition, where computers should tell what is in the picture, with a top-5 error rate of 15.3%, compared to the second place top-5 error rate of 26.2%. top-5 error: predicting 5 categories and if all are wrong, it counts as an error. A picture of AlexNet architecture. A bar graph of classification error rate vs different method groups"
6301bdec-bb97-4d7e-abb4-7d2cbff73974,train,future,elementary school,u7,10,group 2,post test,7,17,1,B,B,"The table below is a small region to apply a pooling operation. What is the correct result after max pooling? The region where max pooling is to be applied: 3,9,6,2. <please select the best answer> A. 4 B. 9 C. 10 D. 6",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
ae40e7e5-5e2b-4ef5-a4d6-b9bb584c1782,train,past,elementary school,u21,10,group 2,post test,3,12,1,C,C,The CNN is a method can be classified as: <please select the best answer> A. Reinforcement learning B. Unsupervised learning C. Supervised learning D. Federated learning,"Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
cc9030e5-af72-4122-b688-370a33f0995a,train,past,elementary school,u21,10,group 2,post test,4,12,1,D,D,"To train a CNN that tells what is in a picture, what kind of pictures are needed? <please select the best answer> A. Pictures collected from the Internet without further information B. Pictures collected from the Internet with the data captured C. Images collected from the Internet with the geographic information D. Images collected from the Internet with category information","Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
b7814c49-b858-48bd-b478-35114ec81371,train,past,elementary school,u21,10,group 2,post test,1,8,1,A,A,Which of the following options comprises digital images stored in computers? <please select the best answer> A. Pixels B. Frames C. Videos,"Images are stored as pixels. When zooming in a picture real close, we find it is composed of mosaics. These small squares are pixels. We fill each pixel with color and then we get a picture! A picture showing the effect of zooming in a picture will get mosaics or pixels."
0e21ec1b-ac13-4028-8cfd-c7eb210001c4,train,future,elementary school,u21,10,group 2,post test,8,17,0,A,C,"The table below is a small region to apply a pooling operation. What is the correct result after an average pooling? The region where average pooling is to be applied: 3,9,6,2. <please select the best answer> A. 4 B. 5 C. 9 D. 6",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
f4dddd0a-2e74-4c86-8cf3-cd77c59ace7f,train,future,elementary school,u21,10,group 2,post test,9,15,1,2,2,"Recall the operations in a convolution layer. When given an image and a kernel as follows, which of the following is the correct answer for the missing value in the output from the layer? The image: [[1,1,1,1],[0,0,1,0],[0,1,0,0],[1,0,0,0]]. The kernel: [[0,1],[1,0]].The output. '_' is the missing value: [[1,1,2],[0,_,0],[2,0,0]] <please input your answer>","Convolution layer in animation and why we convolutes?Dr. Hubel and Dr. Wiesel found that some neurons fired very rapidly by watching the lines at specific angles, while other neurons responded best to the lines at different angles. The kernels (smaller matrix) are similar to the neurons: some produce larger output when given certain features like horizontal edges, while some respond to vertical edges. An animation of convolution computation."
25f6b62d-eedc-466d-b921-cab829cd2fbc,train,past,elementary school,u21,10,group 2,post test,2,9,1,D,D,"What are the three primary colors that computers use to represent other colors introduced in the lecture? <please select the best answer> A. Red, orange and yellow B. Red, green and purple C. Blue, orange and purple D. Red, green and blue","What exactly is stored in computer? Red, green and blue are three primary colors. When blend together, they can generate a full range of colors. The computer actually stores the colors of each pixel, and in our case, the value of red, green and blue. A picture showing RGB are the primary colors. A picture of a traffic sign and its corresponding pixel values representation."
94a1802b-0cbd-4860-be67-f89f011cecd9,train,future,elementary school,u21,10,group 2,post test,6,16,1,C,C,"The output from a convolution layer is shown below. How many values will be changed after a ReLU layer is applied? The output from a convolution layer: 1, 7, 3, -2, -4, 5, 4, 1, 2. <please select the best answer> A. 0 B. 1 C. 2 D. 3","ReLU, a math transformation. Rectified Linear Unit. output = input if input > 0, 0 otherwise. output = max(input, 0). Mimics the way how biological neurons are triggered! A picture of different numbers and their output after ReLU."
6b897417-3c8b-4d8a-9926-3b039e714777,train,past,elementary school,u21,10,group 2,post test,5,14,0,A,B,What does the convolution layer do? <please select the best answer> A. It condenses the output of small regions into a single output B. It slides through the images and sums up the products of numbers C. It mimics the way neurons are only triggered by strong stimuli D. It tells what is in an image based on the information from hidden layers,"Convolution layer. The convolution layer is the core building block of the CNN. This layer performs a dot product (one-to-one) between two matrices (ordered numbers). One is the image, and the other is called kernel, mimicing the way human visual system works. A picture showing the computation process of convolution."
6050acc5-7689-4622-9685-f67a6e015289,train,future,elementary school,u21,10,group 2,post test,10,19,0,C,B,"If the correct category of an image is “train”, which of the following will be considered as correct under the definition of top-3 error? (From the left to the right, the probability of the answer decreases.) <please select the best answer> A. [“plane”, “motorcycle”, “bird”, “snake”, “train”] B. [“plane”, “motorcycle”, “train”, “bird”, “snake”] C. [“motorcycle”, “plane”, “snake”, “train”, “bird”] D. [“motorcycle”, “plane”, “car”, “bird”, “snake”]","AlexNet: A CNN model follows previous pattern. AlexNet won the 2012 ImageNet competition, where computers should tell what is in the picture, with a top-5 error rate of 15.3%, compared to the second place top-5 error rate of 26.2%. top-5 error: predicting 5 categories and if all are wrong, it counts as an error. A picture of AlexNet architecture. A bar graph of classification error rate vs different method groups"
ff4c6ea3-53f5-4288-8ef1-49326ce86017,train,future,elementary school,u21,10,group 2,post test,7,17,1,B,B,"The table below is a small region to apply a pooling operation. What is the correct result after max pooling? The region where max pooling is to be applied: 3,9,6,2. <please select the best answer> A. 4 B. 9 C. 10 D. 6",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
29412ddc-48e6-4b07-9c03-b85dc5b011ed,train,past,elementary school,u26,10,group 3,post test,3,12,0,A,C,The CNN is a method can be classified as: <please select the best answer> A. Reinforcement learning B. Unsupervised learning C. Supervised learning D. Federated learning,"Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
9a3623ca-4b4c-4a3e-ae47-82f71b0708c5,train,past,elementary school,u26,10,group 3,post test,4,12,0,B,D,"To train a CNN that tells what is in a picture, what kind of pictures are needed? <please select the best answer> A. Pictures collected from the Internet without further information B. Pictures collected from the Internet with the data captured C. Images collected from the Internet with the geographic information D. Images collected from the Internet with category information","Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
b4d0ce51-65aa-4b0c-ab05-e9f39d1f52f1,train,past,elementary school,u26,10,group 3,post test,1,8,0,B,A,Which of the following options comprises digital images stored in computers? <please select the best answer> A. Pixels B. Frames C. Videos,"Images are stored as pixels. When zooming in a picture real close, we find it is composed of mosaics. These small squares are pixels. We fill each pixel with color and then we get a picture! A picture showing the effect of zooming in a picture will get mosaics or pixels."
b9a42041-b68b-4319-884e-2a32627bde64,train,future,elementary school,u26,10,group 3,post test,8,17,0,D,C,"The table below is a small region to apply a pooling operation. What is the correct result after an average pooling? The region where average pooling is to be applied: 3,9,6,2. <please select the best answer> A. 4 B. 5 C. 9 D. 6",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
dd443c65-581c-4449-b04e-d55e7ad96a3f,train,future,elementary school,u26,10,group 3,post test,9,15,1,2,2,"Recall the operations in a convolution layer. When given an image and a kernel as follows, which of the following is the correct answer for the missing value in the output from the layer? The image: [[1,1,1,1],[0,0,1,0],[0,1,0,0],[1,0,0,0]]. The kernel: [[0,1],[1,0]].The output. '_' is the missing value: [[1,1,2],[0,_,0],[2,0,0]] <please input your answer>","Convolution layer in animation and why we convolutes?Dr. Hubel and Dr. Wiesel found that some neurons fired very rapidly by watching the lines at specific angles, while other neurons responded best to the lines at different angles. The kernels (smaller matrix) are similar to the neurons: some produce larger output when given certain features like horizontal edges, while some respond to vertical edges. An animation of convolution computation."
f688d3c9-05fb-4d1a-b89d-20358c91698b,train,past,elementary school,u26,10,group 3,post test,2,9,1,D,D,"What are the three primary colors that computers use to represent other colors introduced in the lecture? <please select the best answer> A. Red, orange and yellow B. Red, green and purple C. Blue, orange and purple D. Red, green and blue","What exactly is stored in computer? Red, green and blue are three primary colors. When blend together, they can generate a full range of colors. The computer actually stores the colors of each pixel, and in our case, the value of red, green and blue. A picture showing RGB are the primary colors. A picture of a traffic sign and its corresponding pixel values representation."
38880d0f-c2d9-4476-8a40-227e5d993c40,train,future,elementary school,u26,10,group 3,post test,6,16,0,B,C,"The output from a convolution layer is shown below. How many values will be changed after a ReLU layer is applied? The output from a convolution layer: 1, 7, 3, -2, -4, 5, 4, 1, 2. <please select the best answer> A. 0 B. 1 C. 2 D. 3","ReLU, a math transformation. Rectified Linear Unit. output = input if input > 0, 0 otherwise. output = max(input, 0). Mimics the way how biological neurons are triggered! A picture of different numbers and their output after ReLU."
a54b76ad-3894-4f34-844e-2f4e4897f49d,train,past,elementary school,u26,10,group 3,post test,5,14,0,C,B,What does the convolution layer do? <please select the best answer> A. It condenses the output of small regions into a single output B. It slides through the images and sums up the products of numbers C. It mimics the way neurons are only triggered by strong stimuli D. It tells what is in an image based on the information from hidden layers,"Convolution layer. The convolution layer is the core building block of the CNN. This layer performs a dot product (one-to-one) between two matrices (ordered numbers). One is the image, and the other is called kernel, mimicing the way human visual system works. A picture showing the computation process of convolution."
7b280624-b9c8-4469-972d-b61600614998,train,future,elementary school,u26,10,group 3,post test,10,19,1,B,B,"If the correct category of an image is “train”, which of the following will be considered as correct under the definition of top-3 error? (From the left to the right, the probability of the answer decreases.) <please select the best answer> A. [“plane”, “motorcycle”, “bird”, “snake”, “train”] B. [“plane”, “motorcycle”, “train”, “bird”, “snake”] C. [“motorcycle”, “plane”, “snake”, “train”, “bird”] D. [“motorcycle”, “plane”, “car”, “bird”, “snake”]","AlexNet: A CNN model follows previous pattern. AlexNet won the 2012 ImageNet competition, where computers should tell what is in the picture, with a top-5 error rate of 15.3%, compared to the second place top-5 error rate of 26.2%. top-5 error: predicting 5 categories and if all are wrong, it counts as an error. A picture of AlexNet architecture. A bar graph of classification error rate vs different method groups"
c55a654b-99ed-4ffc-8fc8-fbc72a852591,train,future,elementary school,u26,10,group 3,post test,7,17,1,B,B,"The table below is a small region to apply a pooling operation. What is the correct result after max pooling? The region where max pooling is to be applied: 3,9,6,2. <please select the best answer> A. 4 B. 9 C. 10 D. 6",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
b1832754-4f18-422e-bb13-d44fda0f7a94,train,past,elementary school,u25,10,group 3,post test,3,12,1,C,C,The CNN is a method can be classified as: <please select the best answer> A. Reinforcement learning B. Unsupervised learning C. Supervised learning D. Federated learning,"Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
056c9d17-03ef-4a9b-bb05-1fceecb5a8d9,train,past,elementary school,u25,10,group 3,post test,4,12,1,D,D,"To train a CNN that tells what is in a picture, what kind of pictures are needed? <please select the best answer> A. Pictures collected from the Internet without further information B. Pictures collected from the Internet with the data captured C. Images collected from the Internet with the geographic information D. Images collected from the Internet with category information","Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
2ee65d5e-4bfe-4e30-87f6-68a229ae2ebc,train,past,elementary school,u25,10,group 3,post test,1,8,1,A,A,Which of the following options comprises digital images stored in computers? <please select the best answer> A. Pixels B. Frames C. Videos,"Images are stored as pixels. When zooming in a picture real close, we find it is composed of mosaics. These small squares are pixels. We fill each pixel with color and then we get a picture! A picture showing the effect of zooming in a picture will get mosaics or pixels."
5c94dd39-7ba5-4675-a3f4-856621febb8b,train,future,elementary school,u25,10,group 3,post test,8,17,1,C,C,"The table below is a small region to apply a pooling operation. What is the correct result after an average pooling? The region where average pooling is to be applied: 3,9,6,2. <please select the best answer> A. 4 B. 5 C. 9 D. 6",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
cba9b70b-b46c-43a2-b593-c3fd5050ffc1,train,future,elementary school,u25,10,group 3,post test,9,15,1,2,2,"Recall the operations in a convolution layer. When given an image and a kernel as follows, which of the following is the correct answer for the missing value in the output from the layer? The image: [[1,1,1,1],[0,0,1,0],[0,1,0,0],[1,0,0,0]]. The kernel: [[0,1],[1,0]].The output. '_' is the missing value: [[1,1,2],[0,_,0],[2,0,0]] <please input your answer>","Convolution layer in animation and why we convolutes?Dr. Hubel and Dr. Wiesel found that some neurons fired very rapidly by watching the lines at specific angles, while other neurons responded best to the lines at different angles. The kernels (smaller matrix) are similar to the neurons: some produce larger output when given certain features like horizontal edges, while some respond to vertical edges. An animation of convolution computation."
5124d780-a563-47b7-b714-5400c5b27686,train,past,elementary school,u25,10,group 3,post test,2,9,1,D,D,"What are the three primary colors that computers use to represent other colors introduced in the lecture? <please select the best answer> A. Red, orange and yellow B. Red, green and purple C. Blue, orange and purple D. Red, green and blue","What exactly is stored in computer? Red, green and blue are three primary colors. When blend together, they can generate a full range of colors. The computer actually stores the colors of each pixel, and in our case, the value of red, green and blue. A picture showing RGB are the primary colors. A picture of a traffic sign and its corresponding pixel values representation."
701fd3bd-1ccb-4e5d-874c-a00f68eb8826,train,future,elementary school,u25,10,group 3,post test,6,16,1,C,C,"The output from a convolution layer is shown below. How many values will be changed after a ReLU layer is applied? The output from a convolution layer: 1, 7, 3, -2, -4, 5, 4, 1, 2. <please select the best answer> A. 0 B. 1 C. 2 D. 3","ReLU, a math transformation. Rectified Linear Unit. output = input if input > 0, 0 otherwise. output = max(input, 0). Mimics the way how biological neurons are triggered! A picture of different numbers and their output after ReLU."
04e55d2a-c21c-47e7-9c74-89a11c4d6683,train,past,elementary school,u25,10,group 3,post test,5,14,1,B,B,What does the convolution layer do? <please select the best answer> A. It condenses the output of small regions into a single output B. It slides through the images and sums up the products of numbers C. It mimics the way neurons are only triggered by strong stimuli D. It tells what is in an image based on the information from hidden layers,"Convolution layer. The convolution layer is the core building block of the CNN. This layer performs a dot product (one-to-one) between two matrices (ordered numbers). One is the image, and the other is called kernel, mimicing the way human visual system works. A picture showing the computation process of convolution."
5d157832-5078-41ea-aca7-bbd31669af54,train,future,elementary school,u25,10,group 3,post test,10,19,0,D,B,"If the correct category of an image is “train”, which of the following will be considered as correct under the definition of top-3 error? (From the left to the right, the probability of the answer decreases.) <please select the best answer> A. [“plane”, “motorcycle”, “bird”, “snake”, “train”] B. [“plane”, “motorcycle”, “train”, “bird”, “snake”] C. [“motorcycle”, “plane”, “snake”, “train”, “bird”] D. [“motorcycle”, “plane”, “car”, “bird”, “snake”]","AlexNet: A CNN model follows previous pattern. AlexNet won the 2012 ImageNet competition, where computers should tell what is in the picture, with a top-5 error rate of 15.3%, compared to the second place top-5 error rate of 26.2%. top-5 error: predicting 5 categories and if all are wrong, it counts as an error. A picture of AlexNet architecture. A bar graph of classification error rate vs different method groups"
157d1b32-33f6-4318-91f0-fa977cc24a01,train,future,elementary school,u25,10,group 3,post test,7,17,1,B,B,"The table below is a small region to apply a pooling operation. What is the correct result after max pooling? The region where max pooling is to be applied: 3,9,6,2. <please select the best answer> A. 4 B. 9 C. 10 D. 6",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
7b021e07-af74-4004-8fe5-03a1524d74f9,train,past,elementary school,u22,10,group 3,post test,3,12,1,C,C,The CNN is a method can be classified as: <please select the best answer> A. Reinforcement learning B. Unsupervised learning C. Supervised learning D. Federated learning,"Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
838f9d68-c8c4-41b7-aba2-f65aadd28301,train,past,elementary school,u22,10,group 3,post test,4,12,1,D,D,"To train a CNN that tells what is in a picture, what kind of pictures are needed? <please select the best answer> A. Pictures collected from the Internet without further information B. Pictures collected from the Internet with the data captured C. Images collected from the Internet with the geographic information D. Images collected from the Internet with category information","Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
c5a66af2-60a3-4c15-8c00-0a64bbe20023,train,past,elementary school,u22,10,group 3,post test,1,8,1,A,A,Which of the following options comprises digital images stored in computers? <please select the best answer> A. Pixels B. Frames C. Videos,"Images are stored as pixels. When zooming in a picture real close, we find it is composed of mosaics. These small squares are pixels. We fill each pixel with color and then we get a picture! A picture showing the effect of zooming in a picture will get mosaics or pixels."
46260361-db80-4370-bb43-da1f75ab56e4,train,future,elementary school,u22,10,group 3,post test,8,17,0,A,C,"The table below is a small region to apply a pooling operation. What is the correct result after an average pooling? The region where average pooling is to be applied: 3,9,6,2. <please select the best answer> A. 4 B. 5 C. 9 D. 6",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
bcd6012e-9452-4640-8211-b1581a794090,train,future,elementary school,u22,10,group 3,post test,9,15,0,1,2,"Recall the operations in a convolution layer. When given an image and a kernel as follows, which of the following is the correct answer for the missing value in the output from the layer? The image: [[1,1,1,1],[0,0,1,0],[0,1,0,0],[1,0,0,0]]. The kernel: [[0,1],[1,0]].The output. '_' is the missing value: [[1,1,2],[0,_,0],[2,0,0]] <please input your answer>","Convolution layer in animation and why we convolutes?Dr. Hubel and Dr. Wiesel found that some neurons fired very rapidly by watching the lines at specific angles, while other neurons responded best to the lines at different angles. The kernels (smaller matrix) are similar to the neurons: some produce larger output when given certain features like horizontal edges, while some respond to vertical edges. An animation of convolution computation."
290ec77a-faff-47c3-8365-3e4fbbb77412,train,past,elementary school,u22,10,group 3,post test,2,9,1,D,D,"What are the three primary colors that computers use to represent other colors introduced in the lecture? <please select the best answer> A. Red, orange and yellow B. Red, green and purple C. Blue, orange and purple D. Red, green and blue","What exactly is stored in computer? Red, green and blue are three primary colors. When blend together, they can generate a full range of colors. The computer actually stores the colors of each pixel, and in our case, the value of red, green and blue. A picture showing RGB are the primary colors. A picture of a traffic sign and its corresponding pixel values representation."
7d6ed615-5b55-4518-9f0a-d4f674cf3bb6,train,future,elementary school,u22,10,group 3,post test,6,16,0,D,C,"The output from a convolution layer is shown below. How many values will be changed after a ReLU layer is applied? The output from a convolution layer: 1, 7, 3, -2, -4, 5, 4, 1, 2. <please select the best answer> A. 0 B. 1 C. 2 D. 3","ReLU, a math transformation. Rectified Linear Unit. output = input if input > 0, 0 otherwise. output = max(input, 0). Mimics the way how biological neurons are triggered! A picture of different numbers and their output after ReLU."
80dc75d9-8e40-4483-a647-5e58da9e9302,train,past,elementary school,u22,10,group 3,post test,5,14,1,B,B,What does the convolution layer do? <please select the best answer> A. It condenses the output of small regions into a single output B. It slides through the images and sums up the products of numbers C. It mimics the way neurons are only triggered by strong stimuli D. It tells what is in an image based on the information from hidden layers,"Convolution layer. The convolution layer is the core building block of the CNN. This layer performs a dot product (one-to-one) between two matrices (ordered numbers). One is the image, and the other is called kernel, mimicing the way human visual system works. A picture showing the computation process of convolution."
e6be17ce-b126-4a37-8233-0c4a9841cfee,train,future,elementary school,u22,10,group 3,post test,10,19,1,B,B,"If the correct category of an image is “train”, which of the following will be considered as correct under the definition of top-3 error? (From the left to the right, the probability of the answer decreases.) <please select the best answer> A. [“plane”, “motorcycle”, “bird”, “snake”, “train”] B. [“plane”, “motorcycle”, “train”, “bird”, “snake”] C. [“motorcycle”, “plane”, “snake”, “train”, “bird”] D. [“motorcycle”, “plane”, “car”, “bird”, “snake”]","AlexNet: A CNN model follows previous pattern. AlexNet won the 2012 ImageNet competition, where computers should tell what is in the picture, with a top-5 error rate of 15.3%, compared to the second place top-5 error rate of 26.2%. top-5 error: predicting 5 categories and if all are wrong, it counts as an error. A picture of AlexNet architecture. A bar graph of classification error rate vs different method groups"
44d52c40-3a1c-4226-bb30-4088753f1fe2,train,future,elementary school,u22,10,group 3,post test,7,17,0,C,B,"The table below is a small region to apply a pooling operation. What is the correct result after max pooling? The region where max pooling is to be applied: 3,9,6,2. <please select the best answer> A. 4 B. 9 C. 10 D. 6",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
a820367b-ebe9-4579-a7d2-6228e50c4359,test,past,elementary school,u23,10,group 3,post test,3,12,1,C,C,The CNN is a method can be classified as: <please select the best answer> A. Reinforcement learning B. Unsupervised learning C. Supervised learning D. Federated learning,"Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
acad4032-1a63-40c8-aabe-9ea35319a7a3,test,past,elementary school,u23,10,group 3,post test,4,12,1,D,D,"To train a CNN that tells what is in a picture, what kind of pictures are needed? <please select the best answer> A. Pictures collected from the Internet without further information B. Pictures collected from the Internet with the data captured C. Images collected from the Internet with the geographic information D. Images collected from the Internet with category information","Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
7811499d-7dd8-448d-89f1-952922121a12,test,past,elementary school,u23,10,group 3,post test,1,8,0,B,A,Which of the following options comprises digital images stored in computers? <please select the best answer> A. Pixels B. Frames C. Videos,"Images are stored as pixels. When zooming in a picture real close, we find it is composed of mosaics. These small squares are pixels. We fill each pixel with color and then we get a picture! A picture showing the effect of zooming in a picture will get mosaics or pixels."
9e54f083-1680-4f0f-ba66-fbd8f9103f22,test,future,elementary school,u23,10,group 3,post test,8,17,1,C,C,"The table below is a small region to apply a pooling operation. What is the correct result after an average pooling? The region where average pooling is to be applied: 3,9,6,2. <please select the best answer> A. 4 B. 5 C. 9 D. 6",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
23b905c8-2d6b-46d3-8b38-b56df22bcd37,test,future,elementary school,u23,10,group 3,post test,9,15,1,2,2,"Recall the operations in a convolution layer. When given an image and a kernel as follows, which of the following is the correct answer for the missing value in the output from the layer? The image: [[1,1,1,1],[0,0,1,0],[0,1,0,0],[1,0,0,0]]. The kernel: [[0,1],[1,0]].The output. '_' is the missing value: [[1,1,2],[0,_,0],[2,0,0]] <please input your answer>","Convolution layer in animation and why we convolutes?Dr. Hubel and Dr. Wiesel found that some neurons fired very rapidly by watching the lines at specific angles, while other neurons responded best to the lines at different angles. The kernels (smaller matrix) are similar to the neurons: some produce larger output when given certain features like horizontal edges, while some respond to vertical edges. An animation of convolution computation."
4bccb3f0-b0a6-4641-9b7c-cdbe7857b5e6,test,past,elementary school,u23,10,group 3,post test,2,9,1,D,D,"What are the three primary colors that computers use to represent other colors introduced in the lecture? <please select the best answer> A. Red, orange and yellow B. Red, green and purple C. Blue, orange and purple D. Red, green and blue","What exactly is stored in computer? Red, green and blue are three primary colors. When blend together, they can generate a full range of colors. The computer actually stores the colors of each pixel, and in our case, the value of red, green and blue. A picture showing RGB are the primary colors. A picture of a traffic sign and its corresponding pixel values representation."
13808887-2034-421a-9832-ade685111d20,test,future,elementary school,u23,10,group 3,post test,6,16,1,C,C,"The output from a convolution layer is shown below. How many values will be changed after a ReLU layer is applied? The output from a convolution layer: 1, 7, 3, -2, -4, 5, 4, 1, 2. <please select the best answer> A. 0 B. 1 C. 2 D. 3","ReLU, a math transformation. Rectified Linear Unit. output = input if input > 0, 0 otherwise. output = max(input, 0). Mimics the way how biological neurons are triggered! A picture of different numbers and their output after ReLU."
ff2f3350-46f1-497e-bac6-955719e6daf4,test,past,elementary school,u23,10,group 3,post test,5,14,1,B,B,What does the convolution layer do? <please select the best answer> A. It condenses the output of small regions into a single output B. It slides through the images and sums up the products of numbers C. It mimics the way neurons are only triggered by strong stimuli D. It tells what is in an image based on the information from hidden layers,"Convolution layer. The convolution layer is the core building block of the CNN. This layer performs a dot product (one-to-one) between two matrices (ordered numbers). One is the image, and the other is called kernel, mimicing the way human visual system works. A picture showing the computation process of convolution."
33b51e9b-6d4c-469c-8f1a-93bb44681f95,test,future,elementary school,u23,10,group 3,post test,10,19,1,B,B,"If the correct category of an image is “train”, which of the following will be considered as correct under the definition of top-3 error? (From the left to the right, the probability of the answer decreases.) <please select the best answer> A. [“plane”, “motorcycle”, “bird”, “snake”, “train”] B. [“plane”, “motorcycle”, “train”, “bird”, “snake”] C. [“motorcycle”, “plane”, “snake”, “train”, “bird”] D. [“motorcycle”, “plane”, “car”, “bird”, “snake”]","AlexNet: A CNN model follows previous pattern. AlexNet won the 2012 ImageNet competition, where computers should tell what is in the picture, with a top-5 error rate of 15.3%, compared to the second place top-5 error rate of 26.2%. top-5 error: predicting 5 categories and if all are wrong, it counts as an error. A picture of AlexNet architecture. A bar graph of classification error rate vs different method groups"
755b6cd5-fb7e-4da5-ad86-e5035e23a0f4,test,future,elementary school,u23,10,group 3,post test,7,17,1,B,B,"The table below is a small region to apply a pooling operation. What is the correct result after max pooling? The region where max pooling is to be applied: 3,9,6,2. <please select the best answer> A. 4 B. 9 C. 10 D. 6",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
92cf9eca-2dc2-42e1-ab94-968ed76e96f1,test,past,elementary school,u24,10,group 3,post test,3,12,1,C,C,The CNN is a method can be classified as: <please select the best answer> A. Reinforcement learning B. Unsupervised learning C. Supervised learning D. Federated learning,"Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
9b0a037c-e377-48d2-8e5e-da874585292a,test,past,elementary school,u24,10,group 3,post test,4,12,1,D,D,"To train a CNN that tells what is in a picture, what kind of pictures are needed? <please select the best answer> A. Pictures collected from the Internet without further information B. Pictures collected from the Internet with the data captured C. Images collected from the Internet with the geographic information D. Images collected from the Internet with category information","Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
1eb2008b-cef1-45bb-a1c6-28ef1dd461ce,test,past,elementary school,u24,10,group 3,post test,1,8,1,A,A,Which of the following options comprises digital images stored in computers? <please select the best answer> A. Pixels B. Frames C. Videos,"Images are stored as pixels. When zooming in a picture real close, we find it is composed of mosaics. These small squares are pixels. We fill each pixel with color and then we get a picture! A picture showing the effect of zooming in a picture will get mosaics or pixels."
ba55d86b-1f15-426f-9351-ed7144db5016,test,future,elementary school,u24,10,group 3,post test,8,17,1,C,C,"The table below is a small region to apply a pooling operation. What is the correct result after an average pooling? The region where average pooling is to be applied: 3,9,6,2. <please select the best answer> A. 4 B. 5 C. 9 D. 6",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
15a612e1-7e54-4b9e-b76e-22339754c300,test,future,elementary school,u24,10,group 3,post test,9,15,1,2,2,"Recall the operations in a convolution layer. When given an image and a kernel as follows, which of the following is the correct answer for the missing value in the output from the layer? The image: [[1,1,1,1],[0,0,1,0],[0,1,0,0],[1,0,0,0]]. The kernel: [[0,1],[1,0]].The output. '_' is the missing value: [[1,1,2],[0,_,0],[2,0,0]] <please input your answer>","Convolution layer in animation and why we convolutes?Dr. Hubel and Dr. Wiesel found that some neurons fired very rapidly by watching the lines at specific angles, while other neurons responded best to the lines at different angles. The kernels (smaller matrix) are similar to the neurons: some produce larger output when given certain features like horizontal edges, while some respond to vertical edges. An animation of convolution computation."
59ef9c26-a615-4108-8b05-f50ccba1b812,test,past,elementary school,u24,10,group 3,post test,2,9,1,D,D,"What are the three primary colors that computers use to represent other colors introduced in the lecture? <please select the best answer> A. Red, orange and yellow B. Red, green and purple C. Blue, orange and purple D. Red, green and blue","What exactly is stored in computer? Red, green and blue are three primary colors. When blend together, they can generate a full range of colors. The computer actually stores the colors of each pixel, and in our case, the value of red, green and blue. A picture showing RGB are the primary colors. A picture of a traffic sign and its corresponding pixel values representation."
66ed3919-6daf-4705-bede-813e923e6351,test,future,elementary school,u24,10,group 3,post test,6,16,1,C,C,"The output from a convolution layer is shown below. How many values will be changed after a ReLU layer is applied? The output from a convolution layer: 1, 7, 3, -2, -4, 5, 4, 1, 2. <please select the best answer> A. 0 B. 1 C. 2 D. 3","ReLU, a math transformation. Rectified Linear Unit. output = input if input > 0, 0 otherwise. output = max(input, 0). Mimics the way how biological neurons are triggered! A picture of different numbers and their output after ReLU."
9cad201f-05c7-49a8-bc82-d7cc4fcaf132,test,past,elementary school,u24,10,group 3,post test,5,14,1,B,B,What does the convolution layer do? <please select the best answer> A. It condenses the output of small regions into a single output B. It slides through the images and sums up the products of numbers C. It mimics the way neurons are only triggered by strong stimuli D. It tells what is in an image based on the information from hidden layers,"Convolution layer. The convolution layer is the core building block of the CNN. This layer performs a dot product (one-to-one) between two matrices (ordered numbers). One is the image, and the other is called kernel, mimicing the way human visual system works. A picture showing the computation process of convolution."
ef397856-d817-49b6-861d-cee6ffd005ad,test,future,elementary school,u24,10,group 3,post test,10,19,1,B,B,"If the correct category of an image is “train”, which of the following will be considered as correct under the definition of top-3 error? (From the left to the right, the probability of the answer decreases.) <please select the best answer> A. [“plane”, “motorcycle”, “bird”, “snake”, “train”] B. [“plane”, “motorcycle”, “train”, “bird”, “snake”] C. [“motorcycle”, “plane”, “snake”, “train”, “bird”] D. [“motorcycle”, “plane”, “car”, “bird”, “snake”]","AlexNet: A CNN model follows previous pattern. AlexNet won the 2012 ImageNet competition, where computers should tell what is in the picture, with a top-5 error rate of 15.3%, compared to the second place top-5 error rate of 26.2%. top-5 error: predicting 5 categories and if all are wrong, it counts as an error. A picture of AlexNet architecture. A bar graph of classification error rate vs different method groups"
00dcb729-2f9e-4962-825c-ce21e02b93be,test,future,elementary school,u24,10,group 3,post test,7,17,1,B,B,"The table below is a small region to apply a pooling operation. What is the correct result after max pooling? The region where max pooling is to be applied: 3,9,6,2. <please select the best answer> A. 4 B. 9 C. 10 D. 6",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
0d78e3d2-f54a-485d-9b9a-a2bf53944e56,train,past,elementary school,u16,5,group 1,post test,3,10,1,Stephen Grossberg,B,Which person created Adaptive Resonance Theory 1 (ART1)? <please select the best answer> A. David Hubel B. Stephen Grossberg C. Teuvo Kohonen,"Self-Organizing Feature Map (SOFM). SOFM: an unsupervised learning ANN model. Invented by Teuvo Kohonen, a Finnish researcher in engineering. A tool for mapping complex information on a sheet. It contains a picture of Teuvo."
9939fc79-69fa-483d-8bd6-999276c29fa6,train,past,elementary school,u16,5,group 1,post test,4,4,1,False,False,"True or false: 'In the application of unsupervised learning, unsupervised learning can determine what is illegal.' <please select the best answer> True or False",Other Application Scenarios. Unusual bank users found. Some people use bank accounts to commit illegal acts. It is difficult to find out these bank users through human analysis. Unsupervised learning helps us to quickly classify behaviors. We can quickly exclude normal users and conduct in-depth analysis of abnormal behaviors in a more targeted manner.
9b4e7e79-2d1e-4226-9967-d1fada31c47d,train,past,elementary school,u16,5,group 1,post test,1,3,1,Desired output,C,What is the data given during supervised learning but not in unsupervised learning? <please select the best answer> A. Input B. Connection weight C. Desirable output,Unsupervised learning. Supervised Learning: Requires a teacher to tell the ANN the correct answer. Unsupervised Learning: Learns by examples without the correct answer. E.g. ANNs are given images of apple and images of orange without being told what the fruit is. ANN learns to group them into apples and oranges. It contains a picture of an example of unsupervised learning.
c816b2c6-a47e-4c2d-9aab-8b2dbfb87e13,train,future,elementary school,u16,5,group 1,post test,8,11,0,no clue,Similar inputs are placed in nearby locations.,How can an SOFM place similar inputs? <please input your answer>,"Self-Organizing Feature Map (SOFM). SOFM learns to create a neural map: Similar inputs are placed in nearby locations. Inputs presented more frequently occupy more areas. The more a specific type of input is seen, the more minute differences among the inputs belonging to that type are represented in the map. It contains a picture of SOFM."
428b7675-756e-4b01-aa54-93ee6fdc816f,train,future,elementary school,u16,5,group 1,post test,9,11,0,bias,The corresponding area becomes larger.,"In an SOFM, what happens to the map if one kind of input is given more frequently than others? <please input your answer>","Self-Organizing Feature Map (SOFM). SOFM learns to create a neural map: Similar inputs are placed in nearby locations. Inputs presented more frequently occupy more areas. The more a specific type of input is seen, the more minute differences among the inputs belonging to that type are represented in the map. It contains a picture of SOFM."
c2f85c79-8dc0-4c14-b2f9-c67a2b78df05,train,past,elementary school,u16,5,group 1,post test,2,7,1,Colors,A,"If the unsupervised ANNs that are given images of apples and images of oranges learn to group them into apples and oranges, which feature is useful? <please select the best answer> A. Colors B. Round C. Shiny","Features. Why this grouping is feasible? ---apples (oranges) are similar to each other. Features: Characteristics of the objects selected to make all the inputs widely different from each other. ANN has to pay attention to useful features! Useful (important): colors, textures. Unreliable: round, shiny."
ed247db6-380e-4c42-9cd4-e52f823d164f,train,future,elementary school,u16,5,group 1,post test,6,15,1,Shrink,A,"In the process of SOFM learning, how will the radius change? <please select the best answer> A. Shrink B. Expand","How an SOFM Learns. SOFM learns by being exposed to input samples. Similar inputs activate nearby neurons, the neighborhood shrinks as the network learns more samples. The inputs should be the same size. It contains a picture of SOFM."
6402e676-2634-43ef-b884-c21a6a1b6985,train,past,elementary school,u16,5,group 1,post test,5,8,1,Color;Shape,AB,"In the process of using unsupervised learning to classify pictures of bananas and pictures of apples, which of the following features do you think is/are useful? Multiple answers can be chosen. <please select the answer> A. Color B. Shape C. Ear",Features. What should good features look like? The samples have to be quite different in this feature. E.g. color (useful) round (unreliable). The feature that is highly correlated with the target sample. E.g. color (useful) ear shape (unreliable).
d647ee89-6cb1-45e8-aee4-084dfa48674e,train,future,elementary school,u16,5,group 1,post test,10,12,0,crystal,"Primary sensory area, or primary visual cortex",Please give an example of a self-organized structure. <please input your answer>,Example of Self-Organized Structure. Primary sensory area: Two-dimensional map of the body preserves the topology of the body similar to the map of an SOFM. The relative area size of each part of the body is determined by how much that part is used.
61653758-9a11-431d-8ce3-4699e2dc0eb2,train,future,elementary school,u16,5,group 1,post test,7,16,0,no,The initial neighbor size will cover the entire plane.,"In the first step of the SOFM learning, why can we set the weight to be random without affecting the result? <please input your answer>","How an SOFM Learns. Step 1: Initially set map to a random map. Step 2: Provide an input to the SOFM. In our case, a picture of orange/apple. All neurons will respond to the new input. It contains a picture of SOFM."
1643a2f6-66ec-451f-af66-bb9e165bb62d,train,past,elementary school,u8,5,group 2,post test,3,10,0,Teuvo Kohonen,B,Which person created Adaptive Resonance Theory 1 (ART1)? <please select the best answer> A. David Hubel B. Stephen Grossberg C. Teuvo Kohonen,"Self-Organizing Feature Map (SOFM). SOFM: an unsupervised learning ANN model. Invented by Teuvo Kohonen, a Finnish researcher in engineering. A tool for mapping complex information on a sheet. It contains a picture of Teuvo."
e18852d6-e8ef-41e3-9d15-042058b047d2,train,past,elementary school,u8,5,group 2,post test,4,4,1,False,False,"True or false: 'In the application of unsupervised learning, unsupervised learning can determine what is illegal.' <please select the best answer> True or False",Other Application Scenarios. Unusual bank users found. Some people use bank accounts to commit illegal acts. It is difficult to find out these bank users through human analysis. Unsupervised learning helps us to quickly classify behaviors. We can quickly exclude normal users and conduct in-depth analysis of abnormal behaviors in a more targeted manner.
9f7e9825-a94c-4300-bf7d-a6b477b2f108,train,past,elementary school,u8,5,group 2,post test,1,3,1,Desired output,C,What is the data given during supervised learning but not in unsupervised learning? <please select the best answer> A. Input B. Connection weight C. Desirable output,Unsupervised learning. Supervised Learning: Requires a teacher to tell the ANN the correct answer. Unsupervised Learning: Learns by examples without the correct answer. E.g. ANNs are given images of apple and images of orange without being told what the fruit is. ANN learns to group them into apples and oranges. It contains a picture of an example of unsupervised learning.
6ce3b2c6-be59-4dd8-80a7-55c389e09f7a,train,future,elementary school,u8,5,group 2,post test,8,11,0,the map can grow that area ,Similar inputs are placed in nearby locations.,How can an SOFM place similar inputs? <please input your answer>,"Self-Organizing Feature Map (SOFM). SOFM learns to create a neural map: Similar inputs are placed in nearby locations. Inputs presented more frequently occupy more areas. The more a specific type of input is seen, the more minute differences among the inputs belonging to that type are represented in the map. It contains a picture of SOFM."
380d6cae-9294-46fc-a3af-855bbe998c5a,train,future,elementary school,u8,5,group 2,post test,9,11,0,the area grows,The corresponding area becomes larger.,"In an SOFM, what happens to the map if one kind of input is given more frequently than others? <please input your answer>","Self-Organizing Feature Map (SOFM). SOFM learns to create a neural map: Similar inputs are placed in nearby locations. Inputs presented more frequently occupy more areas. The more a specific type of input is seen, the more minute differences among the inputs belonging to that type are represented in the map. It contains a picture of SOFM."
ccc1df4f-1c56-483d-980c-2d7683c1fdfe,train,past,elementary school,u8,5,group 2,post test,2,7,1,Colors,A,"If the unsupervised ANNs that are given images of apples and images of oranges learn to group them into apples and oranges, which feature is useful? <please select the best answer> A. Colors B. Round C. Shiny","Features. Why this grouping is feasible? ---apples (oranges) are similar to each other. Features: Characteristics of the objects selected to make all the inputs widely different from each other. ANN has to pay attention to useful features! Useful (important): colors, textures. Unreliable: round, shiny."
5257b551-fcbe-4aea-9431-8dfa5474937a,train,future,elementary school,u8,5,group 2,post test,6,15,1,Shrink,A,"In the process of SOFM learning, how will the radius change? <please select the best answer> A. Shrink B. Expand","How an SOFM Learns. SOFM learns by being exposed to input samples. Similar inputs activate nearby neurons, the neighborhood shrinks as the network learns more samples. The inputs should be the same size. It contains a picture of SOFM."
c80e054c-973b-4097-81f6-30c791196195,train,past,elementary school,u8,5,group 2,post test,5,8,1,Color;Shape,AB,"In the process of using unsupervised learning to classify pictures of bananas and pictures of apples, which of the following features do you think is/are useful? Multiple answers can be chosen. <please select the answer> A. Color B. Shape C. Ear",Features. What should good features look like? The samples have to be quite different in this feature. E.g. color (useful) round (unreliable). The feature that is highly correlated with the target sample. E.g. color (useful) ear shape (unreliable).
f75afc17-39ef-4c34-80d5-d97302bc29ff,train,future,elementary school,u8,5,group 2,post test,10,12,0,the brain,"Primary sensory area, or primary visual cortex",Please give an example of a self-organized structure. <please input your answer>,Example of Self-Organized Structure. Primary sensory area: Two-dimensional map of the body preserves the topology of the body similar to the map of an SOFM. The relative area size of each part of the body is determined by how much that part is used.
f48fa8b3-fdab-415e-b85e-20a45e717914,train,future,elementary school,u8,5,group 2,post test,7,16,0, so it can learn the results and adjust,The initial neighbor size will cover the entire plane.,"In the first step of the SOFM learning, why can we set the weight to be random without affecting the result? <please input your answer>","How an SOFM Learns. Step 1: Initially set map to a random map. Step 2: Provide an input to the SOFM. In our case, a picture of orange/apple. All neurons will respond to the new input. It contains a picture of SOFM."
d60a204c-c37d-40b8-95df-91e240eec505,train,past,elementary school,u17,5,group 3,post test,4,4,1,False,False,"True or false: 'In the application of unsupervised learning, unsupervised learning can determine what is illegal.' <please select the best answer> True or False",Other Application Scenarios. Unusual bank users found. Some people use bank accounts to commit illegal acts. It is difficult to find out these bank users through human analysis. Unsupervised learning helps us to quickly classify behaviors. We can quickly exclude normal users and conduct in-depth analysis of abnormal behaviors in a more targeted manner.
21be86f6-beee-4d41-a94a-e4307e2acb76,train,past,elementary school,u17,5,group 3,post test,1,3,1,Desired output,C,What is the data given during supervised learning but not in unsupervised learning? <please select the best answer> A. Input B. Connection weight C. Desirable output,Unsupervised learning. Supervised Learning: Requires a teacher to tell the ANN the correct answer. Unsupervised Learning: Learns by examples without the correct answer. E.g. ANNs are given images of apple and images of orange without being told what the fruit is. ANN learns to group them into apples and oranges. It contains a picture of an example of unsupervised learning.
cfa606aa-f67a-447a-9a69-26ecb3025a65,train,future,elementary school,u17,5,group 3,post test,8,11,0, Images of similar objects are placed together,Similar inputs are placed in nearby locations.,How can an SOFM place similar inputs? <please input your answer>,"Self-Organizing Feature Map (SOFM). SOFM learns to create a neural map: Similar inputs are placed in nearby locations. Inputs presented more frequently occupy more areas. The more a specific type of input is seen, the more minute differences among the inputs belonging to that type are represented in the map. It contains a picture of SOFM."
e11417bd-7e0f-4439-850e-029b1f056ccf,train,future,elementary school,u17,5,group 3,post test,9,11,0,There would be a larger amount of one object on the map then the other,The corresponding area becomes larger.,"In an SOFM, what happens to the map if one kind of input is given more frequently than others? <please input your answer>","Self-Organizing Feature Map (SOFM). SOFM learns to create a neural map: Similar inputs are placed in nearby locations. Inputs presented more frequently occupy more areas. The more a specific type of input is seen, the more minute differences among the inputs belonging to that type are represented in the map. It contains a picture of SOFM."
270cd3a6-7e9c-49d9-bf88-8537899bb7b7,train,past,elementary school,u17,5,group 3,post test,2,7,1,Colors,A,"If the unsupervised ANNs that are given images of apples and images of oranges learn to group them into apples and oranges, which feature is useful? <please select the best answer> A. Colors B. Round C. Shiny","Features. Why this grouping is feasible? ---apples (oranges) are similar to each other. Features: Characteristics of the objects selected to make all the inputs widely different from each other. ANN has to pay attention to useful features! Useful (important): colors, textures. Unreliable: round, shiny."
990a62e5-8685-4412-b273-249df11e4a11,train,future,elementary school,u17,5,group 3,post test,6,15,1,Shrink,A,"In the process of SOFM learning, how will the radius change? <please select the best answer> A. Shrink B. Expand","How an SOFM Learns. SOFM learns by being exposed to input samples. Similar inputs activate nearby neurons, the neighborhood shrinks as the network learns more samples. The inputs should be the same size. It contains a picture of SOFM."
0339b8bb-d2d4-46e2-8af7-201f1c13d964,train,past,elementary school,u17,5,group 3,post test,5,8,1,Color;Shape,AB,"In the process of using unsupervised learning to classify pictures of bananas and pictures of apples, which of the following features do you think is/are useful? Multiple answers can be chosen. <please select the answer> A. Color B. Shape C. Ear",Features. What should good features look like? The samples have to be quite different in this feature. E.g. color (useful) round (unreliable). The feature that is highly correlated with the target sample. E.g. color (useful) ear shape (unreliable).
16be76ad-1c22-4dda-83e3-85b1af955a51,train,future,elementary school,u17,5,group 3,post test,10,12,0,neural circuits,"Primary sensory area, or primary visual cortex",Please give an example of a self-organized structure. <please input your answer>,Example of Self-Organized Structure. Primary sensory area: Two-dimensional map of the body preserves the topology of the body similar to the map of an SOFM. The relative area size of each part of the body is determined by how much that part is used.
85f4d11a-a5f1-4eab-94d3-e152cc887083,train,future,elementary school,u17,5,group 3,post test,7,16,0,Because the weight doesn't change the output,The initial neighbor size will cover the entire plane.,"In the first step of the SOFM learning, why can we set the weight to be random without affecting the result? <please input your answer>","How an SOFM Learns. Step 1: Initially set map to a random map. Step 2: Provide an input to the SOFM. In our case, a picture of orange/apple. All neurons will respond to the new input. It contains a picture of SOFM."
26cfb127-bf10-49f9-9e9d-89a3e716c5eb,test,past,elementary school,u11,5,group 3,post test,4,4,0,True,False,"True or false: 'In the application of unsupervised learning, unsupervised learning can determine what is illegal.' <please select the best answer> True or False",Other Application Scenarios. Unusual bank users found. Some people use bank accounts to commit illegal acts. It is difficult to find out these bank users through human analysis. Unsupervised learning helps us to quickly classify behaviors. We can quickly exclude normal users and conduct in-depth analysis of abnormal behaviors in a more targeted manner.
02875264-a4a8-4194-8f59-0ecc3dfa012d,test,past,elementary school,u11,5,group 3,post test,1,3,0,Connection weight,C,What is the data given during supervised learning but not in unsupervised learning? <please select the best answer> A. Input B. Connection weight C. Desirable output,Unsupervised learning. Supervised Learning: Requires a teacher to tell the ANN the correct answer. Unsupervised Learning: Learns by examples without the correct answer. E.g. ANNs are given images of apple and images of orange without being told what the fruit is. ANN learns to group them into apples and oranges. It contains a picture of an example of unsupervised learning.
1dcbef26-c785-43ce-9ef5-8d8c4bf4fd47,test,future,elementary school,u11,5,group 3,post test,8,11,0, ,Similar inputs are placed in nearby locations.,How can an SOFM place similar inputs? <please input your answer>,"Self-Organizing Feature Map (SOFM). SOFM learns to create a neural map: Similar inputs are placed in nearby locations. Inputs presented more frequently occupy more areas. The more a specific type of input is seen, the more minute differences among the inputs belonging to that type are represented in the map. It contains a picture of SOFM."
272e855c-f519-4a26-abf0-4de8061a8227,test,future,elementary school,u11,5,group 3,post test,9,11,0, ,The corresponding area becomes larger.,"In an SOFM, what happens to the map if one kind of input is given more frequently than others? <please input your answer>","Self-Organizing Feature Map (SOFM). SOFM learns to create a neural map: Similar inputs are placed in nearby locations. Inputs presented more frequently occupy more areas. The more a specific type of input is seen, the more minute differences among the inputs belonging to that type are represented in the map. It contains a picture of SOFM."
34009841-8384-4e66-8a29-0ad8ce7a847b,test,past,elementary school,u11,5,group 3,post test,2,7,1,Colors,A,"If the unsupervised ANNs that are given images of apples and images of oranges learn to group them into apples and oranges, which feature is useful? <please select the best answer> A. Colors B. Round C. Shiny","Features. Why this grouping is feasible? ---apples (oranges) are similar to each other. Features: Characteristics of the objects selected to make all the inputs widely different from each other. ANN has to pay attention to useful features! Useful (important): colors, textures. Unreliable: round, shiny."
16b4b8fd-0d58-489c-adaa-ce2d851f9651,test,future,elementary school,u11,5,group 3,post test,6,15,1,Shrink,A,"In the process of SOFM learning, how will the radius change? <please select the best answer> A. Shrink B. Expand","How an SOFM Learns. SOFM learns by being exposed to input samples. Similar inputs activate nearby neurons, the neighborhood shrinks as the network learns more samples. The inputs should be the same size. It contains a picture of SOFM."
fd9e4f26-8c1d-42cf-97ec-81a46a0b6b4c,test,past,elementary school,u11,5,group 3,post test,5,8,1,Color;Shape,AB,"In the process of using unsupervised learning to classify pictures of bananas and pictures of apples, which of the following features do you think is/are useful? Multiple answers can be chosen. <please select the answer> A. Color B. Shape C. Ear",Features. What should good features look like? The samples have to be quite different in this feature. E.g. color (useful) round (unreliable). The feature that is highly correlated with the target sample. E.g. color (useful) ear shape (unreliable).
1a8eeb3d-c93f-4eb2-8760-923194af66ad,test,future,elementary school,u11,5,group 3,post test,10,12,0, ,"Primary sensory area, or primary visual cortex",Please give an example of a self-organized structure. <please input your answer>,Example of Self-Organized Structure. Primary sensory area: Two-dimensional map of the body preserves the topology of the body similar to the map of an SOFM. The relative area size of each part of the body is determined by how much that part is used.
430de950-bf7a-4260-bd4c-5cb6649d9988,test,future,elementary school,u11,5,group 3,post test,7,16,0, ,The initial neighbor size will cover the entire plane.,"In the first step of the SOFM learning, why can we set the weight to be random without affecting the result? <please input your answer>","How an SOFM Learns. Step 1: Initially set map to a random map. Step 2: Provide an input to the SOFM. In our case, a picture of orange/apple. All neurons will respond to the new input. It contains a picture of SOFM."
28a4cb4a-b474-4038-ae7e-024b5dadb923,train,past,elementary school,u12,5,group 3,post test,4,4,0,True,False,"True or false: 'In the application of unsupervised learning, unsupervised learning can determine what is illegal.' <please select the best answer> True or False",Other Application Scenarios. Unusual bank users found. Some people use bank accounts to commit illegal acts. It is difficult to find out these bank users through human analysis. Unsupervised learning helps us to quickly classify behaviors. We can quickly exclude normal users and conduct in-depth analysis of abnormal behaviors in a more targeted manner.
6cb52199-76fd-4f09-85ec-f4747872a145,train,past,elementary school,u12,5,group 3,post test,1,3,0,Connection weight,C,What is the data given during supervised learning but not in unsupervised learning? <please select the best answer> A. Input B. Connection weight C. Desirable output,Unsupervised learning. Supervised Learning: Requires a teacher to tell the ANN the correct answer. Unsupervised Learning: Learns by examples without the correct answer. E.g. ANNs are given images of apple and images of orange without being told what the fruit is. ANN learns to group them into apples and oranges. It contains a picture of an example of unsupervised learning.
bbb1222f-c155-494a-9e36-0b23970adbf5,train,future,elementary school,u12,5,group 3,post test,8,11,0, ,Similar inputs are placed in nearby locations.,How can an SOFM place similar inputs? <please input your answer>,"Self-Organizing Feature Map (SOFM). SOFM learns to create a neural map: Similar inputs are placed in nearby locations. Inputs presented more frequently occupy more areas. The more a specific type of input is seen, the more minute differences among the inputs belonging to that type are represented in the map. It contains a picture of SOFM."
3a0f9b6b-a613-427e-bca3-0943572961b3,train,future,elementary school,u12,5,group 3,post test,9,11,0, ,The corresponding area becomes larger.,"In an SOFM, what happens to the map if one kind of input is given more frequently than others? <please input your answer>","Self-Organizing Feature Map (SOFM). SOFM learns to create a neural map: Similar inputs are placed in nearby locations. Inputs presented more frequently occupy more areas. The more a specific type of input is seen, the more minute differences among the inputs belonging to that type are represented in the map. It contains a picture of SOFM."
62e8476d-7cc1-430d-9321-90458e6fb906,train,past,elementary school,u12,5,group 3,post test,2,7,1,Colors,A,"If the unsupervised ANNs that are given images of apples and images of oranges learn to group them into apples and oranges, which feature is useful? <please select the best answer> A. Colors B. Round C. Shiny","Features. Why this grouping is feasible? ---apples (oranges) are similar to each other. Features: Characteristics of the objects selected to make all the inputs widely different from each other. ANN has to pay attention to useful features! Useful (important): colors, textures. Unreliable: round, shiny."
d83b95df-fea7-48c4-b9d5-a6f372645950,train,future,elementary school,u12,5,group 3,post test,6,15,0,Expand,A,"In the process of SOFM learning, how will the radius change? <please select the best answer> A. Shrink B. Expand","How an SOFM Learns. SOFM learns by being exposed to input samples. Similar inputs activate nearby neurons, the neighborhood shrinks as the network learns more samples. The inputs should be the same size. It contains a picture of SOFM."
8f66f7fd-4a15-40fa-8929-6bf6512bd41f,train,past,elementary school,u12,5,group 3,post test,5,8,1,Color;Shape,AB,"In the process of using unsupervised learning to classify pictures of bananas and pictures of apples, which of the following features do you think is/are useful? Multiple answers can be chosen. <please select the answer> A. Color B. Shape C. Ear",Features. What should good features look like? The samples have to be quite different in this feature. E.g. color (useful) round (unreliable). The feature that is highly correlated with the target sample. E.g. color (useful) ear shape (unreliable).
f8fb4d8b-0d20-47d0-bc3a-965714b2877b,train,future,elementary school,u12,5,group 3,post test,10,12,0, ,"Primary sensory area, or primary visual cortex",Please give an example of a self-organized structure. <please input your answer>,Example of Self-Organized Structure. Primary sensory area: Two-dimensional map of the body preserves the topology of the body similar to the map of an SOFM. The relative area size of each part of the body is determined by how much that part is used.
55f2e942-ba7e-4848-8f3d-afcf3233ef73,train,future,elementary school,u12,5,group 3,post test,7,16,0, ,The initial neighbor size will cover the entire plane.,"In the first step of the SOFM learning, why can we set the weight to be random without affecting the result? <please input your answer>","How an SOFM Learns. Step 1: Initially set map to a random map. Step 2: Provide an input to the SOFM. In our case, a picture of orange/apple. All neurons will respond to the new input. It contains a picture of SOFM."
cee4db3b-4688-45b5-94a0-6502358d492d,train,past,elementary school,u22,5,group 3,post test,4,4,0,True,False,"True or false: 'In the application of unsupervised learning, unsupervised learning can determine what is illegal.' <please select the best answer> True or False",Other Application Scenarios. Unusual bank users found. Some people use bank accounts to commit illegal acts. It is difficult to find out these bank users through human analysis. Unsupervised learning helps us to quickly classify behaviors. We can quickly exclude normal users and conduct in-depth analysis of abnormal behaviors in a more targeted manner.
dd88f373-49bf-4dfd-91a0-779f46619022,train,past,elementary school,u22,5,group 3,post test,1,3,0,Connection weight,C,What is the data given during supervised learning but not in unsupervised learning? <please select the best answer> A. Input B. Connection weight C. Desirable output,Unsupervised learning. Supervised Learning: Requires a teacher to tell the ANN the correct answer. Unsupervised Learning: Learns by examples without the correct answer. E.g. ANNs are given images of apple and images of orange without being told what the fruit is. ANN learns to group them into apples and oranges. It contains a picture of an example of unsupervised learning.
cd5ed214-5633-432c-aa63-9aec12acd5fc,train,future,elementary school,u22,5,group 3,post test,8,11,0,i dont know,Similar inputs are placed in nearby locations.,How can an SOFM place similar inputs? <please input your answer>,"Self-Organizing Feature Map (SOFM). SOFM learns to create a neural map: Similar inputs are placed in nearby locations. Inputs presented more frequently occupy more areas. The more a specific type of input is seen, the more minute differences among the inputs belonging to that type are represented in the map. It contains a picture of SOFM."
61169757-5419-4b88-b926-163ceefbda4f,train,future,elementary school,u22,5,group 3,post test,9,11,0,expand,The corresponding area becomes larger.,"In an SOFM, what happens to the map if one kind of input is given more frequently than others? <please input your answer>","Self-Organizing Feature Map (SOFM). SOFM learns to create a neural map: Similar inputs are placed in nearby locations. Inputs presented more frequently occupy more areas. The more a specific type of input is seen, the more minute differences among the inputs belonging to that type are represented in the map. It contains a picture of SOFM."
1705dcc4-466f-4078-95bf-a567380e9963,train,past,elementary school,u22,5,group 3,post test,2,7,0,Round,A,"If the unsupervised ANNs that are given images of apples and images of oranges learn to group them into apples and oranges, which feature is useful? <please select the best answer> A. Colors B. Round C. Shiny","Features. Why this grouping is feasible? ---apples (oranges) are similar to each other. Features: Characteristics of the objects selected to make all the inputs widely different from each other. ANN has to pay attention to useful features! Useful (important): colors, textures. Unreliable: round, shiny."
eb91dd28-c683-4087-aa7e-bcaa3e1c1201,train,future,elementary school,u22,5,group 3,post test,6,15,0,Expand,A,"In the process of SOFM learning, how will the radius change? <please select the best answer> A. Shrink B. Expand","How an SOFM Learns. SOFM learns by being exposed to input samples. Similar inputs activate nearby neurons, the neighborhood shrinks as the network learns more samples. The inputs should be the same size. It contains a picture of SOFM."
1ab9f1fb-03a0-4bd6-a08b-2b227c998e7b,train,past,elementary school,u22,5,group 3,post test,5,8,1,Color;Shape,AB,"In the process of using unsupervised learning to classify pictures of bananas and pictures of apples, which of the following features do you think is/are useful? Multiple answers can be chosen. <please select the answer> A. Color B. Shape C. Ear",Features. What should good features look like? The samples have to be quite different in this feature. E.g. color (useful) round (unreliable). The feature that is highly correlated with the target sample. E.g. color (useful) ear shape (unreliable).
b345f115-c895-4643-9a60-436fbce24c55,train,future,elementary school,u22,5,group 3,post test,10,12,0,growing,"Primary sensory area, or primary visual cortex",Please give an example of a self-organized structure. <please input your answer>,Example of Self-Organized Structure. Primary sensory area: Two-dimensional map of the body preserves the topology of the body similar to the map of an SOFM. The relative area size of each part of the body is determined by how much that part is used.
707ada6b-a20b-42b0-8e82-03123e1038a8,train,future,elementary school,u22,5,group 3,post test,7,16,0,I dont know,The initial neighbor size will cover the entire plane.,"In the first step of the SOFM learning, why can we set the weight to be random without affecting the result? <please input your answer>","How an SOFM Learns. Step 1: Initially set map to a random map. Step 2: Provide an input to the SOFM. In our case, a picture of orange/apple. All neurons will respond to the new input. It contains a picture of SOFM."
54cb5967-27de-442b-8381-6af0b06d211e,train,past,elementary school,u15,5,group 3,post test,4,4,1,False,False,"True or false: 'In the application of unsupervised learning, unsupervised learning can determine what is illegal.' <please select the best answer> True or False",Other Application Scenarios. Unusual bank users found. Some people use bank accounts to commit illegal acts. It is difficult to find out these bank users through human analysis. Unsupervised learning helps us to quickly classify behaviors. We can quickly exclude normal users and conduct in-depth analysis of abnormal behaviors in a more targeted manner.
052fbf7b-8114-4e0a-ab00-3e4ce17aa7c3,train,past,elementary school,u15,5,group 3,post test,1,3,1,Desired output,C,What is the data given during supervised learning but not in unsupervised learning? <please select the best answer> A. Input B. Connection weight C. Desirable output,Unsupervised learning. Supervised Learning: Requires a teacher to tell the ANN the correct answer. Unsupervised Learning: Learns by examples without the correct answer. E.g. ANNs are given images of apple and images of orange without being told what the fruit is. ANN learns to group them into apples and oranges. It contains a picture of an example of unsupervised learning.
fd4bb836-3cca-452a-b598-312ea60e5241,train,future,elementary school,u15,5,group 3,post test,8,11,0,"The input will affect all the neurons, and it will significantly affect an area.",Similar inputs are placed in nearby locations.,How can an SOFM place similar inputs? <please input your answer>,"Self-Organizing Feature Map (SOFM). SOFM learns to create a neural map: Similar inputs are placed in nearby locations. Inputs presented more frequently occupy more areas. The more a specific type of input is seen, the more minute differences among the inputs belonging to that type are represented in the map. It contains a picture of SOFM."
142eb785-8011-4c5f-8e15-21c512e7a5d5,train,future,elementary school,u15,5,group 3,post test,9,11,0,There will be a big 'neighborhood' for the input,The corresponding area becomes larger.,"In an SOFM, what happens to the map if one kind of input is given more frequently than others? <please input your answer>","Self-Organizing Feature Map (SOFM). SOFM learns to create a neural map: Similar inputs are placed in nearby locations. Inputs presented more frequently occupy more areas. The more a specific type of input is seen, the more minute differences among the inputs belonging to that type are represented in the map. It contains a picture of SOFM."
f461dabd-4dd8-472c-a47f-5e1371e2a1a1,train,past,elementary school,u15,5,group 3,post test,2,7,1,Colors,A,"If the unsupervised ANNs that are given images of apples and images of oranges learn to group them into apples and oranges, which feature is useful? <please select the best answer> A. Colors B. Round C. Shiny","Features. Why this grouping is feasible? ---apples (oranges) are similar to each other. Features: Characteristics of the objects selected to make all the inputs widely different from each other. ANN has to pay attention to useful features! Useful (important): colors, textures. Unreliable: round, shiny."
14955a8f-2302-4314-aab3-c31b42490055,train,future,elementary school,u15,5,group 3,post test,6,15,1,Shrink,A,"In the process of SOFM learning, how will the radius change? <please select the best answer> A. Shrink B. Expand","How an SOFM Learns. SOFM learns by being exposed to input samples. Similar inputs activate nearby neurons, the neighborhood shrinks as the network learns more samples. The inputs should be the same size. It contains a picture of SOFM."
178bbd0a-9424-4527-9e06-770a676c26d0,train,past,elementary school,u15,5,group 3,post test,5,8,1,Color;Shape,AB,"In the process of using unsupervised learning to classify pictures of bananas and pictures of apples, which of the following features do you think is/are useful? Multiple answers can be chosen. <please select the answer> A. Color B. Shape C. Ear",Features. What should good features look like? The samples have to be quite different in this feature. E.g. color (useful) round (unreliable). The feature that is highly correlated with the target sample. E.g. color (useful) ear shape (unreliable).
a5dab5f0-91f7-4105-b019-956387b6897d,train,future,elementary school,u15,5,group 3,post test,10,12,0,idk,"Primary sensory area, or primary visual cortex",Please give an example of a self-organized structure. <please input your answer>,Example of Self-Organized Structure. Primary sensory area: Two-dimensional map of the body preserves the topology of the body similar to the map of an SOFM. The relative area size of each part of the body is determined by how much that part is used.
fa2035cd-7d44-44ec-b0d8-1a2ceb275692,train,future,elementary school,u15,5,group 3,post test,7,16,0,idk,The initial neighbor size will cover the entire plane.,"In the first step of the SOFM learning, why can we set the weight to be random without affecting the result? <please input your answer>","How an SOFM Learns. Step 1: Initially set map to a random map. Step 2: Provide an input to the SOFM. In our case, a picture of orange/apple. All neurons will respond to the new input. It contains a picture of SOFM."
0b15d749-3196-456d-ac51-ada6ca00186c,train,past,elementary school,u16,4,group 1,post test,3,6,0,Outlook,AB,"In this form below, which features can we select to decide whether people enjoy tennis? <please select the answer> A. Outlook B. Temperature C. Humidity D. Wind; Form: table of features and tennis enjoyment",More details of a decision tree. In the prediction a certain attribute is used to make a judgment at the internal nodes of the tree. According to the judgment result which branch to enter is decided. When it reaches the leaf node the classification result is obtained. It contains a picture of the decision tree.
456b445c-2963-4ab7-8408-93d6697730c0,train,past,elementary school,u16,4,group 1,post test,4,13,0,forgot,Label x with the label of the closest example to x,"In the I-Nearest-Neighbor method, how should we classify a new example? <please input your answer>",I-Nearest-Neighbor (1NN). To classify a new example x: Label x with the label of the closest example to x in the training set. Closest to red class. Euclidean Distance. It contains a picture of 1NN.
7a6b88db-d4ea-4caf-96ce-85b55ed53584,train,past,elementary school,u16,4,group 1,post test,1,3,1,characteristics,features,"What do humans use to classify objects, for instance, pictures of fruits? <please input your answer>",How do humans classify. Humans use objects’ characteristics to classify objects resulting in the label of objects.
c2062b82-a14c-4deb-997c-db44957afe38,train,past,elementary school,u16,4,group 1,post test,2,5,0,sunny no                                                                                                          strong yes,"Internal node, branch, leaf node (Internal node: Outlook, Humidity, Wind Branch: Sunny, Overcast... Leaf node: Yes, No)","The picture below shows a decision tree, please list three kinds of elements of a decision tree? And please give examples of each node type in this decision tree? Picture: decision tree of weather <please input your answer>",The structure of a decision tree. Internal node. Branch. Leaf node. It contains a picture of the structure of a decision tree.
9d272e5b-7b45-4b04-883c-2b87213781c5,train,future,elementary school,u16,4,group 1,post test,6,18,1,No,B,Does the performance of the KNN algorithm always get better as k increases? <please select the best answer> A. Yes B. No,The Effect of K. Choose best k on the validation set. (Often set k as an odd number). It contains a graph of choosing the best k.
984a1e1f-70d2-4149-ace3-6cf93b07ca0c,train,past,elementary school,u16,4,group 1,post test,5,14,1,Red,A,"In this image about the process of KNN algorithm, which cluster should Xj be classified to? <please select the best answer> A. Red B. Green C. Blue; Image: KNN algorithm graph",K-Nearest-Neighbors (KNN). x is closest to a red point. But most of the next closest points are blue. If we only consider the closest point the result won’t be accurate enough. It contains a picture of KNN.
93a14710-0395-4cfe-ae15-17a535fcad5f,train,past,elementary school,u9,4,group 2,post test,3,6,0,,AB,"In this form below, which features can we select to decide whether people enjoy tennis? <please select the answer> A. Outlook B. Temperature C. Humidity D. Wind; Form: table of features and tennis enjoyment",More details of a decision tree. In the prediction a certain attribute is used to make a judgment at the internal nodes of the tree. According to the judgment result which branch to enter is decided. When it reaches the leaf node the classification result is obtained. It contains a picture of the decision tree.
5c521961-3461-437f-b146-8ab854e7df26,train,past,elementary school,u9,4,group 2,post test,4,13,0,,Label x with the label of the closest example to x,"In the I-Nearest-Neighbor method, how should we classify a new example? <please input your answer>",I-Nearest-Neighbor (1NN). To classify a new example x: Label x with the label of the closest example to x in the training set. Closest to red class. Euclidean Distance. It contains a picture of 1NN.
1bb052a0-804a-4085-8bd6-1ec98310ed4f,train,past,elementary school,u9,4,group 2,post test,1,3,0,,features,"What do humans use to classify objects, for instance, pictures of fruits? <please input your answer>",How do humans classify. Humans use objects’ characteristics to classify objects resulting in the label of objects.
c9986f30-257e-4a8a-8344-bd336992d69c,train,past,elementary school,u9,4,group 2,post test,2,5,0,,"Internal node, branch, leaf node (Internal node: Outlook, Humidity, Wind Branch: Sunny, Overcast... Leaf node: Yes, No)","The picture below shows a decision tree, please list three kinds of elements of a decision tree? And please give examples of each node type in this decision tree? Picture: decision tree of weather <please input your answer>",The structure of a decision tree. Internal node. Branch. Leaf node. It contains a picture of the structure of a decision tree.
bf6d4fcd-dae1-4eb3-a3b6-61060d22cc24,train,future,elementary school,u9,4,group 2,post test,6,18,0,,B,Does the performance of the KNN algorithm always get better as k increases? <please select the best answer> A. Yes B. No,The Effect of K. Choose best k on the validation set. (Often set k as an odd number). It contains a graph of choosing the best k.
75f9e3c0-6fc4-4964-b788-0423e7024f4b,train,past,elementary school,u9,4,group 2,post test,5,14,0,,A,"In this image about the process of KNN algorithm, which cluster should Xj be classified to? <please select the best answer> A. Red B. Green C. Blue; Image: KNN algorithm graph",K-Nearest-Neighbors (KNN). x is closest to a red point. But most of the next closest points are blue. If we only consider the closest point the result won’t be accurate enough. It contains a picture of KNN.
f4a9077b-b949-4b41-aa33-1e121473f9e0,train,past,elementary school,u7,4,group 2,post test,3,6,0,Outlook;Temperature;Humidity;Wind,AB,"In this form below, which features can we select to decide whether people enjoy tennis? <please select the answer> A. Outlook B. Temperature C. Humidity D. Wind; Form: table of features and tennis enjoyment",More details of a decision tree. In the prediction a certain attribute is used to make a judgment at the internal nodes of the tree. According to the judgment result which branch to enter is decided. When it reaches the leaf node the classification result is obtained. It contains a picture of the decision tree.
e6a35c39-91d9-47ad-b89d-8495b747056f,train,past,elementary school,u7,4,group 2,post test,4,13,0,inn,Label x with the label of the closest example to x,"In the I-Nearest-Neighbor method, how should we classify a new example? <please input your answer>",I-Nearest-Neighbor (1NN). To classify a new example x: Label x with the label of the closest example to x in the training set. Closest to red class. Euclidean Distance. It contains a picture of 1NN.
6af19ec8-67a9-4af0-9dec-eba5ebe61267,train,past,elementary school,u7,4,group 2,post test,1,3,0,eye,features,"What do humans use to classify objects, for instance, pictures of fruits? <please input your answer>",How do humans classify. Humans use objects’ characteristics to classify objects resulting in the label of objects.
1f622b8b-0f73-481f-8cb5-ed4cf032f7db,train,past,elementary school,u7,4,group 2,post test,2,5,0,label question condition,"Internal node, branch, leaf node (Internal node: Outlook, Humidity, Wind Branch: Sunny, Overcast... Leaf node: Yes, No)","The picture below shows a decision tree, please list three kinds of elements of a decision tree? And please give examples of each node type in this decision tree? Picture: decision tree of weather <please input your answer>",The structure of a decision tree. Internal node. Branch. Leaf node. It contains a picture of the structure of a decision tree.
ed0ed5cc-378f-451d-982a-5e8f0a9b41df,train,future,elementary school,u7,4,group 2,post test,6,18,1,No,B,Does the performance of the KNN algorithm always get better as k increases? <please select the best answer> A. Yes B. No,The Effect of K. Choose best k on the validation set. (Often set k as an odd number). It contains a graph of choosing the best k.
65093a06-45f1-4a1a-b409-4fd62f550da6,train,past,elementary school,u7,4,group 2,post test,5,14,1,Red,A,"In this image about the process of KNN algorithm, which cluster should Xj be classified to? <please select the best answer> A. Red B. Green C. Blue; Image: KNN algorithm graph",K-Nearest-Neighbors (KNN). x is closest to a red point. But most of the next closest points are blue. If we only consider the closest point the result won’t be accurate enough. It contains a picture of KNN.
06082d04-ffd1-469f-8a3b-007d5dfafbfc,train,past,elementary school,u17,4,group 3,post test,3,6,0,Humidity,AB,"In this form below, which features can we select to decide whether people enjoy tennis? <please select the answer> A. Outlook B. Temperature C. Humidity D. Wind; Form: table of features and tennis enjoyment",More details of a decision tree. In the prediction a certain attribute is used to make a judgment at the internal nodes of the tree. According to the judgment result which branch to enter is decided. When it reaches the leaf node the classification result is obtained. It contains a picture of the decision tree.
31112c2a-4a23-4dd4-b0eb-9c7920459a77,train,past,elementary school,u17,4,group 3,post test,4,13,1,x nearest class,Label x with the label of the closest example to x,"In the I-Nearest-Neighbor method, how should we classify a new example? <please input your answer>",I-Nearest-Neighbor (1NN). To classify a new example x: Label x with the label of the closest example to x in the training set. Closest to red class. Euclidean Distance. It contains a picture of 1NN.
d681421e-6892-447e-b2a7-04cf956f60f0,train,past,elementary school,u17,4,group 3,post test,1,3,0,unsupervised learning,features,"What do humans use to classify objects, for instance, pictures of fruits? <please input your answer>",How do humans classify. Humans use objects’ characteristics to classify objects resulting in the label of objects.
f4974dac-62f6-4348-bcd6-717cf11bac2f,train,past,elementary school,u17,4,group 3,post test,2,5,1,"root node, leaf nodes and branches","Internal node, branch, leaf node (Internal node: Outlook, Humidity, Wind Branch: Sunny, Overcast... Leaf node: Yes, No)","The picture below shows a decision tree, please list three kinds of elements of a decision tree? And please give examples of each node type in this decision tree? Picture: decision tree of weather <please input your answer>",The structure of a decision tree. Internal node. Branch. Leaf node. It contains a picture of the structure of a decision tree.
44390aa5-e7f2-4eba-9279-d8836e3d1714,train,future,elementary school,u17,4,group 3,post test,6,18,1,No,B,Does the performance of the KNN algorithm always get better as k increases? <please select the best answer> A. Yes B. No,The Effect of K. Choose best k on the validation set. (Often set k as an odd number). It contains a graph of choosing the best k.
b63a734d-a7ae-44fa-99f2-a52e20943d42,train,past,elementary school,u17,4,group 3,post test,5,14,1,Red,A,"In this image about the process of KNN algorithm, which cluster should Xj be classified to? <please select the best answer> A. Red B. Green C. Blue; Image: KNN algorithm graph",K-Nearest-Neighbors (KNN). x is closest to a red point. But most of the next closest points are blue. If we only consider the closest point the result won’t be accurate enough. It contains a picture of KNN.
5d904a39-91b0-418d-ba28-e6aee21fcc54,test,past,elementary school,u11,4,group 3,post test,3,6,0,Outlook;Temperature;Wind,AB,"In this form below, which features can we select to decide whether people enjoy tennis? <please select the answer> A. Outlook B. Temperature C. Humidity D. Wind; Form: table of features and tennis enjoyment",More details of a decision tree. In the prediction a certain attribute is used to make a judgment at the internal nodes of the tree. According to the judgment result which branch to enter is decided. When it reaches the leaf node the classification result is obtained. It contains a picture of the decision tree.
daf4e2ac-8048-4276-93f9-88df38448b5e,test,past,elementary school,u11,4,group 3,post test,4,13,1,If it is near,Label x with the label of the closest example to x,"In the I-Nearest-Neighbor method, how should we classify a new example? <please input your answer>",I-Nearest-Neighbor (1NN). To classify a new example x: Label x with the label of the closest example to x in the training set. Closest to red class. Euclidean Distance. It contains a picture of 1NN.
285bb9ee-12fe-4e77-bca4-e497b049a583,test,past,elementary school,u11,4,group 3,post test,1,3,0,Neurons,features,"What do humans use to classify objects, for instance, pictures of fruits? <please input your answer>",How do humans classify. Humans use objects’ characteristics to classify objects resulting in the label of objects.
cdb04d33-a065-4119-bf59-9f182ff920fb,test,past,elementary school,u11,4,group 3,post test,2,5,0,???,"Internal node, branch, leaf node (Internal node: Outlook, Humidity, Wind Branch: Sunny, Overcast... Leaf node: Yes, No)","The picture below shows a decision tree, please list three kinds of elements of a decision tree? And please give examples of each node type in this decision tree? Picture: decision tree of weather <please input your answer>",The structure of a decision tree. Internal node. Branch. Leaf node. It contains a picture of the structure of a decision tree.
761d2f9d-12fb-4252-9e8c-adfc9648a72f,test,future,elementary school,u11,4,group 3,post test,6,18,0,Yes,B,Does the performance of the KNN algorithm always get better as k increases? <please select the best answer> A. Yes B. No,The Effect of K. Choose best k on the validation set. (Often set k as an odd number). It contains a graph of choosing the best k.
416038d8-21dc-4735-bb45-172bdeca5d67,test,past,elementary school,u11,4,group 3,post test,5,14,1,Red,A,"In this image about the process of KNN algorithm, which cluster should Xj be classified to? <please select the best answer> A. Red B. Green C. Blue; Image: KNN algorithm graph",K-Nearest-Neighbors (KNN). x is closest to a red point. But most of the next closest points are blue. If we only consider the closest point the result won’t be accurate enough. It contains a picture of KNN.
efc31a3c-c9d7-42c5-9684-ad88e7a08a85,train,past,elementary school,u30,4,group 3,post test,3,6,0,Outlook;Wind,AB,"In this form below, which features can we select to decide whether people enjoy tennis? <please select the answer> A. Outlook B. Temperature C. Humidity D. Wind; Form: table of features and tennis enjoyment",More details of a decision tree. In the prediction a certain attribute is used to make a judgment at the internal nodes of the tree. According to the judgment result which branch to enter is decided. When it reaches the leaf node the classification result is obtained. It contains a picture of the decision tree.
5b88c873-314a-4492-9d5e-cc603d20e9e3,train,past,elementary school,u30,4,group 3,post test,4,13,0,?,Label x with the label of the closest example to x,"In the I-Nearest-Neighbor method, how should we classify a new example? <please input your answer>",I-Nearest-Neighbor (1NN). To classify a new example x: Label x with the label of the closest example to x in the training set. Closest to red class. Euclidean Distance. It contains a picture of 1NN.
19acbaeb-1d74-400c-9728-e25df572cfd7,train,past,elementary school,u30,4,group 3,post test,1,3,0,decision tree,features,"What do humans use to classify objects, for instance, pictures of fruits? <please input your answer>",How do humans classify. Humans use objects’ characteristics to classify objects resulting in the label of objects.
e283ab22-c39f-4f84-98fc-77aa53f0c6d3,train,past,elementary school,u30,4,group 3,post test,2,5,0,?,"Internal node, branch, leaf node (Internal node: Outlook, Humidity, Wind Branch: Sunny, Overcast... Leaf node: Yes, No)","The picture below shows a decision tree, please list three kinds of elements of a decision tree? And please give examples of each node type in this decision tree? Picture: decision tree of weather <please input your answer>",The structure of a decision tree. Internal node. Branch. Leaf node. It contains a picture of the structure of a decision tree.
6d75749a-18d3-4cab-96f3-bf462f115390,train,future,elementary school,u30,4,group 3,post test,6,18,0,Yes,B,Does the performance of the KNN algorithm always get better as k increases? <please select the best answer> A. Yes B. No,The Effect of K. Choose best k on the validation set. (Often set k as an odd number). It contains a graph of choosing the best k.
29ced849-2958-4a27-a288-b700c7fb0fa8,train,past,elementary school,u30,4,group 3,post test,5,14,1,Red,A,"In this image about the process of KNN algorithm, which cluster should Xj be classified to? <please select the best answer> A. Red B. Green C. Blue; Image: KNN algorithm graph",K-Nearest-Neighbors (KNN). x is closest to a red point. But most of the next closest points are blue. If we only consider the closest point the result won’t be accurate enough. It contains a picture of KNN.
7efca6bf-cd14-4088-a1ae-26f70f870d74,train,past,elementary school,u12,4,group 3,post test,3,6,0,Outlook,AB,"In this form below, which features can we select to decide whether people enjoy tennis? <please select the answer> A. Outlook B. Temperature C. Humidity D. Wind; Form: table of features and tennis enjoyment",More details of a decision tree. In the prediction a certain attribute is used to make a judgment at the internal nodes of the tree. According to the judgment result which branch to enter is decided. When it reaches the leaf node the classification result is obtained. It contains a picture of the decision tree.
9dd51b24-9982-4608-b2ec-acc9f812c14f,train,past,elementary school,u12,4,group 3,post test,4,13,0,,Label x with the label of the closest example to x,"In the I-Nearest-Neighbor method, how should we classify a new example? <please input your answer>",I-Nearest-Neighbor (1NN). To classify a new example x: Label x with the label of the closest example to x in the training set. Closest to red class. Euclidean Distance. It contains a picture of 1NN.
949a059b-6015-4abb-8c7f-6a41da1ad319,train,past,elementary school,u12,4,group 3,post test,1,3,0,A decision tree,features,"What do humans use to classify objects, for instance, pictures of fruits? <please input your answer>",How do humans classify. Humans use objects’ characteristics to classify objects resulting in the label of objects.
60c52410-f5e3-4373-879a-4d475ddc7334,train,past,elementary school,u12,4,group 3,post test,2,5,0,"Sunny, overcast, rain","Internal node, branch, leaf node (Internal node: Outlook, Humidity, Wind Branch: Sunny, Overcast... Leaf node: Yes, No)","The picture below shows a decision tree, please list three kinds of elements of a decision tree? And please give examples of each node type in this decision tree? Picture: decision tree of weather <please input your answer>",The structure of a decision tree. Internal node. Branch. Leaf node. It contains a picture of the structure of a decision tree.
5b6dcabc-1bb3-4664-96ce-455258aae28a,train,future,elementary school,u12,4,group 3,post test,6,18,0,Yes,B,Does the performance of the KNN algorithm always get better as k increases? <please select the best answer> A. Yes B. No,The Effect of K. Choose best k on the validation set. (Often set k as an odd number). It contains a graph of choosing the best k.
3fe35e98-dd17-4fa4-b692-42e6d4f3b81b,train,past,elementary school,u12,4,group 3,post test,5,14,1,Red,A,"In this image about the process of KNN algorithm, which cluster should Xj be classified to? <please select the best answer> A. Red B. Green C. Blue; Image: KNN algorithm graph",K-Nearest-Neighbors (KNN). x is closest to a red point. But most of the next closest points are blue. If we only consider the closest point the result won’t be accurate enough. It contains a picture of KNN.
659763ef-4b15-43c8-8b8c-b4afe1ef4b9a,train,past,elementary school,u14,4,group 3,post test,3,6,0,Temperature;Humidity,AB,"In this form below, which features can we select to decide whether people enjoy tennis? <please select the answer> A. Outlook B. Temperature C. Humidity D. Wind; Form: table of features and tennis enjoyment",More details of a decision tree. In the prediction a certain attribute is used to make a judgment at the internal nodes of the tree. According to the judgment result which branch to enter is decided. When it reaches the leaf node the classification result is obtained. It contains a picture of the decision tree.
45d76f07-53e2-4a01-aa9e-854b4b6fe186,train,past,elementary school,u14,4,group 3,post test,4,13,1,which one does it match the most,Label x with the label of the closest example to x,"In the I-Nearest-Neighbor method, how should we classify a new example? <please input your answer>",I-Nearest-Neighbor (1NN). To classify a new example x: Label x with the label of the closest example to x in the training set. Closest to red class. Euclidean Distance. It contains a picture of 1NN.
b1c2c28b-1edd-4378-8ee1-c73f52f599ab,train,past,elementary school,u14,4,group 3,post test,1,3,1,"our senses, ex touch, smell, taste, look",features,"What do humans use to classify objects, for instance, pictures of fruits? <please input your answer>",How do humans classify. Humans use objects’ characteristics to classify objects resulting in the label of objects.
6538fc47-e38d-459f-a76c-f46c76be3866,train,past,elementary school,u14,4,group 3,post test,2,5,1,"input, options, output","Internal node, branch, leaf node (Internal node: Outlook, Humidity, Wind Branch: Sunny, Overcast... Leaf node: Yes, No)","The picture below shows a decision tree, please list three kinds of elements of a decision tree? And please give examples of each node type in this decision tree? Picture: decision tree of weather <please input your answer>",The structure of a decision tree. Internal node. Branch. Leaf node. It contains a picture of the structure of a decision tree.
fa37238d-6cfd-4f2b-a9d3-5786775cfd06,train,future,elementary school,u14,4,group 3,post test,6,18,1,No,B,Does the performance of the KNN algorithm always get better as k increases? <please select the best answer> A. Yes B. No,The Effect of K. Choose best k on the validation set. (Often set k as an odd number). It contains a graph of choosing the best k.
e714375b-0749-49e4-a872-c5707d72cfb3,train,past,elementary school,u14,4,group 3,post test,5,14,1,Red,A,"In this image about the process of KNN algorithm, which cluster should Xj be classified to? <please select the best answer> A. Red B. Green C. Blue; Image: KNN algorithm graph",K-Nearest-Neighbors (KNN). x is closest to a red point. But most of the next closest points are blue. If we only consider the closest point the result won’t be accurate enough. It contains a picture of KNN.
7e55089b-3d75-4c6e-a41e-747d18605a3a,train,past,elementary school,u15,4,group 3,post test,3,6,0,Outlook;Temperature;Humidity;Wind,AB,"In this form below, which features can we select to decide whether people enjoy tennis? <please select the answer> A. Outlook B. Temperature C. Humidity D. Wind; Form: table of features and tennis enjoyment",More details of a decision tree. In the prediction a certain attribute is used to make a judgment at the internal nodes of the tree. According to the judgment result which branch to enter is decided. When it reaches the leaf node the classification result is obtained. It contains a picture of the decision tree.
b5b72303-2c0b-4ec3-83c7-434dfb434524,train,past,elementary school,u15,4,group 3,post test,4,13,0,,Label x with the label of the closest example to x,"In the I-Nearest-Neighbor method, how should we classify a new example? <please input your answer>",I-Nearest-Neighbor (1NN). To classify a new example x: Label x with the label of the closest example to x in the training set. Closest to red class. Euclidean Distance. It contains a picture of 1NN.
a131368a-6df0-467e-9f0f-2b3630f5ed55,train,past,elementary school,u15,4,group 3,post test,1,3,1,Characteristics and Labels,features,"What do humans use to classify objects, for instance, pictures of fruits? <please input your answer>",How do humans classify. Humans use objects’ characteristics to classify objects resulting in the label of objects.
43ca687f-722d-40ca-9af1-a4ce17215fce,train,past,elementary school,u15,4,group 3,post test,2,5,1,Node,"Internal node, branch, leaf node (Internal node: Outlook, Humidity, Wind Branch: Sunny, Overcast... Leaf node: Yes, No)","The picture below shows a decision tree, please list three kinds of elements of a decision tree? And please give examples of each node type in this decision tree? Picture: decision tree of weather <please input your answer>",The structure of a decision tree. Internal node. Branch. Leaf node. It contains a picture of the structure of a decision tree.
f9de463b-328d-4d42-b3cf-1d36d7318ebd,train,future,elementary school,u15,4,group 3,post test,6,18,1,No,B,Does the performance of the KNN algorithm always get better as k increases? <please select the best answer> A. Yes B. No,The Effect of K. Choose best k on the validation set. (Often set k as an odd number). It contains a graph of choosing the best k.
1e98bce7-aa7a-470f-9a4c-dc3c1ca68436,train,past,elementary school,u15,4,group 3,post test,5,14,1,Red,A,"In this image about the process of KNN algorithm, which cluster should Xj be classified to? <please select the best answer> A. Red B. Green C. Blue; Image: KNN algorithm graph",K-Nearest-Neighbors (KNN). x is closest to a red point. But most of the next closest points are blue. If we only consider the closest point the result won’t be accurate enough. It contains a picture of KNN.
1d591002-4ae5-4e87-80b4-ad36c332aacb,train,past,elementary school,u31,12,group 1,post test,3,7,1,B,B,Which one of the following methods is suitable for robots that work on Mars to achieve autonomousness? <please select the best answer> A. Spike neural networks B. Q-learning C. K-nearest neighbors D. Recurrent neural networks,"Usage in dangerous situations. Situations human want to avoid: Old minefields, automobile factories, other planets... AI can make machines in these situations more autonomous and useful. A picture of Curious, a robot that was sent to Mars."
51bdb84e-c301-4d6c-87a0-fb7bdb244199,train,past,elementary school,u31,12,group 1,post test,4,8,1,We should read with caution because a fair amount of hype is often involved,We should read with caution because a fair amount of hype is often involved,What should we notice when we are faced with AI-related news? <please input your answer>,"Summary. The real-world aplication using AI have just begun, and AI technology hasn’t fully matured and been tested. AI-related news should be read with caution. A picture of a robot."
39d3f9f3-bf65-4735-ace1-2306c0ebf34c,train,past,elementary school,u31,12,group 1,post test,1,4,1,C,C,"To help biologists to understand the vast amount of data, AI can generate a knowledge graph. Which is a helpful scheme to build such knowledge? <please select the best answer> A. Reinforcement learning B. Supervised learning C. Unsupervised learning D. Few-shot learning","Medicine. finding new drugs. medical diagnoses. With the vast knowledge of paintents , and chemical sturctures sotred in databases, AI system can search for potentially effective treatments more quickly than human experts can. A video about AI usage in medicine."
558a1a3b-a89e-49e7-bd3d-ade729e9dbf0,train,future,elementary school,u31,12,group 1,post test,8,14,1,D,D,Which of the following best describes artificial general intelligence (AGI)? <please select the best answer> A. Computer programs that experience sentience or consciousness. B. Any program that is designed to solve exactly one problem. C. A computer agent with the ability to sense and the ability to act. D. An intelligent agent to learn any task that a human being can.,"Artificial general intelligence (AGI). AGI is a generic, human-like intelligence that can tackle problems by developing and applying general congnitive abilities across different areas. Many people think that the progress in AI will be made only by tackling specific problems, not by trying to advance machine intelligence in general. A picture of a robot trying to solve complex math/physics problems."
10b3359a-62a9-4740-991d-c8930c15eac9,train,future,elementary school,u31,12,group 1,post test,9,12,1,Spike neurons take as input spikes while tradition neurons take as input continuous value,Spike neurons take as input spikes while tradition neurons take as input continuous value,What is the most significant difference between spike neural networks and traditional neural networks? <please input your answer>,"Supporting hardware. Spiking neural networks: They consider the spike timings rather than just the spiking frequency, which is an important feature of biological neural networls. A biological neuron integrates the inputs and decides whether it generates a spike or not. Three images showing that."
98ea95ef-907d-4eaf-8578-973c12744313,train,past,elementary school,u31,12,group 1,post test,2,5,1,C,C,"Considering the given example, which one of the following opinions correctly describes the entity and related information? Example: SpaceX is an aerospace manufacturer and space transport services company headquartered in California. It was founded in 2002 by entrepreneur and investor Elon Musk with the goal of reducing space transportation costs and enabling the colonization of Mars. <please select the best answer> A. Entrepreneur (“Elon Musk”, “SpaceX”, “California”) B. Entrepreneur (“Elon Musk”, “California”, “2002”) C. Company (“SpaceX”, “California”, “Elon Musk”) D. Company (“SpaceX”, “Mars”, “Elon Musk”)","Natural language application. machine translation. natural language interfaces. AI systems extract knowledge from natural language texts. E.g., Q: The headquarters of BHP Billiton Limited, and the global headquarters of the combined BHP Billiton Group, are located in Melbourne, Australia. A: headquarters('“'BHP Biliton Limited', 'Melbourne, Australia') A cartoon picture showing that."
22beaad7-655b-43bf-b50e-5269b76ffe3d,train,future,elementary school,u31,12,group 1,post test,6,13,1,Qubits can represent combinations simultaneously.,Qubits can represent combinations simultaneously.,Why do quantum computers outperform existing traditional computers in problems related to a large number of combinations? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
75921465-548f-4039-9238-94ae5afbdc4b,train,past,elementary school,u31,12,group 1,post test,5,13,1,Qubit,Quantum bit/Qubit,What is the basic unit of memory in quantum computers? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
40afade8-08b9-40cb-b848-d71a3ef999a4,train,future,elementary school,u31,12,group 1,post test,10,18,1,B,B,"Which of the following descriptions about developing AI with caution is incorrect? <please select the best answer> A. Autonomous driving has safety issues related to the measurement of doing well and liability. B. With more sensitive sensors and more autonomous control, robots are sure to have personalities and consciousness at some point. C. Stephen Hawking, Elon Musk and Bill Gates have warned that AI may spell the end to human intelligence. D. We should be smart enough to use AI and wise enough to plan our future so that using AI will enrich our lives.","Ethical issues. If AI are developed with more sensitive sensors and more autonomous control, will robots, at some point, start to have personalities and consciousness? Should we worry about respecting their opinions or their will for existence? A picture of 2 robots."
1b49f222-4272-4037-9acc-655fa6b44c79,train,future,elementary school,u31,12,group 1,post test,7,10,1,We must do more research on the human brain side,We must do more research on the human brain side,What is the reason that development in brain-AI communication takes a long time? <please input your answer>,Integrate with our brains. We expect our brains will be able to communicate with AI through implanted electrodes to expand out cognitive capabilities. Development in this direction may take many years because we must do more research on the human brain side. A picture of a human brain but it's digital.
59c46f36-1b38-4e71-b2de-75af97e4ecde,test,past,elementary school,u19,12,group 1,post test,3,7,1,B,B,Which one of the following methods is suitable for robots that work on Mars to achieve autonomousness? <please select the best answer> A. Spike neural networks B. Q-learning C. K-nearest neighbors D. Recurrent neural networks,"Usage in dangerous situations. Situations human want to avoid: Old minefields, automobile factories, other planets... AI can make machines in these situations more autonomous and useful. A picture of Curious, a robot that was sent to Mars."
baed8feb-a5a5-43a1-930c-50df81104879,test,past,elementary school,u19,12,group 1,post test,4,8,1,We should read with caution because a fair amount of hype is often involved,We should read with caution because a fair amount of hype is often involved,What should we notice when we are faced with AI-related news? <please input your answer>,"Summary. The real-world aplication using AI have just begun, and AI technology hasn’t fully matured and been tested. AI-related news should be read with caution. A picture of a robot."
d38344a3-212a-4d12-98b6-f5419bdf789d,test,past,elementary school,u19,12,group 1,post test,1,4,1,C,C,"To help biologists to understand the vast amount of data, AI can generate a knowledge graph. Which is a helpful scheme to build such knowledge? <please select the best answer> A. Reinforcement learning B. Supervised learning C. Unsupervised learning D. Few-shot learning","Medicine. finding new drugs. medical diagnoses. With the vast knowledge of paintents , and chemical sturctures sotred in databases, AI system can search for potentially effective treatments more quickly than human experts can. A video about AI usage in medicine."
67ca9489-7c6d-498b-b1e3-39b558b42d20,test,future,elementary school,u19,12,group 1,post test,8,14,1,D,D,Which of the following best describes artificial general intelligence (AGI)? <please select the best answer> A. Computer programs that experience sentience or consciousness. B. Any program that is designed to solve exactly one problem. C. A computer agent with the ability to sense and the ability to act. D. An intelligent agent to learn any task that a human being can.,"Artificial general intelligence (AGI). AGI is a generic, human-like intelligence that can tackle problems by developing and applying general congnitive abilities across different areas. Many people think that the progress in AI will be made only by tackling specific problems, not by trying to advance machine intelligence in general. A picture of a robot trying to solve complex math/physics problems."
eac0b4fd-873d-4c20-8e15-b2970b2d0ffc,test,future,elementary school,u19,12,group 1,post test,9,12,1,Spike neurons take as input spikes while tradition neurons take as input continuous value,Spike neurons take as input spikes while tradition neurons take as input continuous value,What is the most significant difference between spike neural networks and traditional neural networks? <please input your answer>,"Supporting hardware. Spiking neural networks: They consider the spike timings rather than just the spiking frequency, which is an important feature of biological neural networls. A biological neuron integrates the inputs and decides whether it generates a spike or not. Three images showing that."
fe61a7e9-a626-4e17-a5e1-eec805b06667,test,past,elementary school,u19,12,group 1,post test,2,5,1,C,C,"Considering the given example, which one of the following opinions correctly describes the entity and related information? Example: SpaceX is an aerospace manufacturer and space transport services company headquartered in California. It was founded in 2002 by entrepreneur and investor Elon Musk with the goal of reducing space transportation costs and enabling the colonization of Mars. <please select the best answer> A. Entrepreneur (“Elon Musk”, “SpaceX”, “California”) B. Entrepreneur (“Elon Musk”, “California”, “2002”) C. Company (“SpaceX”, “California”, “Elon Musk”) D. Company (“SpaceX”, “Mars”, “Elon Musk”)","Natural language application. machine translation. natural language interfaces. AI systems extract knowledge from natural language texts. E.g., Q: The headquarters of BHP Billiton Limited, and the global headquarters of the combined BHP Billiton Group, are located in Melbourne, Australia. A: headquarters('“'BHP Biliton Limited', 'Melbourne, Australia') A cartoon picture showing that."
408280de-cb4d-450b-b71f-28ff70bb0c25,test,future,elementary school,u19,12,group 1,post test,6,13,1,Qubits can represent combinations simultaneously.,Qubits can represent combinations simultaneously.,Why do quantum computers outperform existing traditional computers in problems related to a large number of combinations? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
5cbab2d7-a0d8-4889-a439-b7ae1a3e1deb,test,past,elementary school,u19,12,group 1,post test,5,13,1,quantum bit,Quantum bit/Qubit,What is the basic unit of memory in quantum computers? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
300537ce-75de-48da-80d2-5936a3e1710a,test,future,elementary school,u19,12,group 1,post test,10,18,1,B,B,"Which of the following descriptions about developing AI with caution is incorrect? <please select the best answer> A. Autonomous driving has safety issues related to the measurement of doing well and liability. B. With more sensitive sensors and more autonomous control, robots are sure to have personalities and consciousness at some point. C. Stephen Hawking, Elon Musk and Bill Gates have warned that AI may spell the end to human intelligence. D. We should be smart enough to use AI and wise enough to plan our future so that using AI will enrich our lives.","Ethical issues. If AI are developed with more sensitive sensors and more autonomous control, will robots, at some point, start to have personalities and consciousness? Should we worry about respecting their opinions or their will for existence? A picture of 2 robots."
151d70b6-affe-4d48-ad62-3d3ea3936adf,test,future,elementary school,u19,12,group 1,post test,7,10,1,We must do more research on the human brain side,We must do more research on the human brain side,What is the reason that development in brain-AI communication takes a long time? <please input your answer>,Integrate with our brains. We expect our brains will be able to communicate with AI through implanted electrodes to expand out cognitive capabilities. Development in this direction may take many years because we must do more research on the human brain side. A picture of a human brain but it's digital.
ee000ed7-7aa0-4e90-a8b6-29fe27418c5c,train,past,elementary school,u7,12,group 2,post test,3,7,0,C,B,Which one of the following methods is suitable for robots that work on Mars to achieve autonomousness? <please select the best answer> A. Spike neural networks B. Q-learning C. K-nearest neighbors D. Recurrent neural networks,"Usage in dangerous situations. Situations human want to avoid: Old minefields, automobile factories, other planets... AI can make machines in these situations more autonomous and useful. A picture of Curious, a robot that was sent to Mars."
65ec94a6-5dd1-4659-9a27-b7eea3b31baa,train,past,elementary school,u7,12,group 2,post test,4,8,0,gfd,We should read with caution because a fair amount of hype is often involved,What should we notice when we are faced with AI-related news? <please input your answer>,"Summary. The real-world aplication using AI have just begun, and AI technology hasn’t fully matured and been tested. AI-related news should be read with caution. A picture of a robot."
28976942-a6c4-4395-bed7-9c9ebb9c4460,train,past,elementary school,u7,12,group 2,post test,1,4,1,C,C,"To help biologists to understand the vast amount of data, AI can generate a knowledge graph. Which is a helpful scheme to build such knowledge? <please select the best answer> A. Reinforcement learning B. Supervised learning C. Unsupervised learning D. Few-shot learning","Medicine. finding new drugs. medical diagnoses. With the vast knowledge of paintents , and chemical sturctures sotred in databases, AI system can search for potentially effective treatments more quickly than human experts can. A video about AI usage in medicine."
3d2ff94b-86b9-4246-b5cc-7c01d64a8884,train,future,elementary school,u7,12,group 2,post test,8,14,0,B,D,Which of the following best describes artificial general intelligence (AGI)? <please select the best answer> A. Computer programs that experience sentience or consciousness. B. Any program that is designed to solve exactly one problem. C. A computer agent with the ability to sense and the ability to act. D. An intelligent agent to learn any task that a human being can.,"Artificial general intelligence (AGI). AGI is a generic, human-like intelligence that can tackle problems by developing and applying general congnitive abilities across different areas. Many people think that the progress in AI will be made only by tackling specific problems, not by trying to advance machine intelligence in general. A picture of a robot trying to solve complex math/physics problems."
c9aa03fa-8286-4989-b69c-9e75b0b5971c,train,future,elementary school,u7,12,group 2,post test,9,12,0,bg,Spike neurons take as input spikes while tradition neurons take as input continuous value,What is the most significant difference between spike neural networks and traditional neural networks? <please input your answer>,"Supporting hardware. Spiking neural networks: They consider the spike timings rather than just the spiking frequency, which is an important feature of biological neural networls. A biological neuron integrates the inputs and decides whether it generates a spike or not. Three images showing that."
8774a2b3-0478-4d2a-8eef-7adb6eb8da84,train,past,elementary school,u7,12,group 2,post test,2,5,0,B,C,"Considering the given example, which one of the following opinions correctly describes the entity and related information? Example: SpaceX is an aerospace manufacturer and space transport services company headquartered in California. It was founded in 2002 by entrepreneur and investor Elon Musk with the goal of reducing space transportation costs and enabling the colonization of Mars. <please select the best answer> A. Entrepreneur (“Elon Musk”, “SpaceX”, “California”) B. Entrepreneur (“Elon Musk”, “California”, “2002”) C. Company (“SpaceX”, “California”, “Elon Musk”) D. Company (“SpaceX”, “Mars”, “Elon Musk”)","Natural language application. machine translation. natural language interfaces. AI systems extract knowledge from natural language texts. E.g., Q: The headquarters of BHP Billiton Limited, and the global headquarters of the combined BHP Billiton Group, are located in Melbourne, Australia. A: headquarters('“'BHP Biliton Limited', 'Melbourne, Australia') A cartoon picture showing that."
f91679ff-6ed3-436c-b9e8-620055744842,train,future,elementary school,u7,12,group 2,post test,6,13,0,gt,Qubits can represent combinations simultaneously.,Why do quantum computers outperform existing traditional computers in problems related to a large number of combinations? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
db5f269e-7a01-46f5-87b0-0cf8f5bd4d08,train,past,elementary school,u7,12,group 2,post test,5,13,0,gt,Quantum bit/Qubit,What is the basic unit of memory in quantum computers? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
57f001f4-032a-4007-9542-a6cee98dce1b,train,future,elementary school,u7,12,group 2,post test,10,18,1,B,B,"Which of the following descriptions about developing AI with caution is incorrect? <please select the best answer> A. Autonomous driving has safety issues related to the measurement of doing well and liability. B. With more sensitive sensors and more autonomous control, robots are sure to have personalities and consciousness at some point. C. Stephen Hawking, Elon Musk and Bill Gates have warned that AI may spell the end to human intelligence. D. We should be smart enough to use AI and wise enough to plan our future so that using AI will enrich our lives.","Ethical issues. If AI are developed with more sensitive sensors and more autonomous control, will robots, at some point, start to have personalities and consciousness? Should we worry about respecting their opinions or their will for existence? A picture of 2 robots."
7ba98502-aa19-4491-9759-e8b1e62577fb,train,future,elementary school,u7,12,group 2,post test,7,10,0,gy,We must do more research on the human brain side,What is the reason that development in brain-AI communication takes a long time? <please input your answer>,Integrate with our brains. We expect our brains will be able to communicate with AI through implanted electrodes to expand out cognitive capabilities. Development in this direction may take many years because we must do more research on the human brain side. A picture of a human brain but it's digital.
bf94666e-cc0f-4596-bdf7-4c62da22a1fb,train,past,elementary school,u21,12,group 2,post test,3,7,0,A,B,Which one of the following methods is suitable for robots that work on Mars to achieve autonomousness? <please select the best answer> A. Spike neural networks B. Q-learning C. K-nearest neighbors D. Recurrent neural networks,"Usage in dangerous situations. Situations human want to avoid: Old minefields, automobile factories, other planets... AI can make machines in these situations more autonomous and useful. A picture of Curious, a robot that was sent to Mars."
aebd545f-6e4a-4398-8c59-6dddf213d7e3,train,past,elementary school,u21,12,group 2,post test,4,8,0,is the news good or bad,We should read with caution because a fair amount of hype is often involved,What should we notice when we are faced with AI-related news? <please input your answer>,"Summary. The real-world aplication using AI have just begun, and AI technology hasn’t fully matured and been tested. AI-related news should be read with caution. A picture of a robot."
11db656e-6ab0-470a-be68-7caae730b147,train,past,elementary school,u21,12,group 2,post test,1,4,0,A,C,"To help biologists to understand the vast amount of data, AI can generate a knowledge graph. Which is a helpful scheme to build such knowledge? <please select the best answer> A. Reinforcement learning B. Supervised learning C. Unsupervised learning D. Few-shot learning","Medicine. finding new drugs. medical diagnoses. With the vast knowledge of paintents , and chemical sturctures sotred in databases, AI system can search for potentially effective treatments more quickly than human experts can. A video about AI usage in medicine."
56732fca-2194-4cd7-88d1-3d5cdac718d7,train,future,elementary school,u21,12,group 2,post test,8,14,1,D,D,Which of the following best describes artificial general intelligence (AGI)? <please select the best answer> A. Computer programs that experience sentience or consciousness. B. Any program that is designed to solve exactly one problem. C. A computer agent with the ability to sense and the ability to act. D. An intelligent agent to learn any task that a human being can.,"Artificial general intelligence (AGI). AGI is a generic, human-like intelligence that can tackle problems by developing and applying general congnitive abilities across different areas. Many people think that the progress in AI will be made only by tackling specific problems, not by trying to advance machine intelligence in general. A picture of a robot trying to solve complex math/physics problems."
f8e2cbc7-1412-4bb2-a1fb-51545085ef5c,train,future,elementary school,u21,12,group 2,post test,9,12,1,spike neural networks consider the spike timings,Spike neurons take as input spikes while tradition neurons take as input continuous value,What is the most significant difference between spike neural networks and traditional neural networks? <please input your answer>,"Supporting hardware. Spiking neural networks: They consider the spike timings rather than just the spiking frequency, which is an important feature of biological neural networls. A biological neuron integrates the inputs and decides whether it generates a spike or not. Three images showing that."
e877acb3-13e7-4f3f-b29b-b18d01f4fb24,train,past,elementary school,u21,12,group 2,post test,2,5,1,C,C,"Considering the given example, which one of the following opinions correctly describes the entity and related information? Example: SpaceX is an aerospace manufacturer and space transport services company headquartered in California. It was founded in 2002 by entrepreneur and investor Elon Musk with the goal of reducing space transportation costs and enabling the colonization of Mars. <please select the best answer> A. Entrepreneur (“Elon Musk”, “SpaceX”, “California”) B. Entrepreneur (“Elon Musk”, “California”, “2002”) C. Company (“SpaceX”, “California”, “Elon Musk”) D. Company (“SpaceX”, “Mars”, “Elon Musk”)","Natural language application. machine translation. natural language interfaces. AI systems extract knowledge from natural language texts. E.g., Q: The headquarters of BHP Billiton Limited, and the global headquarters of the combined BHP Billiton Group, are located in Melbourne, Australia. A: headquarters('“'BHP Biliton Limited', 'Melbourne, Australia') A cartoon picture showing that."
1a98fe1f-79fd-4b6f-9594-4314df651df4,train,future,elementary school,u21,12,group 2,post test,6,13,1,they consider them simultaneously,Qubits can represent combinations simultaneously.,Why do quantum computers outperform existing traditional computers in problems related to a large number of combinations? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
f9c44bfa-18f0-4802-8860-45b76349dc35,train,past,elementary school,u21,12,group 2,post test,5,13,1,Qubits,Quantum bit/Qubit,What is the basic unit of memory in quantum computers? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
a5dbaadb-8c88-42b7-9477-01c2fdab5d04,train,future,elementary school,u21,12,group 2,post test,10,18,0,D,B,"Which of the following descriptions about developing AI with caution is incorrect? <please select the best answer> A. Autonomous driving has safety issues related to the measurement of doing well and liability. B. With more sensitive sensors and more autonomous control, robots are sure to have personalities and consciousness at some point. C. Stephen Hawking, Elon Musk and Bill Gates have warned that AI may spell the end to human intelligence. D. We should be smart enough to use AI and wise enough to plan our future so that using AI will enrich our lives.","Ethical issues. If AI are developed with more sensitive sensors and more autonomous control, will robots, at some point, start to have personalities and consciousness? Should we worry about respecting their opinions or their will for existence? A picture of 2 robots."
4899490a-a17c-4773-8cc2-546e06a1e870,train,future,elementary school,u21,12,group 2,post test,7,10,0,you have to consider every thing,We must do more research on the human brain side,What is the reason that development in brain-AI communication takes a long time? <please input your answer>,Integrate with our brains. We expect our brains will be able to communicate with AI through implanted electrodes to expand out cognitive capabilities. Development in this direction may take many years because we must do more research on the human brain side. A picture of a human brain but it's digital.
db32646b-8a96-429b-940a-d3b5b329be8c,test,past,elementary school,u32,12,group 3,post test,3,7,0,A,B,Which one of the following methods is suitable for robots that work on Mars to achieve autonomousness? <please select the best answer> A. Spike neural networks B. Q-learning C. K-nearest neighbors D. Recurrent neural networks,"Usage in dangerous situations. Situations human want to avoid: Old minefields, automobile factories, other planets... AI can make machines in these situations more autonomous and useful. A picture of Curious, a robot that was sent to Mars."
59cb5c20-07ec-4e3f-b2b6-8ce73991c3c6,test,past,elementary school,u32,12,group 3,post test,4,8,0,the developments,We should read with caution because a fair amount of hype is often involved,What should we notice when we are faced with AI-related news? <please input your answer>,"Summary. The real-world aplication using AI have just begun, and AI technology hasn’t fully matured and been tested. AI-related news should be read with caution. A picture of a robot."
625c5846-1925-44d2-9d60-f7a5a3d99c88,test,past,elementary school,u32,12,group 3,post test,1,4,0,B,C,"To help biologists to understand the vast amount of data, AI can generate a knowledge graph. Which is a helpful scheme to build such knowledge? <please select the best answer> A. Reinforcement learning B. Supervised learning C. Unsupervised learning D. Few-shot learning","Medicine. finding new drugs. medical diagnoses. With the vast knowledge of paintents , and chemical sturctures sotred in databases, AI system can search for potentially effective treatments more quickly than human experts can. A video about AI usage in medicine."
de256774-3346-47f8-9fe8-11bc05f8c9cf,test,future,elementary school,u32,12,group 3,post test,8,14,0,C,D,Which of the following best describes artificial general intelligence (AGI)? <please select the best answer> A. Computer programs that experience sentience or consciousness. B. Any program that is designed to solve exactly one problem. C. A computer agent with the ability to sense and the ability to act. D. An intelligent agent to learn any task that a human being can.,"Artificial general intelligence (AGI). AGI is a generic, human-like intelligence that can tackle problems by developing and applying general congnitive abilities across different areas. Many people think that the progress in AI will be made only by tackling specific problems, not by trying to advance machine intelligence in general. A picture of a robot trying to solve complex math/physics problems."
52760a4c-3002-4001-894e-7522e09295ee,test,future,elementary school,u32,12,group 3,post test,9,12,0,I don't know,Spike neurons take as input spikes while tradition neurons take as input continuous value,What is the most significant difference between spike neural networks and traditional neural networks? <please input your answer>,"Supporting hardware. Spiking neural networks: They consider the spike timings rather than just the spiking frequency, which is an important feature of biological neural networls. A biological neuron integrates the inputs and decides whether it generates a spike or not. Three images showing that."
bbae5b96-ce8b-4b75-9722-4df1fb5ff632,test,past,elementary school,u32,12,group 3,post test,2,5,0,D,C,"Considering the given example, which one of the following opinions correctly describes the entity and related information? Example: SpaceX is an aerospace manufacturer and space transport services company headquartered in California. It was founded in 2002 by entrepreneur and investor Elon Musk with the goal of reducing space transportation costs and enabling the colonization of Mars. <please select the best answer> A. Entrepreneur (“Elon Musk”, “SpaceX”, “California”) B. Entrepreneur (“Elon Musk”, “California”, “2002”) C. Company (“SpaceX”, “California”, “Elon Musk”) D. Company (“SpaceX”, “Mars”, “Elon Musk”)","Natural language application. machine translation. natural language interfaces. AI systems extract knowledge from natural language texts. E.g., Q: The headquarters of BHP Billiton Limited, and the global headquarters of the combined BHP Billiton Group, are located in Melbourne, Australia. A: headquarters('“'BHP Biliton Limited', 'Melbourne, Australia') A cartoon picture showing that."
bb7ebb33-675e-497b-98ce-04ff48c83058,test,future,elementary school,u32,12,group 3,post test,6,13,0,they are smarter,Qubits can represent combinations simultaneously.,Why do quantum computers outperform existing traditional computers in problems related to a large number of combinations? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
9a238950-2f92-4563-a4fd-11ca171d2056,test,past,elementary school,u32,12,group 3,post test,5,13,0,I don't know,Quantum bit/Qubit,What is the basic unit of memory in quantum computers? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
7cd427d3-6968-4677-9725-afc8c6a28846,test,future,elementary school,u32,12,group 3,post test,10,18,1,B,B,"Which of the following descriptions about developing AI with caution is incorrect? <please select the best answer> A. Autonomous driving has safety issues related to the measurement of doing well and liability. B. With more sensitive sensors and more autonomous control, robots are sure to have personalities and consciousness at some point. C. Stephen Hawking, Elon Musk and Bill Gates have warned that AI may spell the end to human intelligence. D. We should be smart enough to use AI and wise enough to plan our future so that using AI will enrich our lives.","Ethical issues. If AI are developed with more sensitive sensors and more autonomous control, will robots, at some point, start to have personalities and consciousness? Should we worry about respecting their opinions or their will for existence? A picture of 2 robots."
2846213f-62ee-43ae-9657-2a58a90fee10,test,future,elementary school,u32,12,group 3,post test,7,10,0,it's hard to do,We must do more research on the human brain side,What is the reason that development in brain-AI communication takes a long time? <please input your answer>,Integrate with our brains. We expect our brains will be able to communicate with AI through implanted electrodes to expand out cognitive capabilities. Development in this direction may take many years because we must do more research on the human brain side. A picture of a human brain but it's digital.
9e386bcb-f436-4df6-9be9-bf80f27cb482,train,past,elementary school,u25,12,group 3,post test,3,7,0,D,B,Which one of the following methods is suitable for robots that work on Mars to achieve autonomousness? <please select the best answer> A. Spike neural networks B. Q-learning C. K-nearest neighbors D. Recurrent neural networks,"Usage in dangerous situations. Situations human want to avoid: Old minefields, automobile factories, other planets... AI can make machines in these situations more autonomous and useful. A picture of Curious, a robot that was sent to Mars."
16fff09b-194d-4e78-99e7-36ad08201dd3,train,past,elementary school,u25,12,group 3,post test,4,8,0,?,We should read with caution because a fair amount of hype is often involved,What should we notice when we are faced with AI-related news? <please input your answer>,"Summary. The real-world aplication using AI have just begun, and AI technology hasn’t fully matured and been tested. AI-related news should be read with caution. A picture of a robot."
88bb2f9a-6c48-4b67-bad9-fe24a4cf7ef2,train,past,elementary school,u25,12,group 3,post test,1,4,0,B,C,"To help biologists to understand the vast amount of data, AI can generate a knowledge graph. Which is a helpful scheme to build such knowledge? <please select the best answer> A. Reinforcement learning B. Supervised learning C. Unsupervised learning D. Few-shot learning","Medicine. finding new drugs. medical diagnoses. With the vast knowledge of paintents , and chemical sturctures sotred in databases, AI system can search for potentially effective treatments more quickly than human experts can. A video about AI usage in medicine."
c0936563-ddc6-4c0a-abdf-fda91a89f786,train,future,elementary school,u25,12,group 3,post test,8,14,1,D,D,Which of the following best describes artificial general intelligence (AGI)? <please select the best answer> A. Computer programs that experience sentience or consciousness. B. Any program that is designed to solve exactly one problem. C. A computer agent with the ability to sense and the ability to act. D. An intelligent agent to learn any task that a human being can.,"Artificial general intelligence (AGI). AGI is a generic, human-like intelligence that can tackle problems by developing and applying general congnitive abilities across different areas. Many people think that the progress in AI will be made only by tackling specific problems, not by trying to advance machine intelligence in general. A picture of a robot trying to solve complex math/physics problems."
398ff511-14fe-4592-8776-c676b446487c,train,future,elementary school,u25,12,group 3,post test,9,12,0,?,Spike neurons take as input spikes while tradition neurons take as input continuous value,What is the most significant difference between spike neural networks and traditional neural networks? <please input your answer>,"Supporting hardware. Spiking neural networks: They consider the spike timings rather than just the spiking frequency, which is an important feature of biological neural networls. A biological neuron integrates the inputs and decides whether it generates a spike or not. Three images showing that."
19de72ec-84cf-42f0-93b3-ddb383a7ce69,train,past,elementary school,u25,12,group 3,post test,2,5,1,C,C,"Considering the given example, which one of the following opinions correctly describes the entity and related information? Example: SpaceX is an aerospace manufacturer and space transport services company headquartered in California. It was founded in 2002 by entrepreneur and investor Elon Musk with the goal of reducing space transportation costs and enabling the colonization of Mars. <please select the best answer> A. Entrepreneur (“Elon Musk”, “SpaceX”, “California”) B. Entrepreneur (“Elon Musk”, “California”, “2002”) C. Company (“SpaceX”, “California”, “Elon Musk”) D. Company (“SpaceX”, “Mars”, “Elon Musk”)","Natural language application. machine translation. natural language interfaces. AI systems extract knowledge from natural language texts. E.g., Q: The headquarters of BHP Billiton Limited, and the global headquarters of the combined BHP Billiton Group, are located in Melbourne, Australia. A: headquarters('“'BHP Biliton Limited', 'Melbourne, Australia') A cartoon picture showing that."
568446b3-7a35-4e5d-a94b-c2b465cfa938,train,future,elementary school,u25,12,group 3,post test,6,13,0,?,Qubits can represent combinations simultaneously.,Why do quantum computers outperform existing traditional computers in problems related to a large number of combinations? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
6a679afa-464b-4f09-98bb-aa382316b13e,train,past,elementary school,u25,12,group 3,post test,5,13,1,Qubits,Quantum bit/Qubit,What is the basic unit of memory in quantum computers? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
6f3f82e2-a0de-43e2-b39e-6142fce45de5,train,future,elementary school,u25,12,group 3,post test,10,18,0,A,B,"Which of the following descriptions about developing AI with caution is incorrect? <please select the best answer> A. Autonomous driving has safety issues related to the measurement of doing well and liability. B. With more sensitive sensors and more autonomous control, robots are sure to have personalities and consciousness at some point. C. Stephen Hawking, Elon Musk and Bill Gates have warned that AI may spell the end to human intelligence. D. We should be smart enough to use AI and wise enough to plan our future so that using AI will enrich our lives.","Ethical issues. If AI are developed with more sensitive sensors and more autonomous control, will robots, at some point, start to have personalities and consciousness? Should we worry about respecting their opinions or their will for existence? A picture of 2 robots."
36075db8-3600-406e-8689-afdf69a73faa,train,future,elementary school,u25,12,group 3,post test,7,10,0,?,We must do more research on the human brain side,What is the reason that development in brain-AI communication takes a long time? <please input your answer>,Integrate with our brains. We expect our brains will be able to communicate with AI through implanted electrodes to expand out cognitive capabilities. Development in this direction may take many years because we must do more research on the human brain side. A picture of a human brain but it's digital.
0040b98e-e461-4776-97d3-c2d55bd7fe58,test,past,elementary school,u5,12,group 3,post test,3,7,0,A,B,Which one of the following methods is suitable for robots that work on Mars to achieve autonomousness? <please select the best answer> A. Spike neural networks B. Q-learning C. K-nearest neighbors D. Recurrent neural networks,"Usage in dangerous situations. Situations human want to avoid: Old minefields, automobile factories, other planets... AI can make machines in these situations more autonomous and useful. A picture of Curious, a robot that was sent to Mars."
86e33473-77b9-4e4d-8600-f0c0b4433b68,test,past,elementary school,u5,12,group 3,post test,4,8,0,Developments in AI,We should read with caution because a fair amount of hype is often involved,What should we notice when we are faced with AI-related news? <please input your answer>,"Summary. The real-world aplication using AI have just begun, and AI technology hasn’t fully matured and been tested. AI-related news should be read with caution. A picture of a robot."
6b3ba70b-a999-48db-9f47-9d22f9880f16,test,past,elementary school,u5,12,group 3,post test,1,4,1,C,C,"To help biologists to understand the vast amount of data, AI can generate a knowledge graph. Which is a helpful scheme to build such knowledge? <please select the best answer> A. Reinforcement learning B. Supervised learning C. Unsupervised learning D. Few-shot learning","Medicine. finding new drugs. medical diagnoses. With the vast knowledge of paintents , and chemical sturctures sotred in databases, AI system can search for potentially effective treatments more quickly than human experts can. A video about AI usage in medicine."
ff873b99-083d-4192-8d8f-b8fda004a797,test,future,elementary school,u5,12,group 3,post test,8,14,0,C,D,Which of the following best describes artificial general intelligence (AGI)? <please select the best answer> A. Computer programs that experience sentience or consciousness. B. Any program that is designed to solve exactly one problem. C. A computer agent with the ability to sense and the ability to act. D. An intelligent agent to learn any task that a human being can.,"Artificial general intelligence (AGI). AGI is a generic, human-like intelligence that can tackle problems by developing and applying general congnitive abilities across different areas. Many people think that the progress in AI will be made only by tackling specific problems, not by trying to advance machine intelligence in general. A picture of a robot trying to solve complex math/physics problems."
d78f6e44-5f0d-4277-a6d8-fbd3651174c8,test,future,elementary school,u5,12,group 3,post test,9,12,0,spike neural networks spike sometimes,Spike neurons take as input spikes while tradition neurons take as input continuous value,What is the most significant difference between spike neural networks and traditional neural networks? <please input your answer>,"Supporting hardware. Spiking neural networks: They consider the spike timings rather than just the spiking frequency, which is an important feature of biological neural networls. A biological neuron integrates the inputs and decides whether it generates a spike or not. Three images showing that."
965533c3-5cc2-43c9-8109-763ec31e2986,test,past,elementary school,u5,12,group 3,post test,2,5,1,C,C,"Considering the given example, which one of the following opinions correctly describes the entity and related information? Example: SpaceX is an aerospace manufacturer and space transport services company headquartered in California. It was founded in 2002 by entrepreneur and investor Elon Musk with the goal of reducing space transportation costs and enabling the colonization of Mars. <please select the best answer> A. Entrepreneur (“Elon Musk”, “SpaceX”, “California”) B. Entrepreneur (“Elon Musk”, “California”, “2002”) C. Company (“SpaceX”, “California”, “Elon Musk”) D. Company (“SpaceX”, “Mars”, “Elon Musk”)","Natural language application. machine translation. natural language interfaces. AI systems extract knowledge from natural language texts. E.g., Q: The headquarters of BHP Billiton Limited, and the global headquarters of the combined BHP Billiton Group, are located in Melbourne, Australia. A: headquarters('“'BHP Biliton Limited', 'Melbourne, Australia') A cartoon picture showing that."
98939f10-9d8b-4b76-beaa-1784b1128d82,test,future,elementary school,u5,12,group 3,post test,6,13,0,because they are smaller,Qubits can represent combinations simultaneously.,Why do quantum computers outperform existing traditional computers in problems related to a large number of combinations? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
a73d9535-751f-4d6a-9e70-9a2687abaccb,test,past,elementary school,u5,12,group 3,post test,5,13,1,quantum bits,Quantum bit/Qubit,What is the basic unit of memory in quantum computers? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
618d220c-c798-4036-9159-3e40f8cd9060,test,future,elementary school,u5,12,group 3,post test,10,18,0,A,B,"Which of the following descriptions about developing AI with caution is incorrect? <please select the best answer> A. Autonomous driving has safety issues related to the measurement of doing well and liability. B. With more sensitive sensors and more autonomous control, robots are sure to have personalities and consciousness at some point. C. Stephen Hawking, Elon Musk and Bill Gates have warned that AI may spell the end to human intelligence. D. We should be smart enough to use AI and wise enough to plan our future so that using AI will enrich our lives.","Ethical issues. If AI are developed with more sensitive sensors and more autonomous control, will robots, at some point, start to have personalities and consciousness? Should we worry about respecting their opinions or their will for existence? A picture of 2 robots."
518355b3-539d-4667-8269-b4da7462e9b6,test,future,elementary school,u5,12,group 3,post test,7,10,1,because we are still working on the brain,We must do more research on the human brain side,What is the reason that development in brain-AI communication takes a long time? <please input your answer>,Integrate with our brains. We expect our brains will be able to communicate with AI through implanted electrodes to expand out cognitive capabilities. Development in this direction may take many years because we must do more research on the human brain side. A picture of a human brain but it's digital.
228618f5-c9a5-40e5-9940-b11268ecf596,test,past,elementary school,u23,12,group 3,post test,3,7,1,B,B,Which one of the following methods is suitable for robots that work on Mars to achieve autonomousness? <please select the best answer> A. Spike neural networks B. Q-learning C. K-nearest neighbors D. Recurrent neural networks,"Usage in dangerous situations. Situations human want to avoid: Old minefields, automobile factories, other planets... AI can make machines in these situations more autonomous and useful. A picture of Curious, a robot that was sent to Mars."
c1afacaf-3a0e-4112-bc02-f00c3c505dfa,test,past,elementary school,u23,12,group 3,post test,4,8,0,idk,We should read with caution because a fair amount of hype is often involved,What should we notice when we are faced with AI-related news? <please input your answer>,"Summary. The real-world aplication using AI have just begun, and AI technology hasn’t fully matured and been tested. AI-related news should be read with caution. A picture of a robot."
2c1e8016-8d38-4571-ab0c-5d7416e5e277,test,past,elementary school,u23,12,group 3,post test,1,4,0,B,C,"To help biologists to understand the vast amount of data, AI can generate a knowledge graph. Which is a helpful scheme to build such knowledge? <please select the best answer> A. Reinforcement learning B. Supervised learning C. Unsupervised learning D. Few-shot learning","Medicine. finding new drugs. medical diagnoses. With the vast knowledge of paintents , and chemical sturctures sotred in databases, AI system can search for potentially effective treatments more quickly than human experts can. A video about AI usage in medicine."
a0b7bfb0-2447-47b6-92fc-d2af1ceda3ed,test,future,elementary school,u23,12,group 3,post test,8,14,0,C,D,Which of the following best describes artificial general intelligence (AGI)? <please select the best answer> A. Computer programs that experience sentience or consciousness. B. Any program that is designed to solve exactly one problem. C. A computer agent with the ability to sense and the ability to act. D. An intelligent agent to learn any task that a human being can.,"Artificial general intelligence (AGI). AGI is a generic, human-like intelligence that can tackle problems by developing and applying general congnitive abilities across different areas. Many people think that the progress in AI will be made only by tackling specific problems, not by trying to advance machine intelligence in general. A picture of a robot trying to solve complex math/physics problems."
acf7d7d5-d80a-47b4-a91a-e1307275a786,test,future,elementary school,u23,12,group 3,post test,9,12,0,idk,Spike neurons take as input spikes while tradition neurons take as input continuous value,What is the most significant difference between spike neural networks and traditional neural networks? <please input your answer>,"Supporting hardware. Spiking neural networks: They consider the spike timings rather than just the spiking frequency, which is an important feature of biological neural networls. A biological neuron integrates the inputs and decides whether it generates a spike or not. Three images showing that."
b7f7bc80-82f2-4773-bfc9-c7614070c3cf,test,past,elementary school,u23,12,group 3,post test,2,5,0,A,C,"Considering the given example, which one of the following opinions correctly describes the entity and related information? Example: SpaceX is an aerospace manufacturer and space transport services company headquartered in California. It was founded in 2002 by entrepreneur and investor Elon Musk with the goal of reducing space transportation costs and enabling the colonization of Mars. <please select the best answer> A. Entrepreneur (“Elon Musk”, “SpaceX”, “California”) B. Entrepreneur (“Elon Musk”, “California”, “2002”) C. Company (“SpaceX”, “California”, “Elon Musk”) D. Company (“SpaceX”, “Mars”, “Elon Musk”)","Natural language application. machine translation. natural language interfaces. AI systems extract knowledge from natural language texts. E.g., Q: The headquarters of BHP Billiton Limited, and the global headquarters of the combined BHP Billiton Group, are located in Melbourne, Australia. A: headquarters('“'BHP Biliton Limited', 'Melbourne, Australia') A cartoon picture showing that."
667c538e-a115-4500-ac76-aea19724b13b,test,future,elementary school,u23,12,group 3,post test,6,13,1,It's because qubits can be many numbers at once.,Qubits can represent combinations simultaneously.,Why do quantum computers outperform existing traditional computers in problems related to a large number of combinations? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
02272262-17f9-432d-b899-63ec12f8ac05,test,past,elementary school,u23,12,group 3,post test,5,13,0,idk,Quantum bit/Qubit,What is the basic unit of memory in quantum computers? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
2a825c11-b9bc-4f7d-b11c-80da69b69d5b,test,future,elementary school,u23,12,group 3,post test,10,18,0,A,B,"Which of the following descriptions about developing AI with caution is incorrect? <please select the best answer> A. Autonomous driving has safety issues related to the measurement of doing well and liability. B. With more sensitive sensors and more autonomous control, robots are sure to have personalities and consciousness at some point. C. Stephen Hawking, Elon Musk and Bill Gates have warned that AI may spell the end to human intelligence. D. We should be smart enough to use AI and wise enough to plan our future so that using AI will enrich our lives.","Ethical issues. If AI are developed with more sensitive sensors and more autonomous control, will robots, at some point, start to have personalities and consciousness? Should we worry about respecting their opinions or their will for existence? A picture of 2 robots."
0814530c-2494-4902-830a-1ec3211e5e43,test,future,elementary school,u23,12,group 3,post test,7,10,1,we need to study more about the human brain,We must do more research on the human brain side,What is the reason that development in brain-AI communication takes a long time? <please input your answer>,Integrate with our brains. We expect our brains will be able to communicate with AI through implanted electrodes to expand out cognitive capabilities. Development in this direction may take many years because we must do more research on the human brain side. A picture of a human brain but it's digital.
edf19140-b9f7-4ec7-b329-1efa5e3e020a,test,past,elementary school,u24,12,group 3,post test,3,7,0,C,B,Which one of the following methods is suitable for robots that work on Mars to achieve autonomousness? <please select the best answer> A. Spike neural networks B. Q-learning C. K-nearest neighbors D. Recurrent neural networks,"Usage in dangerous situations. Situations human want to avoid: Old minefields, automobile factories, other planets... AI can make machines in these situations more autonomous and useful. A picture of Curious, a robot that was sent to Mars."
e6da98e0-1a51-4b73-b650-44bba18f2880,test,past,elementary school,u24,12,group 3,post test,4,8,0, ,We should read with caution because a fair amount of hype is often involved,What should we notice when we are faced with AI-related news? <please input your answer>,"Summary. The real-world aplication using AI have just begun, and AI technology hasn’t fully matured and been tested. AI-related news should be read with caution. A picture of a robot."
aec18517-9acd-43ac-95a8-1426d428b015,test,past,elementary school,u24,12,group 3,post test,1,4,0,B,C,"To help biologists to understand the vast amount of data, AI can generate a knowledge graph. Which is a helpful scheme to build such knowledge? <please select the best answer> A. Reinforcement learning B. Supervised learning C. Unsupervised learning D. Few-shot learning","Medicine. finding new drugs. medical diagnoses. With the vast knowledge of paintents , and chemical sturctures sotred in databases, AI system can search for potentially effective treatments more quickly than human experts can. A video about AI usage in medicine."
e874627e-176f-41e6-8d61-97aa5ec5b470,test,future,elementary school,u24,12,group 3,post test,8,14,0,C,D,Which of the following best describes artificial general intelligence (AGI)? <please select the best answer> A. Computer programs that experience sentience or consciousness. B. Any program that is designed to solve exactly one problem. C. A computer agent with the ability to sense and the ability to act. D. An intelligent agent to learn any task that a human being can.,"Artificial general intelligence (AGI). AGI is a generic, human-like intelligence that can tackle problems by developing and applying general congnitive abilities across different areas. Many people think that the progress in AI will be made only by tackling specific problems, not by trying to advance machine intelligence in general. A picture of a robot trying to solve complex math/physics problems."
3d34bd2f-f03f-4830-abdc-abf40ceb38ba,test,future,elementary school,u24,12,group 3,post test,9,12,0, ,Spike neurons take as input spikes while tradition neurons take as input continuous value,What is the most significant difference between spike neural networks and traditional neural networks? <please input your answer>,"Supporting hardware. Spiking neural networks: They consider the spike timings rather than just the spiking frequency, which is an important feature of biological neural networls. A biological neuron integrates the inputs and decides whether it generates a spike or not. Three images showing that."
5c7894de-b4d4-4c01-a547-3155b6afd09c,test,past,elementary school,u24,12,group 3,post test,2,5,0,A,C,"Considering the given example, which one of the following opinions correctly describes the entity and related information? Example: SpaceX is an aerospace manufacturer and space transport services company headquartered in California. It was founded in 2002 by entrepreneur and investor Elon Musk with the goal of reducing space transportation costs and enabling the colonization of Mars. <please select the best answer> A. Entrepreneur (“Elon Musk”, “SpaceX”, “California”) B. Entrepreneur (“Elon Musk”, “California”, “2002”) C. Company (“SpaceX”, “California”, “Elon Musk”) D. Company (“SpaceX”, “Mars”, “Elon Musk”)","Natural language application. machine translation. natural language interfaces. AI systems extract knowledge from natural language texts. E.g., Q: The headquarters of BHP Billiton Limited, and the global headquarters of the combined BHP Billiton Group, are located in Melbourne, Australia. A: headquarters('“'BHP Biliton Limited', 'Melbourne, Australia') A cartoon picture showing that."
53b196de-ed81-426b-b582-85fa7301635d,test,future,elementary school,u24,12,group 3,post test,6,13,0, ,Qubits can represent combinations simultaneously.,Why do quantum computers outperform existing traditional computers in problems related to a large number of combinations? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
daddb799-c255-4a9a-8b3a-fa8e03b7ced8,test,past,elementary school,u24,12,group 3,post test,5,13,0, ,Quantum bit/Qubit,What is the basic unit of memory in quantum computers? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
7cc302a1-f444-451c-b492-82b404aef308,test,future,elementary school,u24,12,group 3,post test,10,18,1,B,B,"Which of the following descriptions about developing AI with caution is incorrect? <please select the best answer> A. Autonomous driving has safety issues related to the measurement of doing well and liability. B. With more sensitive sensors and more autonomous control, robots are sure to have personalities and consciousness at some point. C. Stephen Hawking, Elon Musk and Bill Gates have warned that AI may spell the end to human intelligence. D. We should be smart enough to use AI and wise enough to plan our future so that using AI will enrich our lives.","Ethical issues. If AI are developed with more sensitive sensors and more autonomous control, will robots, at some point, start to have personalities and consciousness? Should we worry about respecting their opinions or their will for existence? A picture of 2 robots."
335e8982-b106-4134-a42d-539a0772085a,test,future,elementary school,u24,12,group 3,post test,7,10,0, ,We must do more research on the human brain side,What is the reason that development in brain-AI communication takes a long time? <please input your answer>,Integrate with our brains. We expect our brains will be able to communicate with AI through implanted electrodes to expand out cognitive capabilities. Development in this direction may take many years because we must do more research on the human brain side. A picture of a human brain but it's digital.
20af82ef-2da2-4f5d-9a2a-ecc5a4444924,train,past,elementary school,u16,2,group 1,post test,3,10,0,True,F,The first neural networks winter is because of that training ANNs takes a lot of computation and computing power was limited in that era. <please select the best answer> True or False,The first neural networks winter. Rosenblatt could not come up with an effective algorithm for adjusting the weights in the hidden layer neurons. It was easy to adjust the weights to the output there were no effective ways to adjust the weights in hidden layers. It contains a picture of the neural network.
955ad03c-8d65-4d47-ae04-5705097d74f8,train,past,elementary school,u16,2,group 1,post test,4,17,1,False,F,"For the current state of ANNs, it is easy to interpret what ANNs are doing. <please select the best answer> True or False",Current state of ANNs. Interpretability. It’s difficult to interpret what ANNs are doing raises safety concerns. Interpretability: AI can recognize pictures of dogs but we don’t know how it operates. It contains a picture of a dog and the neural network.
f62b0ed6-cfe8-43c6-9e35-f5650a853a74,train,past,elementary school,u16,2,group 1,post test,1,4,1,True,T,"The reticular theory was advocated by physician Camillo Golgi, who invented a groundbreaking method for observing the nervous system. <please select the best answer> True or False",Knows the neural network of brain. The reticular theory: the nervous system was a continuous network. The nervous system transmits signals between different parts of the body. Camillo Golgi invented a groundbreaking method for observing the nervous system. Camillo Golgi (1843-1926). It contains two pictures of Camillo and neurons.
2aed3c5e-334f-4886-913e-99ebbcdd4e3d,train,future,elementary school,u16,2,group 1,post test,8,8,1,the connection weight,C,"When two neurons get excited together, which one between them is increased? <please select the best answer> A. the input B. the output C. the connection weight",Ability to learn. Intelligent machines must be able to learn just like the human brain. Donald Hebb the first learning theory The Organization of Behavior (1949). When two neurons get excited together the connection weights increase. Frank Rosenblatt the first ANN model with learning capability named perceptron. It was designed and realized as an image recognition machine.
4e4a9d96-f04e-4217-acdf-e09f77ec53d8,train,future,elementary school,u16,2,group 1,post test,9,6,0,1,"0, 1","For an AND logic gate, if the inputs are '0' and '1', then the output is? For an OR logic gate, if the inputs are '0' and '1', then the output is? <please input your answer>",Logic gates. Logic gates are physical electronic devices every kind of logic gate has the corresponding input and output rules. AND. OR. NOT. It contains three pictures of logic gates.
2e5a5db5-a918-425d-9d6f-5697592aca12,train,past,elementary school,u16,2,group 1,post test,2,8,0,True,F,Frank Rosenblatt came up with the first learning theory. <please select the best answer> True or False,Ability to learn. Intelligent machines must be able to learn just like the human brain. Donald Hebb the first learning theory The Organization of Behavior (1949). When two neurons get excited together the connection weights increase. Frank Rosenblatt the first ANN model with learning capability named perceptron. It was designed and realized as an image recognition machine.
8483b58a-cd38-4de9-9cac-d105eb93ce90,train,future,elementary school,u16,2,group 1,post test,6,7,1,True,T,McCulloch and Pitts found neurons to be like the basic building block that can be used to build any complex logical circuits. <please select the best answer> True or False,"neuron could act as a logic gate. McCulloch and Pitts thought each neuron could act as a logic gate and that it could be combined to form a complex computing system. McCulloch and Pitts. A neuron can receive inputs from other neurons, weighs and sums them up, and decides whether or not to produce an output. It contains three pictures of McCulloch and neurons."
12b98743-df07-475a-ae87-dcf51bb97a01,train,past,elementary school,u16,2,group 1,post test,5,18,1,True,T,ANNs of the current state don't have a good generalization. <please select the best answer> True or False,Current state of ANNs. Generalizability. ANNs don’t generalize when they encounter inputs different from those they are trained on. Generalizability: When the AI encounters a new batch of pictures of dogs its performance will be different. It contains a picture of a dog and the neural network.
55ff251e-ce8b-4ab8-a884-96215111eed2,train,future,elementary school,u16,2,group 1,post test,7,12,1,True,T,The backpropagation algorithm contributed to the end of the first neural network winter. <please select the best answer> True or False,The second neural networks boom. Several people found ways to train multiple layer neural networks through a technique called backpropagation. ANNs with multiple layers could be trained to yield outputs closer to the desired output values. Backpropagation provides an effective way to change hidden connections to reduce output errors. It contains a picture of the backpropagation.
9e09406d-464e-4068-9123-2f4051b964f4,train,past,elementary school,u4,2,group 1,post test,3,10,1,False,F,The first neural networks winter is because of that training ANNs takes a lot of computation and computing power was limited in that era. <please select the best answer> True or False,The first neural networks winter. Rosenblatt could not come up with an effective algorithm for adjusting the weights in the hidden layer neurons. It was easy to adjust the weights to the output there were no effective ways to adjust the weights in hidden layers. It contains a picture of the neural network.
0afcec9f-d8ee-444b-b377-92ea5aa50116,train,past,elementary school,u4,2,group 1,post test,4,17,0,True,F,"For the current state of ANNs, it is easy to interpret what ANNs are doing. <please select the best answer> True or False",Current state of ANNs. Interpretability. It’s difficult to interpret what ANNs are doing raises safety concerns. Interpretability: AI can recognize pictures of dogs but we don’t know how it operates. It contains a picture of a dog and the neural network.
d153ad66-335c-446f-975d-2a83a3188579,train,past,elementary school,u4,2,group 1,post test,1,4,1,True,T,"The reticular theory was advocated by physician Camillo Golgi, who invented a groundbreaking method for observing the nervous system. <please select the best answer> True or False",Knows the neural network of brain. The reticular theory: the nervous system was a continuous network. The nervous system transmits signals between different parts of the body. Camillo Golgi invented a groundbreaking method for observing the nervous system. Camillo Golgi (1843-1926). It contains two pictures of Camillo and neurons.
51afbd4f-b966-4669-b2b9-8a264483c142,train,future,elementary school,u4,2,group 1,post test,8,8,0,the input,C,"When two neurons get excited together, which one between them is increased? <please select the best answer> A. the input B. the output C. the connection weight",Ability to learn. Intelligent machines must be able to learn just like the human brain. Donald Hebb the first learning theory The Organization of Behavior (1949). When two neurons get excited together the connection weights increase. Frank Rosenblatt the first ANN model with learning capability named perceptron. It was designed and realized as an image recognition machine.
86d54c82-ce38-4418-83ee-932dbf97dc38,train,future,elementary school,u4,2,group 1,post test,9,6,0,1,"0, 1","For an AND logic gate, if the inputs are '0' and '1', then the output is? For an OR logic gate, if the inputs are '0' and '1', then the output is? <please input your answer>",Logic gates. Logic gates are physical electronic devices every kind of logic gate has the corresponding input and output rules. AND. OR. NOT. It contains three pictures of logic gates.
76b4e9b5-9853-46d8-aab0-8d2cedaa9094,train,past,elementary school,u4,2,group 1,post test,2,8,0,True,F,Frank Rosenblatt came up with the first learning theory. <please select the best answer> True or False,Ability to learn. Intelligent machines must be able to learn just like the human brain. Donald Hebb the first learning theory The Organization of Behavior (1949). When two neurons get excited together the connection weights increase. Frank Rosenblatt the first ANN model with learning capability named perceptron. It was designed and realized as an image recognition machine.
aa99d94b-ca97-47f6-9166-418ed0d0eb3e,train,future,elementary school,u4,2,group 1,post test,6,7,0,False,T,McCulloch and Pitts found neurons to be like the basic building block that can be used to build any complex logical circuits. <please select the best answer> True or False,"neuron could act as a logic gate. McCulloch and Pitts thought each neuron could act as a logic gate and that it could be combined to form a complex computing system. McCulloch and Pitts. A neuron can receive inputs from other neurons, weighs and sums them up, and decides whether or not to produce an output. It contains three pictures of McCulloch and neurons."
a5573820-6b64-482d-8b94-be0149eb2979,train,past,elementary school,u4,2,group 1,post test,5,18,1,True,T,ANNs of the current state don't have a good generalization. <please select the best answer> True or False,Current state of ANNs. Generalizability. ANNs don’t generalize when they encounter inputs different from those they are trained on. Generalizability: When the AI encounters a new batch of pictures of dogs its performance will be different. It contains a picture of a dog and the neural network.
f0c10b69-fea1-4773-8051-d81eec81278e,train,future,elementary school,u4,2,group 1,post test,7,12,1,True,T,The backpropagation algorithm contributed to the end of the first neural network winter. <please select the best answer> True or False,The second neural networks boom. Several people found ways to train multiple layer neural networks through a technique called backpropagation. ANNs with multiple layers could be trained to yield outputs closer to the desired output values. Backpropagation provides an effective way to change hidden connections to reduce output errors. It contains a picture of the backpropagation.
d4b97e9c-a8f2-4d27-bc23-cae704aed720,test,past,elementary school,u5,2,group 2,post test,3,10,0,True,F,The first neural networks winter is because of that training ANNs takes a lot of computation and computing power was limited in that era. <please select the best answer> True or False,The first neural networks winter. Rosenblatt could not come up with an effective algorithm for adjusting the weights in the hidden layer neurons. It was easy to adjust the weights to the output there were no effective ways to adjust the weights in hidden layers. It contains a picture of the neural network.
c8cc4374-f423-4e9a-a3c5-0d55d4c5341e,test,past,elementary school,u5,2,group 2,post test,4,17,1,False,F,"For the current state of ANNs, it is easy to interpret what ANNs are doing. <please select the best answer> True or False",Current state of ANNs. Interpretability. It’s difficult to interpret what ANNs are doing raises safety concerns. Interpretability: AI can recognize pictures of dogs but we don’t know how it operates. It contains a picture of a dog and the neural network.
c744963a-8a99-49a5-bf64-17910f2ec86b,test,past,elementary school,u5,2,group 2,post test,1,4,1,True,T,"The reticular theory was advocated by physician Camillo Golgi, who invented a groundbreaking method for observing the nervous system. <please select the best answer> True or False",Knows the neural network of brain. The reticular theory: the nervous system was a continuous network. The nervous system transmits signals between different parts of the body. Camillo Golgi invented a groundbreaking method for observing the nervous system. Camillo Golgi (1843-1926). It contains two pictures of Camillo and neurons.
1cc707f1-7450-4a85-b018-279be4908ea4,test,future,elementary school,u5,2,group 2,post test,8,8,1,the connection weight,C,"When two neurons get excited together, which one between them is increased? <please select the best answer> A. the input B. the output C. the connection weight",Ability to learn. Intelligent machines must be able to learn just like the human brain. Donald Hebb the first learning theory The Organization of Behavior (1949). When two neurons get excited together the connection weights increase. Frank Rosenblatt the first ANN model with learning capability named perceptron. It was designed and realized as an image recognition machine.
c12b2031-6f1b-46fd-81b3-be2c35c08256,test,future,elementary school,u5,2,group 2,post test,9,6,0,0,"0, 1","For an AND logic gate, if the inputs are '0' and '1', then the output is? For an OR logic gate, if the inputs are '0' and '1', then the output is? <please input your answer>",Logic gates. Logic gates are physical electronic devices every kind of logic gate has the corresponding input and output rules. AND. OR. NOT. It contains three pictures of logic gates.
8a15e1fb-7af7-4613-bcda-99e9f5a24601,test,past,elementary school,u5,2,group 2,post test,2,8,0,True,F,Frank Rosenblatt came up with the first learning theory. <please select the best answer> True or False,Ability to learn. Intelligent machines must be able to learn just like the human brain. Donald Hebb the first learning theory The Organization of Behavior (1949). When two neurons get excited together the connection weights increase. Frank Rosenblatt the first ANN model with learning capability named perceptron. It was designed and realized as an image recognition machine.
0355ba59-02bf-456a-b937-d215f6f5903f,test,future,elementary school,u5,2,group 2,post test,6,7,1,True,T,McCulloch and Pitts found neurons to be like the basic building block that can be used to build any complex logical circuits. <please select the best answer> True or False,"neuron could act as a logic gate. McCulloch and Pitts thought each neuron could act as a logic gate and that it could be combined to form a complex computing system. McCulloch and Pitts. A neuron can receive inputs from other neurons, weighs and sums them up, and decides whether or not to produce an output. It contains three pictures of McCulloch and neurons."
35e31484-ff00-4346-94e3-d5804599f6a9,test,past,elementary school,u5,2,group 2,post test,5,18,1,True,T,ANNs of the current state don't have a good generalization. <please select the best answer> True or False,Current state of ANNs. Generalizability. ANNs don’t generalize when they encounter inputs different from those they are trained on. Generalizability: When the AI encounters a new batch of pictures of dogs its performance will be different. It contains a picture of a dog and the neural network.
a8a9d3dc-6d50-4c1e-b977-4cc7f93f4da2,test,future,elementary school,u5,2,group 2,post test,7,12,0,False,T,The backpropagation algorithm contributed to the end of the first neural network winter. <please select the best answer> True or False,The second neural networks boom. Several people found ways to train multiple layer neural networks through a technique called backpropagation. ANNs with multiple layers could be trained to yield outputs closer to the desired output values. Backpropagation provides an effective way to change hidden connections to reduce output errors. It contains a picture of the backpropagation.
cb4384c0-06d6-4f64-85f1-5d9723be2ccb,train,past,elementary school,u7,2,group 2,post test,3,10,0,True,F,The first neural networks winter is because of that training ANNs takes a lot of computation and computing power was limited in that era. <please select the best answer> True or False,The first neural networks winter. Rosenblatt could not come up with an effective algorithm for adjusting the weights in the hidden layer neurons. It was easy to adjust the weights to the output there were no effective ways to adjust the weights in hidden layers. It contains a picture of the neural network.
238671b6-c6f3-408a-98aa-25cdf4aa3ed4,train,past,elementary school,u7,2,group 2,post test,4,17,1,False,F,"For the current state of ANNs, it is easy to interpret what ANNs are doing. <please select the best answer> True or False",Current state of ANNs. Interpretability. It’s difficult to interpret what ANNs are doing raises safety concerns. Interpretability: AI can recognize pictures of dogs but we don’t know how it operates. It contains a picture of a dog and the neural network.
1b901d9d-811b-4287-bd60-4ae6e09e5ce8,train,past,elementary school,u7,2,group 2,post test,1,4,0,False,T,"The reticular theory was advocated by physician Camillo Golgi, who invented a groundbreaking method for observing the nervous system. <please select the best answer> True or False",Knows the neural network of brain. The reticular theory: the nervous system was a continuous network. The nervous system transmits signals between different parts of the body. Camillo Golgi invented a groundbreaking method for observing the nervous system. Camillo Golgi (1843-1926). It contains two pictures of Camillo and neurons.
999e8c43-44b2-4139-b697-909f76e7236c,train,future,elementary school,u7,2,group 2,post test,8,8,0,the input,C,"When two neurons get excited together, which one between them is increased? <please select the best answer> A. the input B. the output C. the connection weight",Ability to learn. Intelligent machines must be able to learn just like the human brain. Donald Hebb the first learning theory The Organization of Behavior (1949). When two neurons get excited together the connection weights increase. Frank Rosenblatt the first ANN model with learning capability named perceptron. It was designed and realized as an image recognition machine.
105f0eac-bca3-4d6a-9b08-02268d52d279,train,future,elementary school,u7,2,group 2,post test,9,6,1,0 and 1,"0, 1","For an AND logic gate, if the inputs are '0' and '1', then the output is? For an OR logic gate, if the inputs are '0' and '1', then the output is? <please input your answer>",Logic gates. Logic gates are physical electronic devices every kind of logic gate has the corresponding input and output rules. AND. OR. NOT. It contains three pictures of logic gates.
d3bbf823-df5a-4276-9d98-c410a0ff6c36,train,past,elementary school,u7,2,group 2,post test,2,8,0,True,F,Frank Rosenblatt came up with the first learning theory. <please select the best answer> True or False,Ability to learn. Intelligent machines must be able to learn just like the human brain. Donald Hebb the first learning theory The Organization of Behavior (1949). When two neurons get excited together the connection weights increase. Frank Rosenblatt the first ANN model with learning capability named perceptron. It was designed and realized as an image recognition machine.
4f7b2381-2f96-4693-99bd-e96158cbe127,train,future,elementary school,u7,2,group 2,post test,6,7,0,False,T,McCulloch and Pitts found neurons to be like the basic building block that can be used to build any complex logical circuits. <please select the best answer> True or False,"neuron could act as a logic gate. McCulloch and Pitts thought each neuron could act as a logic gate and that it could be combined to form a complex computing system. McCulloch and Pitts. A neuron can receive inputs from other neurons, weighs and sums them up, and decides whether or not to produce an output. It contains three pictures of McCulloch and neurons."
c86e7fc7-6ab0-4676-b715-b818d6c571cf,train,past,elementary school,u7,2,group 2,post test,5,18,1,True,T,ANNs of the current state don't have a good generalization. <please select the best answer> True or False,Current state of ANNs. Generalizability. ANNs don’t generalize when they encounter inputs different from those they are trained on. Generalizability: When the AI encounters a new batch of pictures of dogs its performance will be different. It contains a picture of a dog and the neural network.
b9ba9b09-9c70-4818-9692-34ef37aa21d6,train,future,elementary school,u7,2,group 2,post test,7,12,1,True,T,The backpropagation algorithm contributed to the end of the first neural network winter. <please select the best answer> True or False,The second neural networks boom. Several people found ways to train multiple layer neural networks through a technique called backpropagation. ANNs with multiple layers could be trained to yield outputs closer to the desired output values. Backpropagation provides an effective way to change hidden connections to reduce output errors. It contains a picture of the backpropagation.
4b51e2b1-becb-4436-9caf-3c8a0db6b015,train,past,elementary school,u27,2,group 2,post test,3,10,1,False,F,The first neural networks winter is because of that training ANNs takes a lot of computation and computing power was limited in that era. <please select the best answer> True or False,The first neural networks winter. Rosenblatt could not come up with an effective algorithm for adjusting the weights in the hidden layer neurons. It was easy to adjust the weights to the output there were no effective ways to adjust the weights in hidden layers. It contains a picture of the neural network.
779f86ee-e006-4228-973c-f19bd5c47a13,train,past,elementary school,u27,2,group 2,post test,4,17,1,False,F,"For the current state of ANNs, it is easy to interpret what ANNs are doing. <please select the best answer> True or False",Current state of ANNs. Interpretability. It’s difficult to interpret what ANNs are doing raises safety concerns. Interpretability: AI can recognize pictures of dogs but we don’t know how it operates. It contains a picture of a dog and the neural network.
0b88720c-2331-4749-9c16-7f858f49f84f,train,past,elementary school,u27,2,group 2,post test,1,4,1,True,T,"The reticular theory was advocated by physician Camillo Golgi, who invented a groundbreaking method for observing the nervous system. <please select the best answer> True or False",Knows the neural network of brain. The reticular theory: the nervous system was a continuous network. The nervous system transmits signals between different parts of the body. Camillo Golgi invented a groundbreaking method for observing the nervous system. Camillo Golgi (1843-1926). It contains two pictures of Camillo and neurons.
f9190730-8047-45dd-a0f4-14ff5d2a3609,train,future,elementary school,u27,2,group 2,post test,8,8,1,the connection weight,C,"When two neurons get excited together, which one between them is increased? <please select the best answer> A. the input B. the output C. the connection weight",Ability to learn. Intelligent machines must be able to learn just like the human brain. Donald Hebb the first learning theory The Organization of Behavior (1949). When two neurons get excited together the connection weights increase. Frank Rosenblatt the first ANN model with learning capability named perceptron. It was designed and realized as an image recognition machine.
a75cfbc1-dee9-4f02-8041-2ac475ac684d,train,future,elementary school,u27,2,group 2,post test,9,6,1,0,"0, 1","For an AND logic gate, if the inputs are '0' and '1', then the output is? For an OR logic gate, if the inputs are '0' and '1', then the output is? <please input your answer>",Logic gates. Logic gates are physical electronic devices every kind of logic gate has the corresponding input and output rules. AND. OR. NOT. It contains three pictures of logic gates.
a45fe0b6-93f6-4d85-9de5-f1a652e76143,train,past,elementary school,u27,2,group 2,post test,2,8,0,True,F,Frank Rosenblatt came up with the first learning theory. <please select the best answer> True or False,Ability to learn. Intelligent machines must be able to learn just like the human brain. Donald Hebb the first learning theory The Organization of Behavior (1949). When two neurons get excited together the connection weights increase. Frank Rosenblatt the first ANN model with learning capability named perceptron. It was designed and realized as an image recognition machine.
f977dea9-2392-4f94-9f9a-20aa2ed5194c,train,future,elementary school,u27,2,group 2,post test,6,7,0,False,T,McCulloch and Pitts found neurons to be like the basic building block that can be used to build any complex logical circuits. <please select the best answer> True or False,"neuron could act as a logic gate. McCulloch and Pitts thought each neuron could act as a logic gate and that it could be combined to form a complex computing system. McCulloch and Pitts. A neuron can receive inputs from other neurons, weighs and sums them up, and decides whether or not to produce an output. It contains three pictures of McCulloch and neurons."
94a7f868-9d69-470a-b556-5f1e28e52ec8,train,past,elementary school,u27,2,group 2,post test,5,18,1,True,T,ANNs of the current state don't have a good generalization. <please select the best answer> True or False,Current state of ANNs. Generalizability. ANNs don’t generalize when they encounter inputs different from those they are trained on. Generalizability: When the AI encounters a new batch of pictures of dogs its performance will be different. It contains a picture of a dog and the neural network.
ec341a8a-3cd7-4809-affa-6682e7e54381,train,future,elementary school,u27,2,group 2,post test,7,12,1,True,T,The backpropagation algorithm contributed to the end of the first neural network winter. <please select the best answer> True or False,The second neural networks boom. Several people found ways to train multiple layer neural networks through a technique called backpropagation. ANNs with multiple layers could be trained to yield outputs closer to the desired output values. Backpropagation provides an effective way to change hidden connections to reduce output errors. It contains a picture of the backpropagation.
36968922-7ad6-4230-ac9c-0dc7c2227b5e,train,past,elementary school,u17,2,group 3,post test,3,10,1,False,F,The first neural networks winter is because of that training ANNs takes a lot of computation and computing power was limited in that era. <please select the best answer> True or False,The first neural networks winter. Rosenblatt could not come up with an effective algorithm for adjusting the weights in the hidden layer neurons. It was easy to adjust the weights to the output there were no effective ways to adjust the weights in hidden layers. It contains a picture of the neural network.
b3305a0d-a49d-40be-96da-2d41949b77d3,train,past,elementary school,u17,2,group 3,post test,4,17,0,True,F,"For the current state of ANNs, it is easy to interpret what ANNs are doing. <please select the best answer> True or False",Current state of ANNs. Interpretability. It’s difficult to interpret what ANNs are doing raises safety concerns. Interpretability: AI can recognize pictures of dogs but we don’t know how it operates. It contains a picture of a dog and the neural network.
85f283e4-b03c-4cad-a3d4-ce0b8add644b,train,past,elementary school,u17,2,group 3,post test,1,4,1,True,T,"The reticular theory was advocated by physician Camillo Golgi, who invented a groundbreaking method for observing the nervous system. <please select the best answer> True or False",Knows the neural network of brain. The reticular theory: the nervous system was a continuous network. The nervous system transmits signals between different parts of the body. Camillo Golgi invented a groundbreaking method for observing the nervous system. Camillo Golgi (1843-1926). It contains two pictures of Camillo and neurons.
6a906d4a-f1fd-4e59-94a4-b9f1e5987cb4,train,future,elementary school,u17,2,group 3,post test,8,8,1,the connection weight,C,"When two neurons get excited together, which one between them is increased? <please select the best answer> A. the input B. the output C. the connection weight",Ability to learn. Intelligent machines must be able to learn just like the human brain. Donald Hebb the first learning theory The Organization of Behavior (1949). When two neurons get excited together the connection weights increase. Frank Rosenblatt the first ANN model with learning capability named perceptron. It was designed and realized as an image recognition machine.
7a2f3676-cc65-48cf-b198-2dff9c895764,train,future,elementary school,u17,2,group 3,post test,9,6,0,0,"0, 1","For an AND logic gate, if the inputs are '0' and '1', then the output is? For an OR logic gate, if the inputs are '0' and '1', then the output is? <please input your answer>",Logic gates. Logic gates are physical electronic devices every kind of logic gate has the corresponding input and output rules. AND. OR. NOT. It contains three pictures of logic gates.
ebf38aa4-48e1-44c4-bd02-cf383d6b6432,train,past,elementary school,u17,2,group 3,post test,2,8,1,False,F,Frank Rosenblatt came up with the first learning theory. <please select the best answer> True or False,Ability to learn. Intelligent machines must be able to learn just like the human brain. Donald Hebb the first learning theory The Organization of Behavior (1949). When two neurons get excited together the connection weights increase. Frank Rosenblatt the first ANN model with learning capability named perceptron. It was designed and realized as an image recognition machine.
af1f1cbe-0a38-424d-b4c5-aa4fcd8ff4ed,train,future,elementary school,u17,2,group 3,post test,6,7,1,True,T,McCulloch and Pitts found neurons to be like the basic building block that can be used to build any complex logical circuits. <please select the best answer> True or False,"neuron could act as a logic gate. McCulloch and Pitts thought each neuron could act as a logic gate and that it could be combined to form a complex computing system. McCulloch and Pitts. A neuron can receive inputs from other neurons, weighs and sums them up, and decides whether or not to produce an output. It contains three pictures of McCulloch and neurons."
2c055ae8-ab7a-459c-a9ab-9ae1948c4ba2,train,past,elementary school,u17,2,group 3,post test,5,18,0,False,T,ANNs of the current state don't have a good generalization. <please select the best answer> True or False,Current state of ANNs. Generalizability. ANNs don’t generalize when they encounter inputs different from those they are trained on. Generalizability: When the AI encounters a new batch of pictures of dogs its performance will be different. It contains a picture of a dog and the neural network.
2fdeed6d-11f4-4b64-968b-660680367778,train,future,elementary school,u17,2,group 3,post test,7,12,0,False,T,The backpropagation algorithm contributed to the end of the first neural network winter. <please select the best answer> True or False,The second neural networks boom. Several people found ways to train multiple layer neural networks through a technique called backpropagation. ANNs with multiple layers could be trained to yield outputs closer to the desired output values. Backpropagation provides an effective way to change hidden connections to reduce output errors. It contains a picture of the backpropagation.
8b556e7b-6b57-4003-909f-7d81e418f84b,train,past,elementary school,u15,2,group 3,post test,3,10,0,True,F,The first neural networks winter is because of that training ANNs takes a lot of computation and computing power was limited in that era. <please select the best answer> True or False,The first neural networks winter. Rosenblatt could not come up with an effective algorithm for adjusting the weights in the hidden layer neurons. It was easy to adjust the weights to the output there were no effective ways to adjust the weights in hidden layers. It contains a picture of the neural network.
c81c7ee4-efae-4dea-a892-3152b525fff7,train,past,elementary school,u15,2,group 3,post test,4,17,0,True,F,"For the current state of ANNs, it is easy to interpret what ANNs are doing. <please select the best answer> True or False",Current state of ANNs. Interpretability. It’s difficult to interpret what ANNs are doing raises safety concerns. Interpretability: AI can recognize pictures of dogs but we don’t know how it operates. It contains a picture of a dog and the neural network.
d74753cb-6b25-4449-879f-fbbf4bd035fa,train,past,elementary school,u15,2,group 3,post test,1,4,1,True,T,"The reticular theory was advocated by physician Camillo Golgi, who invented a groundbreaking method for observing the nervous system. <please select the best answer> True or False",Knows the neural network of brain. The reticular theory: the nervous system was a continuous network. The nervous system transmits signals between different parts of the body. Camillo Golgi invented a groundbreaking method for observing the nervous system. Camillo Golgi (1843-1926). It contains two pictures of Camillo and neurons.
a7a710ec-d227-483c-94fe-facd4c2d1841,train,future,elementary school,u15,2,group 3,post test,8,8,1,the connection weight,C,"When two neurons get excited together, which one between them is increased? <please select the best answer> A. the input B. the output C. the connection weight",Ability to learn. Intelligent machines must be able to learn just like the human brain. Donald Hebb the first learning theory The Organization of Behavior (1949). When two neurons get excited together the connection weights increase. Frank Rosenblatt the first ANN model with learning capability named perceptron. It was designed and realized as an image recognition machine.
73bcc284-2257-4800-82da-bad3f04d5a68,train,future,elementary school,u15,2,group 3,post test,9,6,0,0,"0, 1","For an AND logic gate, if the inputs are '0' and '1', then the output is? For an OR logic gate, if the inputs are '0' and '1', then the output is? <please input your answer>",Logic gates. Logic gates are physical electronic devices every kind of logic gate has the corresponding input and output rules. AND. OR. NOT. It contains three pictures of logic gates.
9f7c08e9-8376-4a45-9bea-885c8c232907,train,past,elementary school,u15,2,group 3,post test,2,8,1,False,F,Frank Rosenblatt came up with the first learning theory. <please select the best answer> True or False,Ability to learn. Intelligent machines must be able to learn just like the human brain. Donald Hebb the first learning theory The Organization of Behavior (1949). When two neurons get excited together the connection weights increase. Frank Rosenblatt the first ANN model with learning capability named perceptron. It was designed and realized as an image recognition machine.
5859aa98-78ba-4fa4-bc77-06ecd2105889,train,future,elementary school,u15,2,group 3,post test,6,7,1,True,T,McCulloch and Pitts found neurons to be like the basic building block that can be used to build any complex logical circuits. <please select the best answer> True or False,"neuron could act as a logic gate. McCulloch and Pitts thought each neuron could act as a logic gate and that it could be combined to form a complex computing system. McCulloch and Pitts. A neuron can receive inputs from other neurons, weighs and sums them up, and decides whether or not to produce an output. It contains three pictures of McCulloch and neurons."
aaa2dd45-7b63-4586-b5f9-3e0abfc576f9,train,past,elementary school,u15,2,group 3,post test,5,18,0,False,T,ANNs of the current state don't have a good generalization. <please select the best answer> True or False,Current state of ANNs. Generalizability. ANNs don’t generalize when they encounter inputs different from those they are trained on. Generalizability: When the AI encounters a new batch of pictures of dogs its performance will be different. It contains a picture of a dog and the neural network.
98932c24-3345-4610-9fc4-9d2ea3bd47dc,train,future,elementary school,u15,2,group 3,post test,7,12,1,True,T,The backpropagation algorithm contributed to the end of the first neural network winter. <please select the best answer> True or False,The second neural networks boom. Several people found ways to train multiple layer neural networks through a technique called backpropagation. ANNs with multiple layers could be trained to yield outputs closer to the desired output values. Backpropagation provides an effective way to change hidden connections to reduce output errors. It contains a picture of the backpropagation.
f2591657-bd38-4fa4-acbb-d2596ef2ae44,train,past,elementary school,u16,3,group 1,post test,3,12,1,decrease,A,"If the desired change is positive, and the input is -1, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
72279cb4-6a66-4718-ace3-659980e05147,train,past,elementary school,u16,3,group 1,post test,4,12,1,increase,B,"If the desired change is negative, and the input is -2, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
63fa78e4-7b5b-4483-9c61-9958973e9de0,train,past,elementary school,u16,3,group 1,post test,1,2,0,Supervised learning,BC,Which of the following learning methods involves learning from a teacher? <please select the answer> A. Unsupervised learning B. Supervised learning C. Reinforcement learning,Outline. Supervised learning: learning from a teacher. Computing the output. Comparing the output to the desired output. Changing the connection weight. Backpropagation.
02fd8994-8afe-4361-bafd-e2c3d4573e8c,train,future,elementary school,u16,3,group 1,post test,8,21,0,0,C,"If the inner state is 1, then after the ReLU (Rectified Linear Unit), what will the output be? <please select the best answer> A. 2 B. 0 C. 1",Change in the Computation. The output is 5 (because of ReLU) the desired output change: 95 error: the deviation of the actual output from the desired output
e069d2c1-ec8f-4174-8e56-59cff458a2e1,train,future,elementary school,u16,3,group 1,post test,9,5,0,Yes,B,"If there is more than one layer of artificial neurons, does the delta rule still work? <please select the best answer> A. Yes B. No",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
ca2786a4-f32e-42f3-ad30-4d49474833cb,train,past,elementary school,u16,3,group 1,post test,2,5,1,learning constant;desired change;input,ABC,Which of the following options are required to determine the change of one connection in the delta rule (select multiple answers)? <please select the answer> A. learning constant B. desired change C. input D. connection weight,The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
29273574-875f-463e-9182-d520dadf4b58,train,future,elementary school,u16,3,group 1,post test,11,16,1,1.0,A,"After many processes of learning, what value does the output of the 'x' artificial neuron in response to 'x' get closer to? <please select the best answer> A. 1.0 B. 0.0 C. 1.5 D. -1.0",Summary. ANNs work by training the network for samples 'x' and '+' repeatedly. The output of the artificial neuron will become closer and closer to the desired output. It contains a table of relationship between input and neuron.
ea8fd180-8534-4b20-af29-e9a7a8e707ac,train,future,elementary school,u16,3,group 1,post test,6,5,0,6,2,"If the target output is 5 and the computed output is 3, what is the desired change? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
f59b9f3c-1452-4e0b-bf62-c019ef4ea743,train,past,elementary school,u16,3,group 1,post test,5,15,0,5,4,"If the input of a single-layer ANN model is 1,0,1; and the weight of inputs is 1, 2, 3; what would the output of the single-layer ANN model be? <please input your answer>",Example 3: Weight change for the 'x' neuron. After applying the delta rule the weight pattern of the 'x' artificial neuron will be. It contains a picture of calculation.
54f90756-f83c-4760-aa62-22629a8b8c75,train,future,elementary school,u16,3,group 1,post test,10,22,0,bigger,A,"If supervised learning works, will the weight become smaller or bigger? <please select the best answer> A. smaller B. bigger",Change in the Computation. Contribution ratio: the ratio between the inner state change and the output change. The weight change proportional to: input * contribution ratio * error = 1*1*95
08de4435-ee23-4dca-a21e-49e517060b71,train,future,elementary school,u16,3,group 1,post test,7,5,0,5,D,"Let the learning constant be 2, the desired change to be 3, and the input to be 1, what will the change of weight be? <please select the best answer> A. 2 B. 3 C. 5 D. 6",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
c783d91e-3c33-4ab7-bd16-4f1a7e769d0a,train,past,elementary school,u27,3,group 1,post test,3,12,1,decrease,A,"If the desired change is positive, and the input is -1, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
34efa8a4-d6fd-4c17-9e1b-77179494dea0,train,past,elementary school,u27,3,group 1,post test,4,12,1,increase,B,"If the desired change is negative, and the input is -2, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
fa8b3911-c4c8-4e7a-8eb0-aca3d3248747,train,past,elementary school,u27,3,group 1,post test,1,2,0,Supervised learning,BC,Which of the following learning methods involves learning from a teacher? <please select the answer> A. Unsupervised learning B. Supervised learning C. Reinforcement learning,Outline. Supervised learning: learning from a teacher. Computing the output. Comparing the output to the desired output. Changing the connection weight. Backpropagation.
8225fe2f-1095-4166-a315-c93e70b59c9a,train,future,elementary school,u27,3,group 1,post test,8,21,0,2,C,"If the inner state is 1, then after the ReLU (Rectified Linear Unit), what will the output be? <please select the best answer> A. 2 B. 0 C. 1",Change in the Computation. The output is 5 (because of ReLU) the desired output change: 95 error: the deviation of the actual output from the desired output
1b020b45-203d-4eda-b3de-117bdaa5da29,train,future,elementary school,u27,3,group 1,post test,9,5,0,Yes,B,"If there is more than one layer of artificial neurons, does the delta rule still work? <please select the best answer> A. Yes B. No",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
4930a94a-2836-4e5d-86f9-2eae1d99fca5,train,past,elementary school,u27,3,group 1,post test,2,5,1,learning constant;desired change;input,ABC,Which of the following options are required to determine the change of one connection in the delta rule (select multiple answers)? <please select the answer> A. learning constant B. desired change C. input D. connection weight,The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
a8816266-92e3-4ed0-b550-3cae7eda0756,train,future,elementary school,u27,3,group 1,post test,11,16,0,0.0,A,"After many processes of learning, what value does the output of the 'x' artificial neuron in response to 'x' get closer to? <please select the best answer> A. 1.0 B. 0.0 C. 1.5 D. -1.0",Summary. ANNs work by training the network for samples 'x' and '+' repeatedly. The output of the artificial neuron will become closer and closer to the desired output. It contains a table of relationship between input and neuron.
a746a16a-bc98-445a-a01f-d74cf1dba221,train,future,elementary school,u27,3,group 1,post test,6,5,1,2,2,"If the target output is 5 and the computed output is 3, what is the desired change? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
c2147822-b53f-49a7-ae76-3c2c0b08075e,train,past,elementary school,u27,3,group 1,post test,5,15,1,4,4,"If the input of a single-layer ANN model is 1,0,1; and the weight of inputs is 1, 2, 3; what would the output of the single-layer ANN model be? <please input your answer>",Example 3: Weight change for the 'x' neuron. After applying the delta rule the weight pattern of the 'x' artificial neuron will be. It contains a picture of calculation.
f24a60a3-7d60-4c6c-a378-9db570b8269a,train,future,elementary school,u27,3,group 1,post test,10,22,0,bigger,A,"If supervised learning works, will the weight become smaller or bigger? <please select the best answer> A. smaller B. bigger",Change in the Computation. Contribution ratio: the ratio between the inner state change and the output change. The weight change proportional to: input * contribution ratio * error = 1*1*95
4edf431f-7155-459b-8796-364304557748,train,future,elementary school,u27,3,group 1,post test,7,5,1,6,D,"Let the learning constant be 2, the desired change to be 3, and the input to be 1, what will the change of weight be? <please select the best answer> A. 2 B. 3 C. 5 D. 6",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
1aa7af94-6086-4e1d-8d76-fc705c7d28f6,train,past,elementary school,u4,3,group 1,post test,3,12,1,decrease,A,"If the desired change is positive, and the input is -1, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
180fa222-e4bb-4890-bd02-191f9685f79c,train,past,elementary school,u4,3,group 1,post test,4,12,0,decrease,B,"If the desired change is negative, and the input is -2, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
50574ee0-393b-4e56-8b4f-90f7877e3b69,train,past,elementary school,u4,3,group 1,post test,1,2,0,Supervised learning,BC,Which of the following learning methods involves learning from a teacher? <please select the answer> A. Unsupervised learning B. Supervised learning C. Reinforcement learning,Outline. Supervised learning: learning from a teacher. Computing the output. Comparing the output to the desired output. Changing the connection weight. Backpropagation.
8d19cd31-3c02-45ae-965d-419d5f0fb850,train,future,elementary school,u4,3,group 1,post test,8,21,0,2,C,"If the inner state is 1, then after the ReLU (Rectified Linear Unit), what will the output be? <please select the best answer> A. 2 B. 0 C. 1",Change in the Computation. The output is 5 (because of ReLU) the desired output change: 95 error: the deviation of the actual output from the desired output
418872ab-89a6-4dc4-bde7-5311b83c4599,train,future,elementary school,u4,3,group 1,post test,9,5,1,No,B,"If there is more than one layer of artificial neurons, does the delta rule still work? <please select the best answer> A. Yes B. No",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
a9416f87-c108-481a-a480-f59969f9a2a5,train,past,elementary school,u4,3,group 1,post test,2,5,0,learning constant;desired change,ABC,Which of the following options are required to determine the change of one connection in the delta rule (select multiple answers)? <please select the answer> A. learning constant B. desired change C. input D. connection weight,The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
bd000e42-e05a-4cc8-a39b-009174b1717d,train,future,elementary school,u4,3,group 1,post test,11,16,0,,A,"After many processes of learning, what value does the output of the 'x' artificial neuron in response to 'x' get closer to? <please select the best answer> A. 1.0 B. 0.0 C. 1.5 D. -1.0",Summary. ANNs work by training the network for samples 'x' and '+' repeatedly. The output of the artificial neuron will become closer and closer to the desired output. It contains a table of relationship between input and neuron.
70d62307-a4c6-4b99-bcaa-03c5bd1a1b05,train,future,elementary school,u4,3,group 1,post test,6,5,1,2,2,"If the target output is 5 and the computed output is 3, what is the desired change? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
0eb5ff64-9d67-4f5e-b5a6-376e05b12b0f,train,past,elementary school,u4,3,group 1,post test,5,15,1,4,4,"If the input of a single-layer ANN model is 1,0,1; and the weight of inputs is 1, 2, 3; what would the output of the single-layer ANN model be? <please input your answer>",Example 3: Weight change for the 'x' neuron. After applying the delta rule the weight pattern of the 'x' artificial neuron will be. It contains a picture of calculation.
2a457564-f662-4ec4-b1b3-58e02e7eebdb,train,future,elementary school,u4,3,group 1,post test,10,22,0,bigger,A,"If supervised learning works, will the weight become smaller or bigger? <please select the best answer> A. smaller B. bigger",Change in the Computation. Contribution ratio: the ratio between the inner state change and the output change. The weight change proportional to: input * contribution ratio * error = 1*1*95
9903ae1c-283f-4e22-9f7d-b5918238f706,train,future,elementary school,u4,3,group 1,post test,7,5,1,6,D,"Let the learning constant be 2, the desired change to be 3, and the input to be 1, what will the change of weight be? <please select the best answer> A. 2 B. 3 C. 5 D. 6",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
25a920aa-1717-4edd-bae7-51bce3ae7b0f,test,past,elementary school,u1,3,group 2,post test,3,12,1,decrease,A,"If the desired change is positive, and the input is -1, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
57af150d-0ad8-4871-adc5-8050f4fa811e,test,past,elementary school,u1,3,group 2,post test,4,12,1,increase,B,"If the desired change is negative, and the input is -2, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
f584647b-cfcb-439b-8656-cae6653530e4,test,past,elementary school,u1,3,group 2,post test,1,2,0,Supervised learning,BC,Which of the following learning methods involves learning from a teacher? <please select the answer> A. Unsupervised learning B. Supervised learning C. Reinforcement learning,Outline. Supervised learning: learning from a teacher. Computing the output. Comparing the output to the desired output. Changing the connection weight. Backpropagation.
ffcd349a-2d49-44a4-b204-ca75585bb505,test,future,elementary school,u1,3,group 2,post test,8,21,0,0.0,C,"If the inner state is 1, then after the ReLU (Rectified Linear Unit), what will the output be? <please select the best answer> A. 2 B. 0 C. 1",Change in the Computation. The output is 5 (because of ReLU) the desired output change: 95 error: the deviation of the actual output from the desired output
87912b07-5bb3-4ba4-b01d-3ff5dbbbc6c0,test,future,elementary school,u1,3,group 2,post test,9,5,0,Yes,B,"If there is more than one layer of artificial neurons, does the delta rule still work? <please select the best answer> A. Yes B. No",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
39c9b725-3e41-462f-b60e-84be6a3dff9f,test,past,elementary school,u1,3,group 2,post test,2,5,0,learning constant,ABC,Which of the following options are required to determine the change of one connection in the delta rule (select multiple answers)? <please select the answer> A. learning constant B. desired change C. input D. connection weight,The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
89581483-533a-4541-a8a2-8a716347669f,test,future,elementary school,u1,3,group 2,post test,11,16,0,1.5,A,"After many processes of learning, what value does the output of the 'x' artificial neuron in response to 'x' get closer to? <please select the best answer> A. 1.0 B. 0.0 C. 1.5 D. -1.0",Summary. ANNs work by training the network for samples 'x' and '+' repeatedly. The output of the artificial neuron will become closer and closer to the desired output. It contains a table of relationship between input and neuron.
71a24fc2-e63a-4eb1-a2fe-c1481d00977e,test,future,elementary school,u1,3,group 2,post test,6,5,0,,2,"If the target output is 5 and the computed output is 3, what is the desired change? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
76d54065-0714-4817-8089-d012eed2a476,test,past,elementary school,u1,3,group 2,post test,5,15,0,,4,"If the input of a single-layer ANN model is 1,0,1; and the weight of inputs is 1, 2, 3; what would the output of the single-layer ANN model be? <please input your answer>",Example 3: Weight change for the 'x' neuron. After applying the delta rule the weight pattern of the 'x' artificial neuron will be. It contains a picture of calculation.
5b417851-527f-43af-afbb-740373991c6a,test,future,elementary school,u1,3,group 2,post test,10,22,0,bigger,A,"If supervised learning works, will the weight become smaller or bigger? <please select the best answer> A. smaller B. bigger",Change in the Computation. Contribution ratio: the ratio between the inner state change and the output change. The weight change proportional to: input * contribution ratio * error = 1*1*95
2e6b5e86-d046-43ba-a7b7-0b0e4d376bd1,test,future,elementary school,u1,3,group 2,post test,7,5,0,3.0,D,"Let the learning constant be 2, the desired change to be 3, and the input to be 1, what will the change of weight be? <please select the best answer> A. 2 B. 3 C. 5 D. 6",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
cc54ce3f-9a3b-49c5-a12f-392aebd26534,train,past,elementary school,u9,3,group 2,post test,3,12,0,increase,A,"If the desired change is positive, and the input is -1, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
1843ad13-015f-4e46-bf0f-f412b1e15478,train,past,elementary school,u9,3,group 2,post test,4,12,0,decrease,B,"If the desired change is negative, and the input is -2, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
b112b26e-4858-46bf-8649-a33ce909579c,train,past,elementary school,u9,3,group 2,post test,1,2,0,Supervised learning,BC,Which of the following learning methods involves learning from a teacher? <please select the answer> A. Unsupervised learning B. Supervised learning C. Reinforcement learning,Outline. Supervised learning: learning from a teacher. Computing the output. Comparing the output to the desired output. Changing the connection weight. Backpropagation.
a79de6ad-84f0-474f-8fa0-def7b8dc828e,train,future,elementary school,u9,3,group 2,post test,8,21,0,0.0,C,"If the inner state is 1, then after the ReLU (Rectified Linear Unit), what will the output be? <please select the best answer> A. 2 B. 0 C. 1",Change in the Computation. The output is 5 (because of ReLU) the desired output change: 95 error: the deviation of the actual output from the desired output
21c22ff1-dc27-4cec-a212-e46fee3bc97d,train,future,elementary school,u9,3,group 2,post test,9,5,0,Yes,B,"If there is more than one layer of artificial neurons, does the delta rule still work? <please select the best answer> A. Yes B. No",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
32275164-86dc-44af-9222-d45a3fc7015b,train,past,elementary school,u9,3,group 2,post test,2,5,0,desired change,ABC,Which of the following options are required to determine the change of one connection in the delta rule (select multiple answers)? <please select the answer> A. learning constant B. desired change C. input D. connection weight,The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
147d0fab-ac83-4080-aaee-b044ff582f1a,train,future,elementary school,u9,3,group 2,post test,11,16,0,0.0,A,"After many processes of learning, what value does the output of the 'x' artificial neuron in response to 'x' get closer to? <please select the best answer> A. 1.0 B. 0.0 C. 1.5 D. -1.0",Summary. ANNs work by training the network for samples 'x' and '+' repeatedly. The output of the artificial neuron will become closer and closer to the desired output. It contains a table of relationship between input and neuron.
6ee529ac-5add-42c6-9d10-0288ec205215,train,future,elementary school,u9,3,group 2,post test,6,5,0,I do not know,2,"If the target output is 5 and the computed output is 3, what is the desired change? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
08e66f55-cfea-46a8-9595-058bdb23a4a2,train,past,elementary school,u9,3,group 2,post test,5,15,0,I do not know,4,"If the input of a single-layer ANN model is 1,0,1; and the weight of inputs is 1, 2, 3; what would the output of the single-layer ANN model be? <please input your answer>",Example 3: Weight change for the 'x' neuron. After applying the delta rule the weight pattern of the 'x' artificial neuron will be. It contains a picture of calculation.
b2c31530-8470-4723-9543-621b6283920d,train,future,elementary school,u9,3,group 2,post test,10,22,0,bigger,A,"If supervised learning works, will the weight become smaller or bigger? <please select the best answer> A. smaller B. bigger",Change in the Computation. Contribution ratio: the ratio between the inner state change and the output change. The weight change proportional to: input * contribution ratio * error = 1*1*95
2eff0c9a-b513-480f-b123-9f410cb7b7bc,train,future,elementary school,u9,3,group 2,post test,7,5,0,3.0,D,"Let the learning constant be 2, the desired change to be 3, and the input to be 1, what will the change of weight be? <please select the best answer> A. 2 B. 3 C. 5 D. 6",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
96dfaa1b-5778-458f-854f-019a3f4cdef4,train,past,elementary school,u7,3,group 2,post test,3,12,1,decrease,A,"If the desired change is positive, and the input is -1, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
a28a7716-aa21-4ba4-93c4-284635084f41,train,past,elementary school,u7,3,group 2,post test,4,12,1,increase,B,"If the desired change is negative, and the input is -2, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
c69f737e-6eb4-4fe7-9286-90b0fd7e44d6,train,past,elementary school,u7,3,group 2,post test,1,2,0,Reinforcement learning,BC,Which of the following learning methods involves learning from a teacher? <please select the answer> A. Unsupervised learning B. Supervised learning C. Reinforcement learning,Outline. Supervised learning: learning from a teacher. Computing the output. Comparing the output to the desired output. Changing the connection weight. Backpropagation.
58f221c5-88a6-4917-9f42-47e66144aad7,train,future,elementary school,u7,3,group 2,post test,8,21,0,0.0,C,"If the inner state is 1, then after the ReLU (Rectified Linear Unit), what will the output be? <please select the best answer> A. 2 B. 0 C. 1",Change in the Computation. The output is 5 (because of ReLU) the desired output change: 95 error: the deviation of the actual output from the desired output
2d9fa768-ffd3-4c14-903a-5ca2cbb956e0,train,future,elementary school,u7,3,group 2,post test,9,5,0,Yes,B,"If there is more than one layer of artificial neurons, does the delta rule still work? <please select the best answer> A. Yes B. No",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
fd37b8e9-f20d-45b4-a550-a4d242715ba8,train,past,elementary school,u7,3,group 2,post test,2,5,0,learning constant;desired change;input;connection weight,ABC,Which of the following options are required to determine the change of one connection in the delta rule (select multiple answers)? <please select the answer> A. learning constant B. desired change C. input D. connection weight,The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
d5ea66e4-b781-4351-967f-87ef217f2ed4,train,future,elementary school,u7,3,group 2,post test,11,16,0,0.0,A,"After many processes of learning, what value does the output of the 'x' artificial neuron in response to 'x' get closer to? <please select the best answer> A. 1.0 B. 0.0 C. 1.5 D. -1.0",Summary. ANNs work by training the network for samples 'x' and '+' repeatedly. The output of the artificial neuron will become closer and closer to the desired output. It contains a table of relationship between input and neuron.
a2bc8f40-65e3-4653-b716-6144c9e9a4d4,train,future,elementary school,u7,3,group 2,post test,6,5,0,8,2,"If the target output is 5 and the computed output is 3, what is the desired change? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
4e9ff22a-4172-46c2-b6d0-acdb7bb2dfcd,train,past,elementary school,u7,3,group 2,post test,5,15,0,212,4,"If the input of a single-layer ANN model is 1,0,1; and the weight of inputs is 1, 2, 3; what would the output of the single-layer ANN model be? <please input your answer>",Example 3: Weight change for the 'x' neuron. After applying the delta rule the weight pattern of the 'x' artificial neuron will be. It contains a picture of calculation.
3d1fc6ea-44ea-422f-bb36-fcf4ff5ea48f,train,future,elementary school,u7,3,group 2,post test,10,22,1,smaller,A,"If supervised learning works, will the weight become smaller or bigger? <please select the best answer> A. smaller B. bigger",Change in the Computation. Contribution ratio: the ratio between the inner state change and the output change. The weight change proportional to: input * contribution ratio * error = 1*1*95
22f1146d-c329-4f81-9514-478dec983e12,train,future,elementary school,u7,3,group 2,post test,7,5,0,5.0,D,"Let the learning constant be 2, the desired change to be 3, and the input to be 1, what will the change of weight be? <please select the best answer> A. 2 B. 3 C. 5 D. 6",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
cd7cd151-91d2-401a-944b-9e6624d4c28b,train,past,elementary school,u8,3,group 2,post test,3,12,0,increase,A,"If the desired change is positive, and the input is -1, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
7fdc5a5a-37fb-4f60-9939-5372283c3cbc,train,past,elementary school,u8,3,group 2,post test,4,12,0,decrease,B,"If the desired change is negative, and the input is -2, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
e386d2ef-f001-4ccd-a674-e96b534026a0,train,past,elementary school,u8,3,group 2,post test,1,2,0,Supervised learning,BC,Which of the following learning methods involves learning from a teacher? <please select the answer> A. Unsupervised learning B. Supervised learning C. Reinforcement learning,Outline. Supervised learning: learning from a teacher. Computing the output. Comparing the output to the desired output. Changing the connection weight. Backpropagation.
d3861fa7-1e50-4ba4-b706-4e0b3726b196,train,future,elementary school,u8,3,group 2,post test,8,21,0,0.0,C,"If the inner state is 1, then after the ReLU (Rectified Linear Unit), what will the output be? <please select the best answer> A. 2 B. 0 C. 1",Change in the Computation. The output is 5 (because of ReLU) the desired output change: 95 error: the deviation of the actual output from the desired output
f4c05801-a205-422f-88f3-77c874934ec4,train,future,elementary school,u8,3,group 2,post test,9,5,0,Yes,B,"If there is more than one layer of artificial neurons, does the delta rule still work? <please select the best answer> A. Yes B. No",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
52815ef3-50cc-4cb8-a3b7-2bf6ead79213,train,past,elementary school,u8,3,group 2,post test,2,5,0,input;connection weight,ABC,Which of the following options are required to determine the change of one connection in the delta rule (select multiple answers)? <please select the answer> A. learning constant B. desired change C. input D. connection weight,The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
f81be11d-7c30-4edb-bb78-d9dfde89f0aa,train,future,elementary school,u8,3,group 2,post test,11,16,0,1.0,A,"After many processes of learning, what value does the output of the 'x' artificial neuron in response to 'x' get closer to? <please select the best answer> A. 1.0 B. 0.0 C. 1.5 D. -1.0",Summary. ANNs work by training the network for samples 'x' and '+' repeatedly. The output of the artificial neuron will become closer and closer to the desired output. It contains a table of relationship between input and neuron.
1aa3a2e6-9cda-4354-9699-5ae8d05a8ef4,train,future,elementary school,u8,3,group 2,post test,6,5,0,positive,2,"If the target output is 5 and the computed output is 3, what is the desired change? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
151b5d79-247c-4f6f-a834-cee9dd93ae8a,train,past,elementary school,u8,3,group 2,post test,5,15,0,0,4,"If the input of a single-layer ANN model is 1,0,1; and the weight of inputs is 1, 2, 3; what would the output of the single-layer ANN model be? <please input your answer>",Example 3: Weight change for the 'x' neuron. After applying the delta rule the weight pattern of the 'x' artificial neuron will be. It contains a picture of calculation.
eb7566f6-8b33-4396-8f7d-a9c3711907c6,train,future,elementary school,u8,3,group 2,post test,10,22,0,bigger,A,"If supervised learning works, will the weight become smaller or bigger? <please select the best answer> A. smaller B. bigger",Change in the Computation. Contribution ratio: the ratio between the inner state change and the output change. The weight change proportional to: input * contribution ratio * error = 1*1*95
b76b506a-1d3c-4faf-bf94-b42aad920d1d,train,future,elementary school,u8,3,group 2,post test,7,5,0,5.0,D,"Let the learning constant be 2, the desired change to be 3, and the input to be 1, what will the change of weight be? <please select the best answer> A. 2 B. 3 C. 5 D. 6",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
2dfd16c5-fa5c-4d4d-b38d-b214d9e89b2b,train,past,elementary school,u17,3,group 3,post test,3,12,1,decrease,A,"If the desired change is positive, and the input is -1, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
275bfded-b740-4634-99f6-1feaf96995e0,train,past,elementary school,u17,3,group 3,post test,4,12,1,increase,B,"If the desired change is negative, and the input is -2, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
4b4ffc79-3998-41c2-adca-1f390b725d83,train,past,elementary school,u17,3,group 3,post test,1,2,0,Supervised learning,BC,Which of the following learning methods involves learning from a teacher? <please select the answer> A. Unsupervised learning B. Supervised learning C. Reinforcement learning,Outline. Supervised learning: learning from a teacher. Computing the output. Comparing the output to the desired output. Changing the connection weight. Backpropagation.
6e4db95c-201a-437b-b881-4e571cf69693,train,future,elementary school,u17,3,group 3,post test,8,21,0,0,C,"If the inner state is 1, then after the ReLU (Rectified Linear Unit), what will the output be? <please select the best answer> A. 2 B. 0 C. 1",Change in the Computation. The output is 5 (because of ReLU) the desired output change: 95 error: the deviation of the actual output from the desired output
88f6e357-d371-41fe-aef0-ae9edca7ab61,train,future,elementary school,u17,3,group 3,post test,9,5,0,Yes,B,"If there is more than one layer of artificial neurons, does the delta rule still work? <please select the best answer> A. Yes B. No",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
7df15838-1d23-4b25-8744-9d59a27e3bc8,train,past,elementary school,u17,3,group 3,post test,2,5,1,learning constant;desired change;input,ABC,Which of the following options are required to determine the change of one connection in the delta rule (select multiple answers)? <please select the answer> A. learning constant B. desired change C. input D. connection weight,The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
a457fb45-fa52-4a39-ac03-5d4076df3da0,train,future,elementary school,u17,3,group 3,post test,11,16,0,-1.0,A,"After many processes of learning, what value does the output of the 'x' artificial neuron in response to 'x' get closer to? <please select the best answer> A. 1.0 B. 0.0 C. 1.5 D. -1.0",Summary. ANNs work by training the network for samples 'x' and '+' repeatedly. The output of the artificial neuron will become closer and closer to the desired output. It contains a table of relationship between input and neuron.
d18cd48d-bd51-47a5-bd86-72382a7a1db2,train,future,elementary school,u17,3,group 3,post test,6,5,0,8,2,"If the target output is 5 and the computed output is 3, what is the desired change? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
4d1cd0d4-232d-4398-a461-777e5fd77987,train,past,elementary school,u17,3,group 3,post test,5,15,0,321,4,"If the input of a single-layer ANN model is 1,0,1; and the weight of inputs is 1, 2, 3; what would the output of the single-layer ANN model be? <please input your answer>",Example 3: Weight change for the 'x' neuron. After applying the delta rule the weight pattern of the 'x' artificial neuron will be. It contains a picture of calculation.
d04234ec-f88b-42d2-af68-3bf8a7efc448,train,future,elementary school,u17,3,group 3,post test,10,22,0,bigger,A,"If supervised learning works, will the weight become smaller or bigger? <please select the best answer> A. smaller B. bigger",Change in the Computation. Contribution ratio: the ratio between the inner state change and the output change. The weight change proportional to: input * contribution ratio * error = 1*1*95
81aff3f9-caa6-4752-a105-b49b6c7d551a,train,future,elementary school,u17,3,group 3,post test,7,5,0,2,D,"Let the learning constant be 2, the desired change to be 3, and the input to be 1, what will the change of weight be? <please select the best answer> A. 2 B. 3 C. 5 D. 6",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
499390f1-2198-4785-9c4b-5a7a45151047,test,past,elementary school,u10,3,group 3,post test,3,12,0,increase,A,"If the desired change is positive, and the input is -1, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
dac601b3-1f55-4ee1-93c0-6f6fd641b5d4,test,past,elementary school,u10,3,group 3,post test,4,12,0,decrease,B,"If the desired change is negative, and the input is -2, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
f6c03eb7-1242-4e94-8d26-df966b75d734,test,past,elementary school,u10,3,group 3,post test,1,2,0,Supervised learning,BC,Which of the following learning methods involves learning from a teacher? <please select the answer> A. Unsupervised learning B. Supervised learning C. Reinforcement learning,Outline. Supervised learning: learning from a teacher. Computing the output. Comparing the output to the desired output. Changing the connection weight. Backpropagation.
9fd66c69-3200-4669-81f4-4bf94206b09c,test,future,elementary school,u10,3,group 3,post test,8,21,0,0,C,"If the inner state is 1, then after the ReLU (Rectified Linear Unit), what will the output be? <please select the best answer> A. 2 B. 0 C. 1",Change in the Computation. The output is 5 (because of ReLU) the desired output change: 95 error: the deviation of the actual output from the desired output
4dc556f4-e230-4977-9d12-b9a340d3941c,test,future,elementary school,u10,3,group 3,post test,9,5,1,No,B,"If there is more than one layer of artificial neurons, does the delta rule still work? <please select the best answer> A. Yes B. No",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
ee68443f-55c1-44ac-b2c3-2cca99718738,test,past,elementary school,u10,3,group 3,post test,2,5,0,learning constant;input,ABC,Which of the following options are required to determine the change of one connection in the delta rule (select multiple answers)? <please select the answer> A. learning constant B. desired change C. input D. connection weight,The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
b832f507-e262-4162-a0d7-05f288893318,test,future,elementary school,u10,3,group 3,post test,11,16,1,1.0,A,"After many processes of learning, what value does the output of the 'x' artificial neuron in response to 'x' get closer to? <please select the best answer> A. 1.0 B. 0.0 C. 1.5 D. -1.0",Summary. ANNs work by training the network for samples 'x' and '+' repeatedly. The output of the artificial neuron will become closer and closer to the desired output. It contains a table of relationship between input and neuron.
0c1724ed-47dd-4de3-9d3f-a10b849f661a,test,future,elementary school,u10,3,group 3,post test,6,5,1,2,2,"If the target output is 5 and the computed output is 3, what is the desired change? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
608397ad-9c65-4bf6-91e1-f158044872d9,test,past,elementary school,u10,3,group 3,post test,5,15,0,k ion,4,"If the input of a single-layer ANN model is 1,0,1; and the weight of inputs is 1, 2, 3; what would the output of the single-layer ANN model be? <please input your answer>",Example 3: Weight change for the 'x' neuron. After applying the delta rule the weight pattern of the 'x' artificial neuron will be. It contains a picture of calculation.
2fe8e207-246a-4494-bd03-c661b5f0355f,test,future,elementary school,u10,3,group 3,post test,10,22,0,bigger,A,"If supervised learning works, will the weight become smaller or bigger? <please select the best answer> A. smaller B. bigger",Change in the Computation. Contribution ratio: the ratio between the inner state change and the output change. The weight change proportional to: input * contribution ratio * error = 1*1*95
e08a6495-07b1-47de-b105-7495787a98fd,test,future,elementary school,u10,3,group 3,post test,7,5,0,3,D,"Let the learning constant be 2, the desired change to be 3, and the input to be 1, what will the change of weight be? <please select the best answer> A. 2 B. 3 C. 5 D. 6",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
6e1514c8-e4a3-459f-b79e-d33aa5ddb253,test,past,elementary school,u11,3,group 3,post test,3,12,1,decrease,A,"If the desired change is positive, and the input is -1, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
86fc72e4-cfd5-4c63-bd91-b3a05656a2ed,test,past,elementary school,u11,3,group 3,post test,4,12,1,increase,B,"If the desired change is negative, and the input is -2, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
36031a4b-a61b-4f1e-87c4-a74d3c6832fd,test,past,elementary school,u11,3,group 3,post test,1,2,0,Supervised learning,BC,Which of the following learning methods involves learning from a teacher? <please select the answer> A. Unsupervised learning B. Supervised learning C. Reinforcement learning,Outline. Supervised learning: learning from a teacher. Computing the output. Comparing the output to the desired output. Changing the connection weight. Backpropagation.
e39e0f29-6d69-44dc-b2be-1c172c87fa38,test,future,elementary school,u11,3,group 3,post test,8,21,0,0,C,"If the inner state is 1, then after the ReLU (Rectified Linear Unit), what will the output be? <please select the best answer> A. 2 B. 0 C. 1",Change in the Computation. The output is 5 (because of ReLU) the desired output change: 95 error: the deviation of the actual output from the desired output
56c84b08-81c5-4d21-9034-473d038153c5,test,future,elementary school,u11,3,group 3,post test,9,5,1,No,B,"If there is more than one layer of artificial neurons, does the delta rule still work? <please select the best answer> A. Yes B. No",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
cde8d56d-76c6-43aa-83b5-fe24e1a64a4a,test,past,elementary school,u11,3,group 3,post test,2,5,0,learning constant;desired change;connection weight,ABC,Which of the following options are required to determine the change of one connection in the delta rule (select multiple answers)? <please select the answer> A. learning constant B. desired change C. input D. connection weight,The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
7bfad9bc-74d2-4e03-8695-0cb0c2e83dbf,test,future,elementary school,u11,3,group 3,post test,11,16,0,1.5,A,"After many processes of learning, what value does the output of the 'x' artificial neuron in response to 'x' get closer to? <please select the best answer> A. 1.0 B. 0.0 C. 1.5 D. -1.0",Summary. ANNs work by training the network for samples 'x' and '+' repeatedly. The output of the artificial neuron will become closer and closer to the desired output. It contains a table of relationship between input and neuron.
6a6c2b8f-4c26-4ee0-8761-912019666614,test,future,elementary school,u11,3,group 3,post test,6,5,1,2,2,"If the target output is 5 and the computed output is 3, what is the desired change? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
d22dda5a-1d01-4f9f-90de-f8137ad456f6,test,past,elementary school,u11,3,group 3,post test,5,15,0,"1,2,3",4,"If the input of a single-layer ANN model is 1,0,1; and the weight of inputs is 1, 2, 3; what would the output of the single-layer ANN model be? <please input your answer>",Example 3: Weight change for the 'x' neuron. After applying the delta rule the weight pattern of the 'x' artificial neuron will be. It contains a picture of calculation.
ab7ba13d-55f1-40f6-94ea-8748d5ac81c9,test,future,elementary school,u11,3,group 3,post test,10,22,0,bigger,A,"If supervised learning works, will the weight become smaller or bigger? <please select the best answer> A. smaller B. bigger",Change in the Computation. Contribution ratio: the ratio between the inner state change and the output change. The weight change proportional to: input * contribution ratio * error = 1*1*95
27248c34-96d1-4dda-bd4a-bb6c9fc4f727,test,future,elementary school,u11,3,group 3,post test,7,5,0,5,D,"Let the learning constant be 2, the desired change to be 3, and the input to be 1, what will the change of weight be? <please select the best answer> A. 2 B. 3 C. 5 D. 6",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
aa196b2b-2b0d-4aa0-bd21-fdae8e45f865,train,past,elementary school,u30,3,group 3,post test,3,12,1,decrease,A,"If the desired change is positive, and the input is -1, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
18a870a3-a95f-44c9-a357-c3bbbeffdbff,train,past,elementary school,u30,3,group 3,post test,4,12,0,decrease,B,"If the desired change is negative, and the input is -2, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
bfcf2c39-3bf2-4ddd-b12f-101473ec1347,train,past,elementary school,u30,3,group 3,post test,1,2,0,Supervised learning,BC,Which of the following learning methods involves learning from a teacher? <please select the answer> A. Unsupervised learning B. Supervised learning C. Reinforcement learning,Outline. Supervised learning: learning from a teacher. Computing the output. Comparing the output to the desired output. Changing the connection weight. Backpropagation.
11ad4bf6-69e8-4e73-9996-8642e3d0b17f,train,future,elementary school,u30,3,group 3,post test,8,21,0,2,C,"If the inner state is 1, then after the ReLU (Rectified Linear Unit), what will the output be? <please select the best answer> A. 2 B. 0 C. 1",Change in the Computation. The output is 5 (because of ReLU) the desired output change: 95 error: the deviation of the actual output from the desired output
4341b5d8-5d98-4c76-92d8-f6a213bb8bc5,train,future,elementary school,u30,3,group 3,post test,9,5,1,No,B,"If there is more than one layer of artificial neurons, does the delta rule still work? <please select the best answer> A. Yes B. No",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
bd257f2b-dfdc-46cd-baff-796924c35bc5,train,past,elementary school,u30,3,group 3,post test,2,5,0,desired change;input,ABC,Which of the following options are required to determine the change of one connection in the delta rule (select multiple answers)? <please select the answer> A. learning constant B. desired change C. input D. connection weight,The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
4c2193d0-6e81-4c9d-9a56-1bc71a650377,train,future,elementary school,u30,3,group 3,post test,11,16,0,1.5,A,"After many processes of learning, what value does the output of the 'x' artificial neuron in response to 'x' get closer to? <please select the best answer> A. 1.0 B. 0.0 C. 1.5 D. -1.0",Summary. ANNs work by training the network for samples 'x' and '+' repeatedly. The output of the artificial neuron will become closer and closer to the desired output. It contains a table of relationship between input and neuron.
83b113c7-56b2-450b-98d0-5eb7a864460a,train,future,elementary school,u30,3,group 3,post test,6,5,1,2,2,"If the target output is 5 and the computed output is 3, what is the desired change? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
f2f84f17-b044-4693-952f-835a35070556,train,past,elementary school,u30,3,group 3,post test,5,15,0,?,4,"If the input of a single-layer ANN model is 1,0,1; and the weight of inputs is 1, 2, 3; what would the output of the single-layer ANN model be? <please input your answer>",Example 3: Weight change for the 'x' neuron. After applying the delta rule the weight pattern of the 'x' artificial neuron will be. It contains a picture of calculation.
e1e47c4b-f1d8-4680-beb3-a1e0b02ccece,train,future,elementary school,u30,3,group 3,post test,10,22,0,bigger,A,"If supervised learning works, will the weight become smaller or bigger? <please select the best answer> A. smaller B. bigger",Change in the Computation. Contribution ratio: the ratio between the inner state change and the output change. The weight change proportional to: input * contribution ratio * error = 1*1*95
a802b136-f19b-478c-96f8-b8ffa646aec6,train,future,elementary school,u30,3,group 3,post test,7,5,0,2,D,"Let the learning constant be 2, the desired change to be 3, and the input to be 1, what will the change of weight be? <please select the best answer> A. 2 B. 3 C. 5 D. 6",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
31478f15-a23c-40a8-9fec-9b4b5d7178d8,train,past,elementary school,u38,3,group 3,post test,3,12,1,decrease,A,"If the desired change is positive, and the input is -1, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
08aceacd-36ef-4fa9-8e98-ddb255dc2526,train,past,elementary school,u38,3,group 3,post test,4,12,1,increase,B,"If the desired change is negative, and the input is -2, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
3ef513dd-6bc1-4491-8e96-2b30199351bd,train,past,elementary school,u38,3,group 3,post test,1,2,0,Supervised learning,BC,Which of the following learning methods involves learning from a teacher? <please select the answer> A. Unsupervised learning B. Supervised learning C. Reinforcement learning,Outline. Supervised learning: learning from a teacher. Computing the output. Comparing the output to the desired output. Changing the connection weight. Backpropagation.
3a5c0df2-0f6a-4f0a-a250-f53875fdea66,train,future,elementary school,u38,3,group 3,post test,8,21,0,2,C,"If the inner state is 1, then after the ReLU (Rectified Linear Unit), what will the output be? <please select the best answer> A. 2 B. 0 C. 1",Change in the Computation. The output is 5 (because of ReLU) the desired output change: 95 error: the deviation of the actual output from the desired output
e6eb911b-aac1-4f0e-b79e-7eaf6308155d,train,future,elementary school,u38,3,group 3,post test,9,5,1,No,B,"If there is more than one layer of artificial neurons, does the delta rule still work? <please select the best answer> A. Yes B. No",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
cd2043f8-7de1-4b5f-8616-823d3144f424,train,past,elementary school,u38,3,group 3,post test,2,5,0,desired change;input,ABC,Which of the following options are required to determine the change of one connection in the delta rule (select multiple answers)? <please select the answer> A. learning constant B. desired change C. input D. connection weight,The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
b6d5624e-433b-483d-b97b-fe0db092e2c0,train,future,elementary school,u38,3,group 3,post test,11,16,0,1.5,A,"After many processes of learning, what value does the output of the 'x' artificial neuron in response to 'x' get closer to? <please select the best answer> A. 1.0 B. 0.0 C. 1.5 D. -1.0",Summary. ANNs work by training the network for samples 'x' and '+' repeatedly. The output of the artificial neuron will become closer and closer to the desired output. It contains a table of relationship between input and neuron.
ede77d20-a20f-4ea2-8ca0-8255a06aebeb,train,future,elementary school,u38,3,group 3,post test,6,5,1,2,2,"If the target output is 5 and the computed output is 3, what is the desired change? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
88522616-b8d5-4934-864e-05e0bace6835,train,past,elementary school,u38,3,group 3,post test,5,15,0,"1,2,3",4,"If the input of a single-layer ANN model is 1,0,1; and the weight of inputs is 1, 2, 3; what would the output of the single-layer ANN model be? <please input your answer>",Example 3: Weight change for the 'x' neuron. After applying the delta rule the weight pattern of the 'x' artificial neuron will be. It contains a picture of calculation.
f3d2b8c0-6c3c-441d-ab60-eb1074e76051,train,future,elementary school,u38,3,group 3,post test,10,22,1,smaller,A,"If supervised learning works, will the weight become smaller or bigger? <please select the best answer> A. smaller B. bigger",Change in the Computation. Contribution ratio: the ratio between the inner state change and the output change. The weight change proportional to: input * contribution ratio * error = 1*1*95
fbd442b8-22ee-4a5b-bb59-0bd0457e07a1,train,future,elementary school,u38,3,group 3,post test,7,5,0,3,D,"Let the learning constant be 2, the desired change to be 3, and the input to be 1, what will the change of weight be? <please select the best answer> A. 2 B. 3 C. 5 D. 6",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
88a8c31d-6245-4649-b773-c4e4efee27bf,train,past,elementary school,u15,3,group 3,post test,3,12,0,increase,A,"If the desired change is positive, and the input is -1, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
78413fae-0110-4870-97f1-e8a40c616213,train,past,elementary school,u15,3,group 3,post test,4,12,0,decrease,B,"If the desired change is negative, and the input is -2, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
09bf28aa-9d42-44c3-a9be-baa5196e320b,train,past,elementary school,u15,3,group 3,post test,1,2,0,Supervised learning,BC,Which of the following learning methods involves learning from a teacher? <please select the answer> A. Unsupervised learning B. Supervised learning C. Reinforcement learning,Outline. Supervised learning: learning from a teacher. Computing the output. Comparing the output to the desired output. Changing the connection weight. Backpropagation.
51906e99-bc93-4fcf-9769-7df769011f55,train,future,elementary school,u15,3,group 3,post test,8,21,1,1,C,"If the inner state is 1, then after the ReLU (Rectified Linear Unit), what will the output be? <please select the best answer> A. 2 B. 0 C. 1",Change in the Computation. The output is 5 (because of ReLU) the desired output change: 95 error: the deviation of the actual output from the desired output
c71ba974-e245-4caf-80ab-d246c74ca918,train,future,elementary school,u15,3,group 3,post test,9,5,1,No,B,"If there is more than one layer of artificial neurons, does the delta rule still work? <please select the best answer> A. Yes B. No",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
24d05451-3056-473c-b52f-b9d3a0a8abce,train,past,elementary school,u15,3,group 3,post test,2,5,0,learning constant;desired change;connection weight,ABC,Which of the following options are required to determine the change of one connection in the delta rule (select multiple answers)? <please select the answer> A. learning constant B. desired change C. input D. connection weight,The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
2ebe96d4-7b8c-4d74-8391-9da155408c01,train,future,elementary school,u15,3,group 3,post test,11,16,1,1.0,A,"After many processes of learning, what value does the output of the 'x' artificial neuron in response to 'x' get closer to? <please select the best answer> A. 1.0 B. 0.0 C. 1.5 D. -1.0",Summary. ANNs work by training the network for samples 'x' and '+' repeatedly. The output of the artificial neuron will become closer and closer to the desired output. It contains a table of relationship between input and neuron.
7a071e5a-4706-4cec-bde0-fca53ec852e6,train,future,elementary school,u15,3,group 3,post test,6,5,1,2,2,"If the target output is 5 and the computed output is 3, what is the desired change? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
2e2119ae-bd3e-41ce-a3ce-d28fff0a9628,train,past,elementary school,u15,3,group 3,post test,5,15,0,6,4,"If the input of a single-layer ANN model is 1,0,1; and the weight of inputs is 1, 2, 3; what would the output of the single-layer ANN model be? <please input your answer>",Example 3: Weight change for the 'x' neuron. After applying the delta rule the weight pattern of the 'x' artificial neuron will be. It contains a picture of calculation.
9ab59c4a-d5b8-4834-8d7c-aa33068c6434,train,future,elementary school,u15,3,group 3,post test,10,22,0,bigger,A,"If supervised learning works, will the weight become smaller or bigger? <please select the best answer> A. smaller B. bigger",Change in the Computation. Contribution ratio: the ratio between the inner state change and the output change. The weight change proportional to: input * contribution ratio * error = 1*1*95
4f63d0bc-0aa0-4fb7-bd43-3d989e873756,train,future,elementary school,u15,3,group 3,post test,7,5,0,2,D,"Let the learning constant be 2, the desired change to be 3, and the input to be 1, what will the change of weight be? <please select the best answer> A. 2 B. 3 C. 5 D. 6",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
5e870b29-69ec-43a7-adc5-321051324776,train,past,elementary school,u40,7,group 1,post test,3,5,0,C,D,"In reinforcement learning, which two kinds of response does the agent get from its environment? <please select the best answer> A. Action, Reward B. Value, State C. Action, Value D. State, Reward","Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
72dd98d8-4af0-49d5-9163-bb3bd105537b,train,past,elementary school,u40,7,group 1,post test,4,4,0,B,C,"Please select one of the following which falls into the framework of reinforcement learning. <please select the best answer> A. A computer calculates the digits of π, a mathematical constant which is close to 3.14. B. A neural network learns to distinguish images with known categories as cars or bicycles. C. An autonomous car tries to adapt to changing road conditions without causing accidents. D. A software collects user information and provides personalized recommendations automatically.",The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
65803af8-8033-4d4a-8f31-d9f0de26d6cd,train,past,elementary school,u40,7,group 1,post test,1,5,1,A,A,True or False: Reinforcement learning gets inputs as well as produces outputs? <please select the best answer> A. True   B. False,"Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
866a6f6d-b31e-41ac-adaa-7205ac55c732,train,future,elementary school,u40,7,group 1,post test,8,17,0,C,B,"If the value (V) in the current state is only indicated by the current reward (r), what is the relationship between them if we consider the variation of reward (r)? <please select the best answer> A. V = r B. V = V_old + 0.1 * (r - V_old) C. V = 0.1 * (r + 0.5 * V_next) D. V = V_old + 0.1 * ((r + 0.5 * V_next) - V_old)","The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. However, r is not always consistent in real world. new state = s. reward = r. Value of s: V = V_old + α * (r - V_old). Averaging the old value with new reward. A picture showing a mouse going through a maze where each cell is a state."
e8ee6c3c-2923-40b8-966a-e19b5d7b7440,train,future,elementary school,u40,7,group 1,post test,9,14,0,A,D,Which of the following options best defines the value of a given state from the environment? <please select the best answer> A. The value is the immediate reward the agent receives from the environment. B. The value is the association between what action to take given the observation. C. The value is the place within which the reinforcement learning agent operates. D. The value is the best expected total reward an agent will receive given a state.,Value learning (V-learning). Value learning places a value on the situation. Learning how good or bad the situation is can be important. Value of a situation: The total reward that an agent can expect to collect from that state and onwards into the future. Two animations showing two different total rewards a agent could get by choosing different actions.
2929a6a3-1438-4924-9625-647f5e8c7227,train,past,elementary school,u40,7,group 1,post test,2,6,0,D,C,Which of the following fields is the origin of the concept of reinforcement learning? <please select the best answer> A. Artificial  intelligence B. K-12 Education C. Psychological science D. Electric engineering,"History of reinforcement learning. Reinforcement learning was originally a concept used in behavioral psychology. Richard Sutton, a Canadian computer scientist, is one of the pioneers in the development of reinforcement learning in the context of AI. He contributed to a RL method called: Temporal Difference learning. A picture of Richard Sutton."
ab500065-eb5c-4434-a702-3a20bc4029c6,train,future,elementary school,u40,7,group 1,post test,11,19,0,A,B,"If a problem or a game has a lot of states, like the Go game, then we will need a neural network. What relationship do we expect the neural network to capture? <please select the best answer> A. The reward an agent receive after action  B. The value of a given state of the environment C. The action to take under a state of the environment D. The next state of the environment after agent takes an action",Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
7e258c8e-75eb-423b-bbd5-4da02c41bdac,train,future,elementary school,u40,7,group 1,post test,6,8,1,pac man,pac-man,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the agent of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
2fb17424-ebc1-470a-95ba-991f4b5c8534,train,past,elementary school,u40,7,group 1,post test,5,4,0,A,B,Which of the following best describes the jobs suitable for learning methods that fall into the category of reinforcement learning? <please select the best answer> A. Reinforcement learning is good at clustering data without help from humans. B. Reinforcement learning is good at producing a series of actions to achieve the goal. C. Reinforcement learning is good at recognizing the item in a given image D. Reinforcement learning is good at compressing data and filtering out noise in data.,The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
59fe2b9b-75a2-4986-be4e-12feef89af7d,train,future,elementary school,u40,7,group 1,post test,10,19,0,345,A table/lookup dictionary,What can reinforcement learning use when an ANN is not required because of the limited number of states and actions? <please input your answer>,Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
f9f90509-e8af-495f-a274-ac2b9efc0564,train,future,elementary school,u40,7,group 1,post test,7,8,1,maze,location,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the state of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
a8f70720-4abf-46f1-b0c6-4893b8b71cd3,train,past,elementary school,u41,7,group 1,post test,3,5,1,D,D,"In reinforcement learning, which two kinds of response does the agent get from its environment? <please select the best answer> A. Action, Reward B. Value, State C. Action, Value D. State, Reward","Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
fcccb067-7432-45ed-a5ec-d6d8421f0840,train,past,elementary school,u41,7,group 1,post test,4,4,1,C,C,"Please select one of the following which falls into the framework of reinforcement learning. <please select the best answer> A. A computer calculates the digits of π, a mathematical constant which is close to 3.14. B. A neural network learns to distinguish images with known categories as cars or bicycles. C. An autonomous car tries to adapt to changing road conditions without causing accidents. D. A software collects user information and provides personalized recommendations automatically.",The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
f8b6af57-4ed6-49f4-b52f-ef4276cbb144,train,past,elementary school,u41,7,group 1,post test,1,5,1,A,A,True or False: Reinforcement learning gets inputs as well as produces outputs? <please select the best answer> A. True   B. False,"Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
03af0cc7-52df-4bd1-9f07-ed4a57c9f3c7,train,future,elementary school,u41,7,group 1,post test,8,17,1,B,B,"If the value (V) in the current state is only indicated by the current reward (r), what is the relationship between them if we consider the variation of reward (r)? <please select the best answer> A. V = r B. V = V_old + 0.1 * (r - V_old) C. V = 0.1 * (r + 0.5 * V_next) D. V = V_old + 0.1 * ((r + 0.5 * V_next) - V_old)","The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. However, r is not always consistent in real world. new state = s. reward = r. Value of s: V = V_old + α * (r - V_old). Averaging the old value with new reward. A picture showing a mouse going through a maze where each cell is a state."
8ab12cb6-2b45-49c5-ac95-df734f366b08,train,future,elementary school,u41,7,group 1,post test,9,14,1,D,D,Which of the following options best defines the value of a given state from the environment? <please select the best answer> A. The value is the immediate reward the agent receives from the environment. B. The value is the association between what action to take given the observation. C. The value is the place within which the reinforcement learning agent operates. D. The value is the best expected total reward an agent will receive given a state.,Value learning (V-learning). Value learning places a value on the situation. Learning how good or bad the situation is can be important. Value of a situation: The total reward that an agent can expect to collect from that state and onwards into the future. Two animations showing two different total rewards a agent could get by choosing different actions.
16fc0d1c-5e3a-4aeb-baef-39a4ff1801bf,train,past,elementary school,u41,7,group 1,post test,2,6,1,C,C,Which of the following fields is the origin of the concept of reinforcement learning? <please select the best answer> A. Artificial  intelligence B. K-12 Education C. Psychological science D. Electric engineering,"History of reinforcement learning. Reinforcement learning was originally a concept used in behavioral psychology. Richard Sutton, a Canadian computer scientist, is one of the pioneers in the development of reinforcement learning in the context of AI. He contributed to a RL method called: Temporal Difference learning. A picture of Richard Sutton."
34fd1611-7ce5-4f51-a8b5-4724f0ce058c,train,future,elementary school,u41,7,group 1,post test,11,19,1,B,B,"If a problem or a game has a lot of states, like the Go game, then we will need a neural network. What relationship do we expect the neural network to capture? <please select the best answer> A. The reward an agent receive after action  B. The value of a given state of the environment C. The action to take under a state of the environment D. The next state of the environment after agent takes an action",Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
c64bb15d-027a-4709-b5ed-d4f422e5faf0,train,future,elementary school,u41,7,group 1,post test,6,8,1,pac-man,pac-man,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the agent of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
e18b3a91-7cfd-4d87-b898-0dac5b2d34a4,train,past,elementary school,u41,7,group 1,post test,5,4,1,B,B,Which of the following best describes the jobs suitable for learning methods that fall into the category of reinforcement learning? <please select the best answer> A. Reinforcement learning is good at clustering data without help from humans. B. Reinforcement learning is good at producing a series of actions to achieve the goal. C. Reinforcement learning is good at recognizing the item in a given image D. Reinforcement learning is good at compressing data and filtering out noise in data.,The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
9514aadb-b9fe-468a-8626-489f88e19b9f,train,future,elementary school,u41,7,group 1,post test,10,19,1,Table,A table/lookup dictionary,What can reinforcement learning use when an ANN is not required because of the limited number of states and actions? <please input your answer>,Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
c818b773-0f0e-4891-bead-cc93be5194f0,train,future,elementary school,u41,7,group 1,post test,7,8,1,Location,location,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the state of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
47a25149-f9db-4c87-bd48-5813e1974cd0,train,past,elementary school,u42,7,group 1,post test,3,5,0,C,D,"In reinforcement learning, which two kinds of response does the agent get from its environment? <please select the best answer> A. Action, Reward B. Value, State C. Action, Value D. State, Reward","Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
8a24d5c0-6b1f-443f-ae1c-869d0e1e1d40,train,past,elementary school,u42,7,group 1,post test,4,4,0,B,C,"Please select one of the following which falls into the framework of reinforcement learning. <please select the best answer> A. A computer calculates the digits of π, a mathematical constant which is close to 3.14. B. A neural network learns to distinguish images with known categories as cars or bicycles. C. An autonomous car tries to adapt to changing road conditions without causing accidents. D. A software collects user information and provides personalized recommendations automatically.",The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
e6cc99d1-bcb5-4a04-9744-3f19b4701ad6,train,past,elementary school,u42,7,group 1,post test,1,5,0,B,A,True or False: Reinforcement learning gets inputs as well as produces outputs? <please select the best answer> A. True   B. False,"Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
883289c0-ec75-45b0-8986-85f8e6204002,train,future,elementary school,u42,7,group 1,post test,8,17,1,B,B,"If the value (V) in the current state is only indicated by the current reward (r), what is the relationship between them if we consider the variation of reward (r)? <please select the best answer> A. V = r B. V = V_old + 0.1 * (r - V_old) C. V = 0.1 * (r + 0.5 * V_next) D. V = V_old + 0.1 * ((r + 0.5 * V_next) - V_old)","The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. However, r is not always consistent in real world. new state = s. reward = r. Value of s: V = V_old + α * (r - V_old). Averaging the old value with new reward. A picture showing a mouse going through a maze where each cell is a state."
a46372d7-06cf-4cca-8008-74d1bbc5aa1e,train,future,elementary school,u42,7,group 1,post test,9,14,0,C,D,Which of the following options best defines the value of a given state from the environment? <please select the best answer> A. The value is the immediate reward the agent receives from the environment. B. The value is the association between what action to take given the observation. C. The value is the place within which the reinforcement learning agent operates. D. The value is the best expected total reward an agent will receive given a state.,Value learning (V-learning). Value learning places a value on the situation. Learning how good or bad the situation is can be important. Value of a situation: The total reward that an agent can expect to collect from that state and onwards into the future. Two animations showing two different total rewards a agent could get by choosing different actions.
77c5cc43-2e7b-4585-8447-55d96665d553,train,past,elementary school,u42,7,group 1,post test,2,6,0,B,C,Which of the following fields is the origin of the concept of reinforcement learning? <please select the best answer> A. Artificial  intelligence B. K-12 Education C. Psychological science D. Electric engineering,"History of reinforcement learning. Reinforcement learning was originally a concept used in behavioral psychology. Richard Sutton, a Canadian computer scientist, is one of the pioneers in the development of reinforcement learning in the context of AI. He contributed to a RL method called: Temporal Difference learning. A picture of Richard Sutton."
d4fe9f30-6368-4fe8-a221-57c343ee8dff,train,future,elementary school,u42,7,group 1,post test,11,19,1,B,B,"If a problem or a game has a lot of states, like the Go game, then we will need a neural network. What relationship do we expect the neural network to capture? <please select the best answer> A. The reward an agent receive after action  B. The value of a given state of the environment C. The action to take under a state of the environment D. The next state of the environment after agent takes an action",Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
b2d91f57-583e-4e15-8765-f2e641b99113,train,future,elementary school,u42,7,group 1,post test,6,8,0,IDK,pac-man,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the agent of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
37a5054b-4bdd-4401-90d7-570aeeda579f,train,past,elementary school,u42,7,group 1,post test,5,4,1,B,B,Which of the following best describes the jobs suitable for learning methods that fall into the category of reinforcement learning? <please select the best answer> A. Reinforcement learning is good at clustering data without help from humans. B. Reinforcement learning is good at producing a series of actions to achieve the goal. C. Reinforcement learning is good at recognizing the item in a given image D. Reinforcement learning is good at compressing data and filtering out noise in data.,The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
c9b7b386-4422-4d68-a8df-f3af97151a03,train,future,elementary school,u42,7,group 1,post test,10,19,0,IDK,A table/lookup dictionary,What can reinforcement learning use when an ANN is not required because of the limited number of states and actions? <please input your answer>,Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
76286856-de2d-4dac-a5f4-77f5d2fe8675,train,future,elementary school,u42,7,group 1,post test,7,8,0,IDK,location,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the state of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
3b3c4406-9861-4253-b2aa-e4cf079a206b,train,past,elementary school,u31,7,group 1,post test,3,5,0,B,D,"In reinforcement learning, which two kinds of response does the agent get from its environment? <please select the best answer> A. Action, Reward B. Value, State C. Action, Value D. State, Reward","Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
1c237e24-8ed5-4450-a59b-601b3b37dbe2,train,past,elementary school,u31,7,group 1,post test,4,4,0,B,C,"Please select one of the following which falls into the framework of reinforcement learning. <please select the best answer> A. A computer calculates the digits of π, a mathematical constant which is close to 3.14. B. A neural network learns to distinguish images with known categories as cars or bicycles. C. An autonomous car tries to adapt to changing road conditions without causing accidents. D. A software collects user information and provides personalized recommendations automatically.",The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
1e554200-2426-4853-a417-8d3d5166d6c9,train,past,elementary school,u31,7,group 1,post test,1,5,0,B,A,True or False: Reinforcement learning gets inputs as well as produces outputs? <please select the best answer> A. True   B. False,"Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
b921eae0-4e7c-4e7e-85b0-713a9ce87258,train,future,elementary school,u31,7,group 1,post test,8,17,1,B,B,"If the value (V) in the current state is only indicated by the current reward (r), what is the relationship between them if we consider the variation of reward (r)? <please select the best answer> A. V = r B. V = V_old + 0.1 * (r - V_old) C. V = 0.1 * (r + 0.5 * V_next) D. V = V_old + 0.1 * ((r + 0.5 * V_next) - V_old)","The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. However, r is not always consistent in real world. new state = s. reward = r. Value of s: V = V_old + α * (r - V_old). Averaging the old value with new reward. A picture showing a mouse going through a maze where each cell is a state."
37a6da51-3542-4428-81e3-095989850ed5,train,future,elementary school,u31,7,group 1,post test,9,14,0,C,D,Which of the following options best defines the value of a given state from the environment? <please select the best answer> A. The value is the immediate reward the agent receives from the environment. B. The value is the association between what action to take given the observation. C. The value is the place within which the reinforcement learning agent operates. D. The value is the best expected total reward an agent will receive given a state.,Value learning (V-learning). Value learning places a value on the situation. Learning how good or bad the situation is can be important. Value of a situation: The total reward that an agent can expect to collect from that state and onwards into the future. Two animations showing two different total rewards a agent could get by choosing different actions.
72872637-7e44-4464-a775-250f596cdccc,train,past,elementary school,u31,7,group 1,post test,2,6,0,B,C,Which of the following fields is the origin of the concept of reinforcement learning? <please select the best answer> A. Artificial  intelligence B. K-12 Education C. Psychological science D. Electric engineering,"History of reinforcement learning. Reinforcement learning was originally a concept used in behavioral psychology. Richard Sutton, a Canadian computer scientist, is one of the pioneers in the development of reinforcement learning in the context of AI. He contributed to a RL method called: Temporal Difference learning. A picture of Richard Sutton."
10868a7b-d799-4b54-b548-65cafe770b11,train,future,elementary school,u31,7,group 1,post test,11,19,0,A,B,"If a problem or a game has a lot of states, like the Go game, then we will need a neural network. What relationship do we expect the neural network to capture? <please select the best answer> A. The reward an agent receive after action  B. The value of a given state of the environment C. The action to take under a state of the environment D. The next state of the environment after agent takes an action",Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
dadfbd54-0c07-4e9e-8610-5acb5736f3e0,train,future,elementary school,u31,7,group 1,post test,6,8,0,??????????,pac-man,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the agent of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
9c433bb7-c383-4e19-96e5-3729c463806b,train,past,elementary school,u31,7,group 1,post test,5,4,0,A,B,Which of the following best describes the jobs suitable for learning methods that fall into the category of reinforcement learning? <please select the best answer> A. Reinforcement learning is good at clustering data without help from humans. B. Reinforcement learning is good at producing a series of actions to achieve the goal. C. Reinforcement learning is good at recognizing the item in a given image D. Reinforcement learning is good at compressing data and filtering out noise in data.,The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
7ac708aa-d387-4f31-a799-d2aef15c32cc,train,future,elementary school,u31,7,group 1,post test,10,19,0,what?,A table/lookup dictionary,What can reinforcement learning use when an ANN is not required because of the limited number of states and actions? <please input your answer>,Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
df8de51c-74de-4180-ac06-200e51a9dc39,train,future,elementary school,u31,7,group 1,post test,7,8,0,???????,location,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the state of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
d00d5076-6ba5-445f-bfbc-9889f7c05b6d,train,past,elementary school,u20,7,group 1,post test,3,5,0,A,D,"In reinforcement learning, which two kinds of response does the agent get from its environment? <please select the best answer> A. Action, Reward B. Value, State C. Action, Value D. State, Reward","Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
c8b06f5c-01b5-4a10-a662-6503f5645f86,train,past,elementary school,u20,7,group 1,post test,4,4,0,A,C,"Please select one of the following which falls into the framework of reinforcement learning. <please select the best answer> A. A computer calculates the digits of π, a mathematical constant which is close to 3.14. B. A neural network learns to distinguish images with known categories as cars or bicycles. C. An autonomous car tries to adapt to changing road conditions without causing accidents. D. A software collects user information and provides personalized recommendations automatically.",The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
5ec42f69-1ea6-4434-a696-fe26108f6732,train,past,elementary school,u20,7,group 1,post test,1,5,1,A,A,True or False: Reinforcement learning gets inputs as well as produces outputs? <please select the best answer> A. True   B. False,"Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
1703f2a1-4ced-44c0-819d-75bd75503e92,train,future,elementary school,u20,7,group 1,post test,8,17,1,B,B,"If the value (V) in the current state is only indicated by the current reward (r), what is the relationship between them if we consider the variation of reward (r)? <please select the best answer> A. V = r B. V = V_old + 0.1 * (r - V_old) C. V = 0.1 * (r + 0.5 * V_next) D. V = V_old + 0.1 * ((r + 0.5 * V_next) - V_old)","The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. However, r is not always consistent in real world. new state = s. reward = r. Value of s: V = V_old + α * (r - V_old). Averaging the old value with new reward. A picture showing a mouse going through a maze where each cell is a state."
6682e32d-331e-4446-92f5-4ff1cafea558,train,future,elementary school,u20,7,group 1,post test,9,14,0,A,D,Which of the following options best defines the value of a given state from the environment? <please select the best answer> A. The value is the immediate reward the agent receives from the environment. B. The value is the association between what action to take given the observation. C. The value is the place within which the reinforcement learning agent operates. D. The value is the best expected total reward an agent will receive given a state.,Value learning (V-learning). Value learning places a value on the situation. Learning how good or bad the situation is can be important. Value of a situation: The total reward that an agent can expect to collect from that state and onwards into the future. Two animations showing two different total rewards a agent could get by choosing different actions.
f6354e30-109f-4770-9df9-7119599b8d62,train,past,elementary school,u20,7,group 1,post test,2,6,0,A,C,Which of the following fields is the origin of the concept of reinforcement learning? <please select the best answer> A. Artificial  intelligence B. K-12 Education C. Psychological science D. Electric engineering,"History of reinforcement learning. Reinforcement learning was originally a concept used in behavioral psychology. Richard Sutton, a Canadian computer scientist, is one of the pioneers in the development of reinforcement learning in the context of AI. He contributed to a RL method called: Temporal Difference learning. A picture of Richard Sutton."
b1964c84-c4c7-4606-8747-52236c145b58,train,future,elementary school,u20,7,group 1,post test,11,19,0,A,B,"If a problem or a game has a lot of states, like the Go game, then we will need a neural network. What relationship do we expect the neural network to capture? <please select the best answer> A. The reward an agent receive after action  B. The value of a given state of the environment C. The action to take under a state of the environment D. The next state of the environment after agent takes an action",Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
7b06b382-4f9a-49b0-9a9d-436c9f795d53,train,future,elementary school,u20,7,group 1,post test,6,8,1,pac-man,pac-man,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the agent of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
c05e4236-0da0-4a1f-bbb2-a50761b0e095,train,past,elementary school,u20,7,group 1,post test,5,4,0,A,B,Which of the following best describes the jobs suitable for learning methods that fall into the category of reinforcement learning? <please select the best answer> A. Reinforcement learning is good at clustering data without help from humans. B. Reinforcement learning is good at producing a series of actions to achieve the goal. C. Reinforcement learning is good at recognizing the item in a given image D. Reinforcement learning is good at compressing data and filtering out noise in data.,The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
6333c385-4757-4025-8c5a-4c95e93634d3,train,future,elementary school,u20,7,group 1,post test,10,19,0,IDK,A table/lookup dictionary,What can reinforcement learning use when an ANN is not required because of the limited number of states and actions? <please input your answer>,Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
c31765ef-a51b-4da6-b3b0-fa8b2a4a5293,train,future,elementary school,u20,7,group 1,post test,7,8,0,alice,location,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the state of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
7d552d1d-0c11-427c-babe-f74c098bed63,test,past,elementary school,u5,7,group 1,post test,3,5,0,B,D,"In reinforcement learning, which two kinds of response does the agent get from its environment? <please select the best answer> A. Action, Reward B. Value, State C. Action, Value D. State, Reward","Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
c7cf4ca8-750d-43c2-9a99-9349eef55615,test,past,elementary school,u5,7,group 1,post test,4,4,0,B,C,"Please select one of the following which falls into the framework of reinforcement learning. <please select the best answer> A. A computer calculates the digits of π, a mathematical constant which is close to 3.14. B. A neural network learns to distinguish images with known categories as cars or bicycles. C. An autonomous car tries to adapt to changing road conditions without causing accidents. D. A software collects user information and provides personalized recommendations automatically.",The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
8f761022-9f77-4e98-9e40-983e8f4aca45,test,past,elementary school,u5,7,group 1,post test,1,5,1,A,A,True or False: Reinforcement learning gets inputs as well as produces outputs? <please select the best answer> A. True   B. False,"Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
f0daf8c3-ccc7-4b17-962d-6ea1ed813012,test,future,elementary school,u5,7,group 1,post test,8,17,0,D,B,"If the value (V) in the current state is only indicated by the current reward (r), what is the relationship between them if we consider the variation of reward (r)? <please select the best answer> A. V = r B. V = V_old + 0.1 * (r - V_old) C. V = 0.1 * (r + 0.5 * V_next) D. V = V_old + 0.1 * ((r + 0.5 * V_next) - V_old)","The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. However, r is not always consistent in real world. new state = s. reward = r. Value of s: V = V_old + α * (r - V_old). Averaging the old value with new reward. A picture showing a mouse going through a maze where each cell is a state."
3987a2e3-9ab8-4524-84ab-8304a80aa2f1,test,future,elementary school,u5,7,group 1,post test,9,14,0,B,D,Which of the following options best defines the value of a given state from the environment? <please select the best answer> A. The value is the immediate reward the agent receives from the environment. B. The value is the association between what action to take given the observation. C. The value is the place within which the reinforcement learning agent operates. D. The value is the best expected total reward an agent will receive given a state.,Value learning (V-learning). Value learning places a value on the situation. Learning how good or bad the situation is can be important. Value of a situation: The total reward that an agent can expect to collect from that state and onwards into the future. Two animations showing two different total rewards a agent could get by choosing different actions.
1fffa640-3ffa-4238-ad97-ffcc808d24ee,test,past,elementary school,u5,7,group 1,post test,2,6,0,A,C,Which of the following fields is the origin of the concept of reinforcement learning? <please select the best answer> A. Artificial  intelligence B. K-12 Education C. Psychological science D. Electric engineering,"History of reinforcement learning. Reinforcement learning was originally a concept used in behavioral psychology. Richard Sutton, a Canadian computer scientist, is one of the pioneers in the development of reinforcement learning in the context of AI. He contributed to a RL method called: Temporal Difference learning. A picture of Richard Sutton."
7510232d-cb3a-42f2-ad6e-9edd30bea0bb,test,future,elementary school,u5,7,group 1,post test,11,19,0,A,B,"If a problem or a game has a lot of states, like the Go game, then we will need a neural network. What relationship do we expect the neural network to capture? <please select the best answer> A. The reward an agent receive after action  B. The value of a given state of the environment C. The action to take under a state of the environment D. The next state of the environment after agent takes an action",Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
387a3b9a-84ea-49f3-a22e-38fdf4af87b4,test,future,elementary school,u5,7,group 1,post test,6,8,0,pizza man,pac-man,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the agent of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
152c9384-f0ed-4d7d-bfe2-aaf2c652f3d1,test,past,elementary school,u5,7,group 1,post test,5,4,0,D,B,Which of the following best describes the jobs suitable for learning methods that fall into the category of reinforcement learning? <please select the best answer> A. Reinforcement learning is good at clustering data without help from humans. B. Reinforcement learning is good at producing a series of actions to achieve the goal. C. Reinforcement learning is good at recognizing the item in a given image D. Reinforcement learning is good at compressing data and filtering out noise in data.,The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
7b9d4534-92f0-40fc-8b69-f007857f73d4,test,future,elementary school,u5,7,group 1,post test,10,19,0,yes,A table/lookup dictionary,What can reinforcement learning use when an ANN is not required because of the limited number of states and actions? <please input your answer>,Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
50795dfb-59f5-4bdb-9a21-0bfe9572136e,test,future,elementary school,u5,7,group 1,post test,7,8,0,bad,location,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the state of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
4052e049-022f-4f60-a664-9ea5b07eb071,train,past,elementary school,u43,7,group 1,post test,3,5,1,D,D,"In reinforcement learning, which two kinds of response does the agent get from its environment? <please select the best answer> A. Action, Reward B. Value, State C. Action, Value D. State, Reward","Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
6ccfc96e-59ec-4872-8369-d365e008c07f,train,past,elementary school,u43,7,group 1,post test,4,4,1,C,C,"Please select one of the following which falls into the framework of reinforcement learning. <please select the best answer> A. A computer calculates the digits of π, a mathematical constant which is close to 3.14. B. A neural network learns to distinguish images with known categories as cars or bicycles. C. An autonomous car tries to adapt to changing road conditions without causing accidents. D. A software collects user information and provides personalized recommendations automatically.",The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
c70628a4-2cf3-49b9-8ee3-8cdbaa47ddd4,train,past,elementary school,u43,7,group 1,post test,1,5,1,A,A,True or False: Reinforcement learning gets inputs as well as produces outputs? <please select the best answer> A. True   B. False,"Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
f3b2411f-c79c-4b46-a52a-77c4510ee4bd,train,future,elementary school,u43,7,group 1,post test,8,17,1,B,B,"If the value (V) in the current state is only indicated by the current reward (r), what is the relationship between them if we consider the variation of reward (r)? <please select the best answer> A. V = r B. V = V_old + 0.1 * (r - V_old) C. V = 0.1 * (r + 0.5 * V_next) D. V = V_old + 0.1 * ((r + 0.5 * V_next) - V_old)","The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. However, r is not always consistent in real world. new state = s. reward = r. Value of s: V = V_old + α * (r - V_old). Averaging the old value with new reward. A picture showing a mouse going through a maze where each cell is a state."
8f92d235-30ed-4af7-ab4d-153a53c9a80a,train,future,elementary school,u43,7,group 1,post test,9,14,1,D,D,Which of the following options best defines the value of a given state from the environment? <please select the best answer> A. The value is the immediate reward the agent receives from the environment. B. The value is the association between what action to take given the observation. C. The value is the place within which the reinforcement learning agent operates. D. The value is the best expected total reward an agent will receive given a state.,Value learning (V-learning). Value learning places a value on the situation. Learning how good or bad the situation is can be important. Value of a situation: The total reward that an agent can expect to collect from that state and onwards into the future. Two animations showing two different total rewards a agent could get by choosing different actions.
66df49d8-b60d-429d-b091-25022312bf0b,train,past,elementary school,u43,7,group 1,post test,2,6,1,C,C,Which of the following fields is the origin of the concept of reinforcement learning? <please select the best answer> A. Artificial  intelligence B. K-12 Education C. Psychological science D. Electric engineering,"History of reinforcement learning. Reinforcement learning was originally a concept used in behavioral psychology. Richard Sutton, a Canadian computer scientist, is one of the pioneers in the development of reinforcement learning in the context of AI. He contributed to a RL method called: Temporal Difference learning. A picture of Richard Sutton."
45bbe711-63d1-44e5-9094-aa9a8a11c65c,train,future,elementary school,u43,7,group 1,post test,11,19,1,B,B,"If a problem or a game has a lot of states, like the Go game, then we will need a neural network. What relationship do we expect the neural network to capture? <please select the best answer> A. The reward an agent receive after action  B. The value of a given state of the environment C. The action to take under a state of the environment D. The next state of the environment after agent takes an action",Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
f09e5272-9e86-4cbc-a8b2-eba20c7bb0c3,train,future,elementary school,u43,7,group 1,post test,6,8,1,Pac-man,pac-man,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the agent of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
33d23722-4bef-4498-b752-52664f92859e,train,past,elementary school,u43,7,group 1,post test,5,4,1,B,B,Which of the following best describes the jobs suitable for learning methods that fall into the category of reinforcement learning? <please select the best answer> A. Reinforcement learning is good at clustering data without help from humans. B. Reinforcement learning is good at producing a series of actions to achieve the goal. C. Reinforcement learning is good at recognizing the item in a given image D. Reinforcement learning is good at compressing data and filtering out noise in data.,The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
567b9894-bcd3-49d3-92bc-cfc25f9ae945,train,future,elementary school,u43,7,group 1,post test,10,19,1,Table,A table/lookup dictionary,What can reinforcement learning use when an ANN is not required because of the limited number of states and actions? <please input your answer>,Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
704bb063-cf95-4900-b1c9-d665928450e5,train,future,elementary school,u43,7,group 1,post test,7,8,1,LocatIon,location,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the state of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
a187bd93-6453-44ba-a233-c229b8b89cd5,train,past,elementary school,u44,7,group 2,post test,3,5,1,D,D,"In reinforcement learning, which two kinds of response does the agent get from its environment? <please select the best answer> A. Action, Reward B. Value, State C. Action, Value D. State, Reward","Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
f511a40c-f2f8-49d2-bd5b-8ade57438fac,train,past,elementary school,u44,7,group 2,post test,4,4,1,C,C,"Please select one of the following which falls into the framework of reinforcement learning. <please select the best answer> A. A computer calculates the digits of π, a mathematical constant which is close to 3.14. B. A neural network learns to distinguish images with known categories as cars or bicycles. C. An autonomous car tries to adapt to changing road conditions without causing accidents. D. A software collects user information and provides personalized recommendations automatically.",The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
8ee5f450-bfe9-4cb1-b46d-a8e4c2f5a217,train,past,elementary school,u44,7,group 2,post test,1,5,1,A,A,True or False: Reinforcement learning gets inputs as well as produces outputs? <please select the best answer> A. True   B. False,"Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
50a16f6c-13ca-45dc-bf19-ff120f03fc46,train,future,elementary school,u44,7,group 2,post test,8,17,1,B,B,"If the value (V) in the current state is only indicated by the current reward (r), what is the relationship between them if we consider the variation of reward (r)? <please select the best answer> A. V = r B. V = V_old + 0.1 * (r - V_old) C. V = 0.1 * (r + 0.5 * V_next) D. V = V_old + 0.1 * ((r + 0.5 * V_next) - V_old)","The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. However, r is not always consistent in real world. new state = s. reward = r. Value of s: V = V_old + α * (r - V_old). Averaging the old value with new reward. A picture showing a mouse going through a maze where each cell is a state."
cce82084-18e8-4a00-aa3d-1be2ea1ca118,train,future,elementary school,u44,7,group 2,post test,9,14,1,D,D,Which of the following options best defines the value of a given state from the environment? <please select the best answer> A. The value is the immediate reward the agent receives from the environment. B. The value is the association between what action to take given the observation. C. The value is the place within which the reinforcement learning agent operates. D. The value is the best expected total reward an agent will receive given a state.,Value learning (V-learning). Value learning places a value on the situation. Learning how good or bad the situation is can be important. Value of a situation: The total reward that an agent can expect to collect from that state and onwards into the future. Two animations showing two different total rewards a agent could get by choosing different actions.
eae9696f-9939-43ca-bac7-9eb580fe2835,train,past,elementary school,u44,7,group 2,post test,2,6,1,C,C,Which of the following fields is the origin of the concept of reinforcement learning? <please select the best answer> A. Artificial  intelligence B. K-12 Education C. Psychological science D. Electric engineering,"History of reinforcement learning. Reinforcement learning was originally a concept used in behavioral psychology. Richard Sutton, a Canadian computer scientist, is one of the pioneers in the development of reinforcement learning in the context of AI. He contributed to a RL method called: Temporal Difference learning. A picture of Richard Sutton."
d88f953a-dbe2-481b-942e-110d0cea4ea3,train,future,elementary school,u44,7,group 2,post test,11,19,1,B,B,"If a problem or a game has a lot of states, like the Go game, then we will need a neural network. What relationship do we expect the neural network to capture? <please select the best answer> A. The reward an agent receive after action  B. The value of a given state of the environment C. The action to take under a state of the environment D. The next state of the environment after agent takes an action",Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
4df9ed83-8f54-44ef-a3c9-aea6e43b1d5f,train,future,elementary school,u44,7,group 2,post test,6,8,1,pac-man,pac-man,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the agent of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
2fbfac03-3dd5-4135-87a8-780723fd7be3,train,past,elementary school,u44,7,group 2,post test,5,4,1,B,B,Which of the following best describes the jobs suitable for learning methods that fall into the category of reinforcement learning? <please select the best answer> A. Reinforcement learning is good at clustering data without help from humans. B. Reinforcement learning is good at producing a series of actions to achieve the goal. C. Reinforcement learning is good at recognizing the item in a given image D. Reinforcement learning is good at compressing data and filtering out noise in data.,The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
af99e93f-a825-40f2-98be-576c46154fac,train,future,elementary school,u44,7,group 2,post test,10,19,1,dictionary ,A table/lookup dictionary,What can reinforcement learning use when an ANN is not required because of the limited number of states and actions? <please input your answer>,Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
c6dec403-d56c-4c4c-956b-9cedb7fb4af5,train,future,elementary school,u44,7,group 2,post test,7,8,1,pac-man,location,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the state of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
a68b0b24-9bd6-4fd7-88cd-25f1d883d7c9,train,past,elementary school,u7,7,group 2,post test,3,5,1,D,D,"In reinforcement learning, which two kinds of response does the agent get from its environment? <please select the best answer> A. Action, Reward B. Value, State C. Action, Value D. State, Reward","Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
3dc950e2-b886-4b89-9e67-2bd9d3470bd4,train,past,elementary school,u7,7,group 2,post test,4,4,1,C,C,"Please select one of the following which falls into the framework of reinforcement learning. <please select the best answer> A. A computer calculates the digits of π, a mathematical constant which is close to 3.14. B. A neural network learns to distinguish images with known categories as cars or bicycles. C. An autonomous car tries to adapt to changing road conditions without causing accidents. D. A software collects user information and provides personalized recommendations automatically.",The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
5abc49b6-859d-4ee4-8fd2-8c7d596d281a,train,past,elementary school,u7,7,group 2,post test,1,5,1,A,A,True or False: Reinforcement learning gets inputs as well as produces outputs? <please select the best answer> A. True   B. False,"Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
6d9b2237-59dd-4713-ab1e-746ef54fd81c,train,future,elementary school,u7,7,group 2,post test,8,17,1,B,B,"If the value (V) in the current state is only indicated by the current reward (r), what is the relationship between them if we consider the variation of reward (r)? <please select the best answer> A. V = r B. V = V_old + 0.1 * (r - V_old) C. V = 0.1 * (r + 0.5 * V_next) D. V = V_old + 0.1 * ((r + 0.5 * V_next) - V_old)","The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. However, r is not always consistent in real world. new state = s. reward = r. Value of s: V = V_old + α * (r - V_old). Averaging the old value with new reward. A picture showing a mouse going through a maze where each cell is a state."
496acf22-291f-4041-938e-b4793e32cbe0,train,future,elementary school,u7,7,group 2,post test,9,14,1,D,D,Which of the following options best defines the value of a given state from the environment? <please select the best answer> A. The value is the immediate reward the agent receives from the environment. B. The value is the association between what action to take given the observation. C. The value is the place within which the reinforcement learning agent operates. D. The value is the best expected total reward an agent will receive given a state.,Value learning (V-learning). Value learning places a value on the situation. Learning how good or bad the situation is can be important. Value of a situation: The total reward that an agent can expect to collect from that state and onwards into the future. Two animations showing two different total rewards a agent could get by choosing different actions.
b7fd8b9e-563c-436c-8061-5f8059f22596,train,past,elementary school,u7,7,group 2,post test,2,6,1,C,C,Which of the following fields is the origin of the concept of reinforcement learning? <please select the best answer> A. Artificial  intelligence B. K-12 Education C. Psychological science D. Electric engineering,"History of reinforcement learning. Reinforcement learning was originally a concept used in behavioral psychology. Richard Sutton, a Canadian computer scientist, is one of the pioneers in the development of reinforcement learning in the context of AI. He contributed to a RL method called: Temporal Difference learning. A picture of Richard Sutton."
db1dc779-c6e5-4fbd-bc96-ac811dfeba4d,train,future,elementary school,u7,7,group 2,post test,11,19,1,B,B,"If a problem or a game has a lot of states, like the Go game, then we will need a neural network. What relationship do we expect the neural network to capture? <please select the best answer> A. The reward an agent receive after action  B. The value of a given state of the environment C. The action to take under a state of the environment D. The next state of the environment after agent takes an action",Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
72d9a035-924b-455f-a7ac-eedbffd842fb,train,future,elementary school,u7,7,group 2,post test,6,8,1,pac-man,pac-man,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the agent of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
dd29fb53-6a88-4451-ad9c-d8888343acc9,train,past,elementary school,u7,7,group 2,post test,5,4,0,C,B,Which of the following best describes the jobs suitable for learning methods that fall into the category of reinforcement learning? <please select the best answer> A. Reinforcement learning is good at clustering data without help from humans. B. Reinforcement learning is good at producing a series of actions to achieve the goal. C. Reinforcement learning is good at recognizing the item in a given image D. Reinforcement learning is good at compressing data and filtering out noise in data.,The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
53f7b8cc-588e-464a-9806-829fe3e2085c,train,future,elementary school,u7,7,group 2,post test,10,19,1,table,A table/lookup dictionary,What can reinforcement learning use when an ANN is not required because of the limited number of states and actions? <please input your answer>,Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
69dd3ffe-ed0a-414c-ac3a-b313c95a1fb9,train,future,elementary school,u7,7,group 2,post test,7,8,1,Location,location,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the state of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
e4bccce0-56a8-49a4-95cd-e6c499636405,train,past,elementary school,u22,7,group 3,post test,3,5,0,A,D,"In reinforcement learning, which two kinds of response does the agent get from its environment? <please select the best answer> A. Action, Reward B. Value, State C. Action, Value D. State, Reward","Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
38029538-1baa-4e4b-a991-5cb66adca680,train,past,elementary school,u22,7,group 3,post test,4,4,0,A,C,"Please select one of the following which falls into the framework of reinforcement learning. <please select the best answer> A. A computer calculates the digits of π, a mathematical constant which is close to 3.14. B. A neural network learns to distinguish images with known categories as cars or bicycles. C. An autonomous car tries to adapt to changing road conditions without causing accidents. D. A software collects user information and provides personalized recommendations automatically.",The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
b7e07d1d-62de-4d01-95f2-e0d65cd693e8,train,past,elementary school,u22,7,group 3,post test,1,5,1,A,A,True or False: Reinforcement learning gets inputs as well as produces outputs? <please select the best answer> A. True   B. False,"Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
f0309385-136c-4760-b68d-0fb07efec331,train,future,elementary school,u22,7,group 3,post test,8,17,0,D,B,"If the value (V) in the current state is only indicated by the current reward (r), what is the relationship between them if we consider the variation of reward (r)? <please select the best answer> A. V = r B. V = V_old + 0.1 * (r - V_old) C. V = 0.1 * (r + 0.5 * V_next) D. V = V_old + 0.1 * ((r + 0.5 * V_next) - V_old)","The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. However, r is not always consistent in real world. new state = s. reward = r. Value of s: V = V_old + α * (r - V_old). Averaging the old value with new reward. A picture showing a mouse going through a maze where each cell is a state."
8812e114-791e-4315-9e9c-53ab827e0d67,train,future,elementary school,u22,7,group 3,post test,9,14,0,C,D,Which of the following options best defines the value of a given state from the environment? <please select the best answer> A. The value is the immediate reward the agent receives from the environment. B. The value is the association between what action to take given the observation. C. The value is the place within which the reinforcement learning agent operates. D. The value is the best expected total reward an agent will receive given a state.,Value learning (V-learning). Value learning places a value on the situation. Learning how good or bad the situation is can be important. Value of a situation: The total reward that an agent can expect to collect from that state and onwards into the future. Two animations showing two different total rewards a agent could get by choosing different actions.
4d79916e-d5e3-4ec6-b886-1f95e5e12aa3,train,past,elementary school,u22,7,group 3,post test,2,6,1,C,C,Which of the following fields is the origin of the concept of reinforcement learning? <please select the best answer> A. Artificial  intelligence B. K-12 Education C. Psychological science D. Electric engineering,"History of reinforcement learning. Reinforcement learning was originally a concept used in behavioral psychology. Richard Sutton, a Canadian computer scientist, is one of the pioneers in the development of reinforcement learning in the context of AI. He contributed to a RL method called: Temporal Difference learning. A picture of Richard Sutton."
1118024d-f3c0-4cb8-be59-551b79df99db,train,future,elementary school,u22,7,group 3,post test,11,19,1,B,B,"If a problem or a game has a lot of states, like the Go game, then we will need a neural network. What relationship do we expect the neural network to capture? <please select the best answer> A. The reward an agent receive after action  B. The value of a given state of the environment C. The action to take under a state of the environment D. The next state of the environment after agent takes an action",Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
f9fafb49-f093-448b-862f-19bf14b9cfcb,train,future,elementary school,u22,7,group 3,post test,6,8,1,pac man,pac-man,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the agent of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
9e1591fa-44ab-4025-8871-ecb76838cbb0,train,past,elementary school,u22,7,group 3,post test,5,4,1,B,B,Which of the following best describes the jobs suitable for learning methods that fall into the category of reinforcement learning? <please select the best answer> A. Reinforcement learning is good at clustering data without help from humans. B. Reinforcement learning is good at producing a series of actions to achieve the goal. C. Reinforcement learning is good at recognizing the item in a given image D. Reinforcement learning is good at compressing data and filtering out noise in data.,The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
f83132bc-032b-4088-9f4c-a2dee89aa1e1,train,future,elementary school,u22,7,group 3,post test,10,19,0,i,A table/lookup dictionary,What can reinforcement learning use when an ANN is not required because of the limited number of states and actions? <please input your answer>,Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
c19251e2-7da6-4352-bc6f-693fa1f28ed8,train,future,elementary school,u22,7,group 3,post test,7,8,0,beans,location,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the state of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
8a3ff605-49f3-48d6-9e58-17619629bdff,test,past,elementary school,u23,7,group 3,post test,3,5,1,D,D,"In reinforcement learning, which two kinds of response does the agent get from its environment? <please select the best answer> A. Action, Reward B. Value, State C. Action, Value D. State, Reward","Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
d72c09d7-7efb-419b-8467-8776823770b3,test,past,elementary school,u23,7,group 3,post test,4,4,1,C,C,"Please select one of the following which falls into the framework of reinforcement learning. <please select the best answer> A. A computer calculates the digits of π, a mathematical constant which is close to 3.14. B. A neural network learns to distinguish images with known categories as cars or bicycles. C. An autonomous car tries to adapt to changing road conditions without causing accidents. D. A software collects user information and provides personalized recommendations automatically.",The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
1a3e2b1d-e9d1-4528-bd35-3f6247f4753f,test,past,elementary school,u23,7,group 3,post test,1,5,1,A,A,True or False: Reinforcement learning gets inputs as well as produces outputs? <please select the best answer> A. True   B. False,"Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
21073130-643e-4a8e-869e-245c3511f9b6,test,future,elementary school,u23,7,group 3,post test,8,17,0,A,B,"If the value (V) in the current state is only indicated by the current reward (r), what is the relationship between them if we consider the variation of reward (r)? <please select the best answer> A. V = r B. V = V_old + 0.1 * (r - V_old) C. V = 0.1 * (r + 0.5 * V_next) D. V = V_old + 0.1 * ((r + 0.5 * V_next) - V_old)","The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. However, r is not always consistent in real world. new state = s. reward = r. Value of s: V = V_old + α * (r - V_old). Averaging the old value with new reward. A picture showing a mouse going through a maze where each cell is a state."
750975fd-6d0e-4029-89dc-e0bf37de4ae2,test,future,elementary school,u23,7,group 3,post test,9,14,0,C,D,Which of the following options best defines the value of a given state from the environment? <please select the best answer> A. The value is the immediate reward the agent receives from the environment. B. The value is the association between what action to take given the observation. C. The value is the place within which the reinforcement learning agent operates. D. The value is the best expected total reward an agent will receive given a state.,Value learning (V-learning). Value learning places a value on the situation. Learning how good or bad the situation is can be important. Value of a situation: The total reward that an agent can expect to collect from that state and onwards into the future. Two animations showing two different total rewards a agent could get by choosing different actions.
417f26b2-39b9-4d53-a31a-41adbcd974a1,test,past,elementary school,u23,7,group 3,post test,2,6,1,C,C,Which of the following fields is the origin of the concept of reinforcement learning? <please select the best answer> A. Artificial  intelligence B. K-12 Education C. Psychological science D. Electric engineering,"History of reinforcement learning. Reinforcement learning was originally a concept used in behavioral psychology. Richard Sutton, a Canadian computer scientist, is one of the pioneers in the development of reinforcement learning in the context of AI. He contributed to a RL method called: Temporal Difference learning. A picture of Richard Sutton."
4da71173-c996-4d83-a7be-b135284e7534,test,future,elementary school,u23,7,group 3,post test,11,19,1,B,B,"If a problem or a game has a lot of states, like the Go game, then we will need a neural network. What relationship do we expect the neural network to capture? <please select the best answer> A. The reward an agent receive after action  B. The value of a given state of the environment C. The action to take under a state of the environment D. The next state of the environment after agent takes an action",Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
54ef0666-671a-4cce-8c60-2e62afba9f98,test,future,elementary school,u23,7,group 3,post test,6,8,1,Pac-man,pac-man,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the agent of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
71da77f8-4e33-46f1-9d6d-bafa13e78df8,test,past,elementary school,u23,7,group 3,post test,5,4,1,B,B,Which of the following best describes the jobs suitable for learning methods that fall into the category of reinforcement learning? <please select the best answer> A. Reinforcement learning is good at clustering data without help from humans. B. Reinforcement learning is good at producing a series of actions to achieve the goal. C. Reinforcement learning is good at recognizing the item in a given image D. Reinforcement learning is good at compressing data and filtering out noise in data.,The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
3910eeff-2e09-48f1-bc6d-9023843d78eb,test,future,elementary school,u23,7,group 3,post test,10,19,0,idk,A table/lookup dictionary,What can reinforcement learning use when an ANN is not required because of the limited number of states and actions? <please input your answer>,Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
7fc07a15-739e-44f3-9a34-adad507fbb2a,test,future,elementary school,u23,7,group 3,post test,7,8,1,Maze,location,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the state of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
6a2a61c9-aae3-48ce-bbc3-34fb53f6a5a1,test,past,elementary school,u24,7,group 3,post test,3,5,1,D,D,"In reinforcement learning, which two kinds of response does the agent get from its environment? <please select the best answer> A. Action, Reward B. Value, State C. Action, Value D. State, Reward","Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
b98f2ff5-8e90-40fe-bd73-68a99933a2fa,test,past,elementary school,u24,7,group 3,post test,4,4,1,C,C,"Please select one of the following which falls into the framework of reinforcement learning. <please select the best answer> A. A computer calculates the digits of π, a mathematical constant which is close to 3.14. B. A neural network learns to distinguish images with known categories as cars or bicycles. C. An autonomous car tries to adapt to changing road conditions without causing accidents. D. A software collects user information and provides personalized recommendations automatically.",The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
7a329bf4-c88f-44f0-a498-8c2e83145663,test,past,elementary school,u24,7,group 3,post test,1,5,1,A,A,True or False: Reinforcement learning gets inputs as well as produces outputs? <please select the best answer> A. True   B. False,"Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
d61ced3b-b73f-4d49-baf0-4efac25eb585,test,future,elementary school,u24,7,group 3,post test,8,17,1,B,B,"If the value (V) in the current state is only indicated by the current reward (r), what is the relationship between them if we consider the variation of reward (r)? <please select the best answer> A. V = r B. V = V_old + 0.1 * (r - V_old) C. V = 0.1 * (r + 0.5 * V_next) D. V = V_old + 0.1 * ((r + 0.5 * V_next) - V_old)","The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. However, r is not always consistent in real world. new state = s. reward = r. Value of s: V = V_old + α * (r - V_old). Averaging the old value with new reward. A picture showing a mouse going through a maze where each cell is a state."
473c674f-1f89-4bec-9aab-052e30e64874,test,future,elementary school,u24,7,group 3,post test,9,14,1,D,D,Which of the following options best defines the value of a given state from the environment? <please select the best answer> A. The value is the immediate reward the agent receives from the environment. B. The value is the association between what action to take given the observation. C. The value is the place within which the reinforcement learning agent operates. D. The value is the best expected total reward an agent will receive given a state.,Value learning (V-learning). Value learning places a value on the situation. Learning how good or bad the situation is can be important. Value of a situation: The total reward that an agent can expect to collect from that state and onwards into the future. Two animations showing two different total rewards a agent could get by choosing different actions.
f3a353a7-4708-4f40-8a02-e970d0510ca5,test,past,elementary school,u24,7,group 3,post test,2,6,1,C,C,Which of the following fields is the origin of the concept of reinforcement learning? <please select the best answer> A. Artificial  intelligence B. K-12 Education C. Psychological science D. Electric engineering,"History of reinforcement learning. Reinforcement learning was originally a concept used in behavioral psychology. Richard Sutton, a Canadian computer scientist, is one of the pioneers in the development of reinforcement learning in the context of AI. He contributed to a RL method called: Temporal Difference learning. A picture of Richard Sutton."
6b7b27a7-cbbb-4714-9483-3e8695e96f20,test,future,elementary school,u24,7,group 3,post test,11,19,1,B,B,"If a problem or a game has a lot of states, like the Go game, then we will need a neural network. What relationship do we expect the neural network to capture? <please select the best answer> A. The reward an agent receive after action  B. The value of a given state of the environment C. The action to take under a state of the environment D. The next state of the environment after agent takes an action",Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
f6ba569f-aa35-4bde-aefd-8ec88a934dbf,test,future,elementary school,u24,7,group 3,post test,6,8,1,pac-man,pac-man,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the agent of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
0b03a56f-dbf4-4fdf-be7f-568c6d655011,test,past,elementary school,u24,7,group 3,post test,5,4,1,B,B,Which of the following best describes the jobs suitable for learning methods that fall into the category of reinforcement learning? <please select the best answer> A. Reinforcement learning is good at clustering data without help from humans. B. Reinforcement learning is good at producing a series of actions to achieve the goal. C. Reinforcement learning is good at recognizing the item in a given image D. Reinforcement learning is good at compressing data and filtering out noise in data.,The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
b6445be8-7995-49cc-9bdc-59f522822894,test,future,elementary school,u24,7,group 3,post test,10,19,1,Table,A table/lookup dictionary,What can reinforcement learning use when an ANN is not required because of the limited number of states and actions? <please input your answer>,Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
493d4af6-b564-4019-a376-b542d8c5ace4,test,future,elementary school,u24,7,group 3,post test,7,8,1,Location,location,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the state of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
5067a0cc-0878-44a6-ab52-6c2ed3b88447,train,past,elementary school,u25,7,group 3,post test,3,5,1,D,D,"In reinforcement learning, which two kinds of response does the agent get from its environment? <please select the best answer> A. Action, Reward B. Value, State C. Action, Value D. State, Reward","Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
5b9146ee-4242-432b-be48-94b0383ed134,train,past,elementary school,u25,7,group 3,post test,4,4,1,C,C,"Please select one of the following which falls into the framework of reinforcement learning. <please select the best answer> A. A computer calculates the digits of π, a mathematical constant which is close to 3.14. B. A neural network learns to distinguish images with known categories as cars or bicycles. C. An autonomous car tries to adapt to changing road conditions without causing accidents. D. A software collects user information and provides personalized recommendations automatically.",The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
a7a9ca6c-9f92-48df-9948-16c89dd22e4f,train,past,elementary school,u25,7,group 3,post test,1,5,1,A,A,True or False: Reinforcement learning gets inputs as well as produces outputs? <please select the best answer> A. True   B. False,"Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
ac1187f9-8a01-4fd2-afbc-851f7f4a015e,train,future,elementary school,u25,7,group 3,post test,8,17,1,B,B,"If the value (V) in the current state is only indicated by the current reward (r), what is the relationship between them if we consider the variation of reward (r)? <please select the best answer> A. V = r B. V = V_old + 0.1 * (r - V_old) C. V = 0.1 * (r + 0.5 * V_next) D. V = V_old + 0.1 * ((r + 0.5 * V_next) - V_old)","The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. However, r is not always consistent in real world. new state = s. reward = r. Value of s: V = V_old + α * (r - V_old). Averaging the old value with new reward. A picture showing a mouse going through a maze where each cell is a state."
7f64ec97-0d27-4fb5-ae32-ea0dbcbd9e97,train,future,elementary school,u25,7,group 3,post test,9,14,1,D,D,Which of the following options best defines the value of a given state from the environment? <please select the best answer> A. The value is the immediate reward the agent receives from the environment. B. The value is the association between what action to take given the observation. C. The value is the place within which the reinforcement learning agent operates. D. The value is the best expected total reward an agent will receive given a state.,Value learning (V-learning). Value learning places a value on the situation. Learning how good or bad the situation is can be important. Value of a situation: The total reward that an agent can expect to collect from that state and onwards into the future. Two animations showing two different total rewards a agent could get by choosing different actions.
c62faf1f-fb49-4a16-9386-7d2724535470,train,past,elementary school,u25,7,group 3,post test,2,6,1,C,C,Which of the following fields is the origin of the concept of reinforcement learning? <please select the best answer> A. Artificial  intelligence B. K-12 Education C. Psychological science D. Electric engineering,"History of reinforcement learning. Reinforcement learning was originally a concept used in behavioral psychology. Richard Sutton, a Canadian computer scientist, is one of the pioneers in the development of reinforcement learning in the context of AI. He contributed to a RL method called: Temporal Difference learning. A picture of Richard Sutton."
443dd985-7a24-454d-b571-48a45d5c44fc,train,future,elementary school,u25,7,group 3,post test,11,19,1,B,B,"If a problem or a game has a lot of states, like the Go game, then we will need a neural network. What relationship do we expect the neural network to capture? <please select the best answer> A. The reward an agent receive after action  B. The value of a given state of the environment C. The action to take under a state of the environment D. The next state of the environment after agent takes an action",Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
460560ad-17cc-47d2-b734-36a932924ee8,train,future,elementary school,u25,7,group 3,post test,6,8,1,Pac-man,pac-man,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the agent of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
f34c61dc-a10d-46a4-9ff3-db4dbbde3f17,train,past,elementary school,u25,7,group 3,post test,5,4,1,B,B,Which of the following best describes the jobs suitable for learning methods that fall into the category of reinforcement learning? <please select the best answer> A. Reinforcement learning is good at clustering data without help from humans. B. Reinforcement learning is good at producing a series of actions to achieve the goal. C. Reinforcement learning is good at recognizing the item in a given image D. Reinforcement learning is good at compressing data and filtering out noise in data.,The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
c456fb39-1702-4be5-8df8-413c5eff4637,train,future,elementary school,u25,7,group 3,post test,10,19,1,Look up dictionary ,A table/lookup dictionary,What can reinforcement learning use when an ANN is not required because of the limited number of states and actions? <please input your answer>,Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
cb1ff46f-7ee4-48da-a45e-ae77652e2c96,train,future,elementary school,u25,7,group 3,post test,7,8,1,Location,location,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the state of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
1481aa65-b976-4a84-af10-efc40ec44349,train,past,elementary school,u47,11,group 1,post test,3,8,0,the nodes and lines repesent the network,"numbers/labels, the statistical relationships among them","In graphic models, what does nodes and lines represent? <please input your answer>",Graphical model. Graphical model is a new kind of fast-learning algorithm. Nodes: describe anything that can be represented by numbers or labels. Arrows and lines: show one node’s value ends up with the given value of another node. A picture of an example graph.
801849a0-dc81-449b-85e0-aa0d5e0b1814,train,past,elementary school,u47,11,group 1,post test,4,10,1,few shot learning,few shot learning,What is the name of the method that enables ANNs to learn from limited examples? <please input your answer>,Few-shot learning. Few-shot learning aims to build accurate machine learning models with less training data. A picture highlighting the difference between large data training and few-shot training.
9b033ca1-9999-48d2-b35b-304b0e5eefcf,train,past,elementary school,u47,11,group 1,post test,1,4,0, ,backpropagation,Please give an example of mechanism that neurons do not have but neural networks have? <please input your answer>,"The interaction has decreased. A real neuron is made of tiny electrochemical processes that are only roughly approximated in an artificial neuron model. It is unlikely that backpropagation is going on in the brain when people learn, while backpropagation is a powerful algorithm for training ANNs. A picture of backpropagation."
f10ec55e-9c56-42ad-bce2-fd8abed4d86e,train,future,elementary school,u47,11,group 1,post test,8,17,1,6,Six,How many layers does the cortex of the human big brain have? <please input your answer>,"The structure of human brain. The “big brain” of humans is made of six layers organized into columns. We don’t precisely understand how the layers and columns work although we know how these cell types are distributed in the layers. Once we find out, the understanding of brain may change and impact ANN technology. A picture showing the six layers of a human brain."
37206564-c83d-4449-bf64-c250530c2913,train,past,elementary school,u47,11,group 1,post test,2,5,1,because in some cases humans do better than AI,There are still areas where people perform much better than AI,Why should we watch for developments in neuroscience? Please list one reason. <please input your answer>,We should watch for developments in neuroscience. There are still areas where people perform much better than AI. There may be a different operating principle we can learn from biological neural networks. Two pictures that show the similarty between a biological neuron and the one in ANN.
e6e2bebb-f548-4700-81b3-33f2c4309949,train,future,elementary school,u47,11,group 1,post test,6,11,1,generative model,Generative model,What is the name of the neural network that can generate new examples of what it has learned but has not yet seen? <please input your answer>,Generative model. Another thing that humans have but machines seem to lack is creativity. ANN models called the generative model can create examples after learning. Generative adversarial network (GAN) learns to generate outputs indistinguishable from the real data. Images generated by GAN.
3353336c-ee07-43ec-8575-3d9e893540aa,train,past,elementary school,u47,11,group 1,post test,5,13,1,when the original task and the applied task have a few common features,The original task and the applied task have some common features,In which condition can transfer learning reduce the time to train for the new task? (Hint: not a exact example like CNN.) <please input your answer>,Transfer learning to new areas. Humans also seem to have the ability to transfer learning to new areas. A network trained for one task may be able to be trained for another task faster if the original task and the applied task have some common features. A picture showing transfer learning where the source data/labels are larger than the target data/labels.
7b48126e-c343-461f-b140-af85383ec52f,train,future,elementary school,u47,11,group 1,post test,7,12,0,i do not know,Generator/Discriminator,What are names of the two smaller models in the the neural network that can generate examples of what it has learned but has not yet seen <please input your answer>,GAN in details. A picture of the GAN architecture (random noise to generator to generate a fake image and a discriminator trying to discriminate that from the training image)
48ed9443-53fe-4654-bf2f-ae4737916855,test,past,elementary school,u19,11,group 1,post test,3,8,0, the statistical relationships among them,"numbers/labels, the statistical relationships among them","In graphic models, what does nodes and lines represent? <please input your answer>",Graphical model. Graphical model is a new kind of fast-learning algorithm. Nodes: describe anything that can be represented by numbers or labels. Arrows and lines: show one node’s value ends up with the given value of another node. A picture of an example graph.
ada010af-cfe8-4a9b-9040-7ee1723e3bbe,test,past,elementary school,u19,11,group 1,post test,4,10,1,few shot learning,few shot learning,What is the name of the method that enables ANNs to learn from limited examples? <please input your answer>,Few-shot learning. Few-shot learning aims to build accurate machine learning models with less training data. A picture highlighting the difference between large data training and few-shot training.
352d55ed-0fbb-4d3f-ad26-fa60bef9bab4,test,past,elementary school,u19,11,group 1,post test,1,4,1,backpropagation  ,backpropagation,Please give an example of mechanism that neurons do not have but neural networks have? <please input your answer>,"The interaction has decreased. A real neuron is made of tiny electrochemical processes that are only roughly approximated in an artificial neuron model. It is unlikely that backpropagation is going on in the brain when people learn, while backpropagation is a powerful algorithm for training ANNs. A picture of backpropagation."
8a49dc14-3045-48f2-a716-7aa7fc166c4c,test,future,elementary school,u19,11,group 1,post test,8,17,1,6,Six,How many layers does the cortex of the human big brain have? <please input your answer>,"The structure of human brain. The “big brain” of humans is made of six layers organized into columns. We don’t precisely understand how the layers and columns work although we know how these cell types are distributed in the layers. Once we find out, the understanding of brain may change and impact ANN technology. A picture showing the six layers of a human brain."
683bb0b4-f333-425b-9b61-3bfe7619462d,test,past,elementary school,u19,11,group 1,post test,2,5,1,There are still areas where people perform much better than AI,There are still areas where people perform much better than AI,Why should we watch for developments in neuroscience? Please list one reason. <please input your answer>,We should watch for developments in neuroscience. There are still areas where people perform much better than AI. There may be a different operating principle we can learn from biological neural networks. Two pictures that show the similarty between a biological neuron and the one in ANN.
c6444cfd-a733-47fe-aaec-b39ee54e0961,test,future,elementary school,u19,11,group 1,post test,6,11,0,The original task and the applied task have some common features,Generative model,What is the name of the neural network that can generate new examples of what it has learned but has not yet seen? <please input your answer>,Generative model. Another thing that humans have but machines seem to lack is creativity. ANN models called the generative model can create examples after learning. Generative adversarial network (GAN) learns to generate outputs indistinguishable from the real data. Images generated by GAN.
cc337a7b-13eb-4bed-ac53-856562ff6230,test,past,elementary school,u19,11,group 1,post test,5,13,0,F2l,The original task and the applied task have some common features,In which condition can transfer learning reduce the time to train for the new task? (Hint: not a exact example like CNN.) <please input your answer>,Transfer learning to new areas. Humans also seem to have the ability to transfer learning to new areas. A network trained for one task may be able to be trained for another task faster if the original task and the applied task have some common features. A picture showing transfer learning where the source data/labels are larger than the target data/labels.
f193fe75-d7a8-43ff-9b7b-28bb5382f3ca,test,future,elementary school,u19,11,group 1,post test,7,12,0,Generative model,Generator/Discriminator,What are names of the two smaller models in the the neural network that can generate examples of what it has learned but has not yet seen <please input your answer>,GAN in details. A picture of the GAN architecture (random noise to generator to generate a fake image and a discriminator trying to discriminate that from the training image)
a4c3547d-6cf5-4d7d-b7e0-e9d4a999f764,train,past,elementary school,u3,11,group 1,post test,3,8,0,i,"numbers/labels, the statistical relationships among them","In graphic models, what does nodes and lines represent? <please input your answer>",Graphical model. Graphical model is a new kind of fast-learning algorithm. Nodes: describe anything that can be represented by numbers or labels. Arrows and lines: show one node’s value ends up with the given value of another node. A picture of an example graph.
1a37c3ae-025a-47ae-be07-82c3d9044722,train,past,elementary school,u3,11,group 1,post test,4,10,0,y,few shot learning,What is the name of the method that enables ANNs to learn from limited examples? <please input your answer>,Few-shot learning. Few-shot learning aims to build accurate machine learning models with less training data. A picture highlighting the difference between large data training and few-shot training.
4ac3ea55-2e30-4988-a697-cfa4719c5022,train,past,elementary school,u3,11,group 1,post test,1,4,1,Backpropigation,backpropagation,Please give an example of mechanism that neurons do not have but neural networks have? <please input your answer>,"The interaction has decreased. A real neuron is made of tiny electrochemical processes that are only roughly approximated in an artificial neuron model. It is unlikely that backpropagation is going on in the brain when people learn, while backpropagation is a powerful algorithm for training ANNs. A picture of backpropagation."
7608e6d4-be3a-443c-8f62-dd9609299c8d,train,future,elementary school,u3,11,group 1,post test,8,17,1,6,Six,How many layers does the cortex of the human big brain have? <please input your answer>,"The structure of human brain. The “big brain” of humans is made of six layers organized into columns. We don’t precisely understand how the layers and columns work although we know how these cell types are distributed in the layers. Once we find out, the understanding of brain may change and impact ANN technology. A picture showing the six layers of a human brain."
1ba0be61-a945-49a7-8c28-6816c7286daf,train,past,elementary school,u3,11,group 1,post test,2,5,0,in ,There are still areas where people perform much better than AI,Why should we watch for developments in neuroscience? Please list one reason. <please input your answer>,We should watch for developments in neuroscience. There are still areas where people perform much better than AI. There may be a different operating principle we can learn from biological neural networks. Two pictures that show the similarty between a biological neuron and the one in ANN.
aed81e0e-f1a7-409e-aff2-05c519a8f794,train,future,elementary school,u3,11,group 1,post test,6,11,0,n,Generative model,What is the name of the neural network that can generate new examples of what it has learned but has not yet seen? <please input your answer>,Generative model. Another thing that humans have but machines seem to lack is creativity. ANN models called the generative model can create examples after learning. Generative adversarial network (GAN) learns to generate outputs indistinguishable from the real data. Images generated by GAN.
a8a88b21-3ce8-44b3-9585-61f1a22d2be3,train,past,elementary school,u3,11,group 1,post test,5,13,0,j,The original task and the applied task have some common features,In which condition can transfer learning reduce the time to train for the new task? (Hint: not a exact example like CNN.) <please input your answer>,Transfer learning to new areas. Humans also seem to have the ability to transfer learning to new areas. A network trained for one task may be able to be trained for another task faster if the original task and the applied task have some common features. A picture showing transfer learning where the source data/labels are larger than the target data/labels.
075e93a3-4ca7-4d64-862b-cc57475af159,train,future,elementary school,u3,11,group 1,post test,7,12,0,j,Generator/Discriminator,What are names of the two smaller models in the the neural network that can generate examples of what it has learned but has not yet seen <please input your answer>,GAN in details. A picture of the GAN architecture (random noise to generator to generate a fake image and a discriminator trying to discriminate that from the training image)
050e334b-ca7e-451b-8b68-8239941101b9,train,past,elementary school,u45,11,group 2,post test,3,8,1,"numbers/labels, the statistical relationships among them","numbers/labels, the statistical relationships among them","In graphic models, what does nodes and lines represent? <please input your answer>",Graphical model. Graphical model is a new kind of fast-learning algorithm. Nodes: describe anything that can be represented by numbers or labels. Arrows and lines: show one node’s value ends up with the given value of another node. A picture of an example graph.
19f93612-3308-4410-8dd2-f224cf7934aa,train,past,elementary school,u45,11,group 2,post test,4,10,1,few shot learning,few shot learning,What is the name of the method that enables ANNs to learn from limited examples? <please input your answer>,Few-shot learning. Few-shot learning aims to build accurate machine learning models with less training data. A picture highlighting the difference between large data training and few-shot training.
8ae21d87-2762-41ae-afae-836c2e4f36c4,train,past,elementary school,u45,11,group 2,post test,1,4,1,backpropagation,backpropagation,Please give an example of mechanism that neurons do not have but neural networks have? <please input your answer>,"The interaction has decreased. A real neuron is made of tiny electrochemical processes that are only roughly approximated in an artificial neuron model. It is unlikely that backpropagation is going on in the brain when people learn, while backpropagation is a powerful algorithm for training ANNs. A picture of backpropagation."
5b59096b-d9ea-4254-b8a6-7f6f5295e1f0,train,future,elementary school,u45,11,group 2,post test,8,17,1,6,Six,How many layers does the cortex of the human big brain have? <please input your answer>,"The structure of human brain. The “big brain” of humans is made of six layers organized into columns. We don’t precisely understand how the layers and columns work although we know how these cell types are distributed in the layers. Once we find out, the understanding of brain may change and impact ANN technology. A picture showing the six layers of a human brain."
e69444f1-c1ec-4797-b1dc-f40f8d82d5dc,train,past,elementary school,u45,11,group 2,post test,2,5,1,There are still areas where people perform much better than AI,There are still areas where people perform much better than AI,Why should we watch for developments in neuroscience? Please list one reason. <please input your answer>,We should watch for developments in neuroscience. There are still areas where people perform much better than AI. There may be a different operating principle we can learn from biological neural networks. Two pictures that show the similarty between a biological neuron and the one in ANN.
4592d3ae-d727-43f8-841b-f049c57f0e79,train,future,elementary school,u45,11,group 2,post test,6,11,1,Generative model,Generative model,What is the name of the neural network that can generate new examples of what it has learned but has not yet seen? <please input your answer>,Generative model. Another thing that humans have but machines seem to lack is creativity. ANN models called the generative model can create examples after learning. Generative adversarial network (GAN) learns to generate outputs indistinguishable from the real data. Images generated by GAN.
e18bcdf7-6625-441f-8c46-0588bed48701,train,past,elementary school,u45,11,group 2,post test,5,13,1,The original task and the applied task have some common features,The original task and the applied task have some common features,In which condition can transfer learning reduce the time to train for the new task? (Hint: not a exact example like CNN.) <please input your answer>,Transfer learning to new areas. Humans also seem to have the ability to transfer learning to new areas. A network trained for one task may be able to be trained for another task faster if the original task and the applied task have some common features. A picture showing transfer learning where the source data/labels are larger than the target data/labels.
2a4eb502-06f2-46d0-90c1-001c87999e9f,train,future,elementary school,u45,11,group 2,post test,7,12,0,I don? know,Generator/Discriminator,What are names of the two smaller models in the the neural network that can generate examples of what it has learned but has not yet seen <please input your answer>,GAN in details. A picture of the GAN architecture (random noise to generator to generate a fake image and a discriminator trying to discriminate that from the training image)
461b332f-bc0c-4038-8c71-061ed17ed373,train,past,elementary school,u21,11,group 2,post test,3,8,0,numbers or labels,"numbers/labels, the statistical relationships among them","In graphic models, what does nodes and lines represent? <please input your answer>",Graphical model. Graphical model is a new kind of fast-learning algorithm. Nodes: describe anything that can be represented by numbers or labels. Arrows and lines: show one node’s value ends up with the given value of another node. A picture of an example graph.
960da492-8422-4faa-8f40-f9f13e764174,train,past,elementary school,u21,11,group 2,post test,4,10,1,FSL,few shot learning,What is the name of the method that enables ANNs to learn from limited examples? <please input your answer>,Few-shot learning. Few-shot learning aims to build accurate machine learning models with less training data. A picture highlighting the difference between large data training and few-shot training.
86eb0afc-131d-4f1e-b354-c88a21f71524,train,past,elementary school,u21,11,group 2,post test,1,4,1,backpropagation ,backpropagation,Please give an example of mechanism that neurons do not have but neural networks have? <please input your answer>,"The interaction has decreased. A real neuron is made of tiny electrochemical processes that are only roughly approximated in an artificial neuron model. It is unlikely that backpropagation is going on in the brain when people learn, while backpropagation is a powerful algorithm for training ANNs. A picture of backpropagation."
36e5133c-3202-4038-a6cb-3487fc9d6e73,train,future,elementary school,u21,11,group 2,post test,8,17,1,6,Six,How many layers does the cortex of the human big brain have? <please input your answer>,"The structure of human brain. The “big brain” of humans is made of six layers organized into columns. We don’t precisely understand how the layers and columns work although we know how these cell types are distributed in the layers. Once we find out, the understanding of brain may change and impact ANN technology. A picture showing the six layers of a human brain."
992c0fa4-13d0-4a1c-a9be-225a8e55282f,train,past,elementary school,u21,11,group 2,post test,2,5,1,there are things that people do a lot better than ai,There are still areas where people perform much better than AI,Why should we watch for developments in neuroscience? Please list one reason. <please input your answer>,We should watch for developments in neuroscience. There are still areas where people perform much better than AI. There may be a different operating principle we can learn from biological neural networks. Two pictures that show the similarty between a biological neuron and the one in ANN.
faa4013c-c879-409d-94ac-788a2bab1f05,train,future,elementary school,u21,11,group 2,post test,6,11,1,generative model,Generative model,What is the name of the neural network that can generate new examples of what it has learned but has not yet seen? <please input your answer>,Generative model. Another thing that humans have but machines seem to lack is creativity. ANN models called the generative model can create examples after learning. Generative adversarial network (GAN) learns to generate outputs indistinguishable from the real data. Images generated by GAN.
caa64e34-7724-4802-8f68-c10dddcd3279,train,past,elementary school,u21,11,group 2,post test,5,13,1,the original task and applied have similar features,The original task and the applied task have some common features,In which condition can transfer learning reduce the time to train for the new task? (Hint: not a exact example like CNN.) <please input your answer>,Transfer learning to new areas. Humans also seem to have the ability to transfer learning to new areas. A network trained for one task may be able to be trained for another task faster if the original task and the applied task have some common features. A picture showing transfer learning where the source data/labels are larger than the target data/labels.
6eb54ad0-5ed0-4c7c-bc2d-294aaf412f4d,train,future,elementary school,u21,11,group 2,post test,7,12,0,imaginative and i do not know the other,Generator/Discriminator,What are names of the two smaller models in the the neural network that can generate examples of what it has learned but has not yet seen <please input your answer>,GAN in details. A picture of the GAN architecture (random noise to generator to generate a fake image and a discriminator trying to discriminate that from the training image)
4f1c91a2-b798-48fb-8961-39b6da9b9cd3,test,past,elementary school,u10,11,group 3,post test,3,8,0,nodes represent the choices,"numbers/labels, the statistical relationships among them","In graphic models, what does nodes and lines represent? <please input your answer>",Graphical model. Graphical model is a new kind of fast-learning algorithm. Nodes: describe anything that can be represented by numbers or labels. Arrows and lines: show one node’s value ends up with the given value of another node. A picture of an example graph.
0c0d3eb4-a299-4674-9ff2-9beba02ace45,test,past,elementary school,u10,11,group 3,post test,4,10,0,I don? know ,few shot learning,What is the name of the method that enables ANNs to learn from limited examples? <please input your answer>,Few-shot learning. Few-shot learning aims to build accurate machine learning models with less training data. A picture highlighting the difference between large data training and few-shot training.
58dbe8b5-085e-455e-99dd-0fb16b025d1a,test,past,elementary school,u10,11,group 3,post test,1,4,0,I don't know,backpropagation,Please give an example of mechanism that neurons do not have but neural networks have? <please input your answer>,"The interaction has decreased. A real neuron is made of tiny electrochemical processes that are only roughly approximated in an artificial neuron model. It is unlikely that backpropagation is going on in the brain when people learn, while backpropagation is a powerful algorithm for training ANNs. A picture of backpropagation."
a0ba798c-519f-460c-bba2-cf9d69759e0c,test,future,elementary school,u10,11,group 3,post test,8,17,0,7,Six,How many layers does the cortex of the human big brain have? <please input your answer>,"The structure of human brain. The “big brain” of humans is made of six layers organized into columns. We don’t precisely understand how the layers and columns work although we know how these cell types are distributed in the layers. Once we find out, the understanding of brain may change and impact ANN technology. A picture showing the six layers of a human brain."
d08ee14b-4dde-4ae7-aaac-8d772908cf50,test,past,elementary school,u10,11,group 3,post test,2,5,0,because they are important,There are still areas where people perform much better than AI,Why should we watch for developments in neuroscience? Please list one reason. <please input your answer>,We should watch for developments in neuroscience. There are still areas where people perform much better than AI. There may be a different operating principle we can learn from biological neural networks. Two pictures that show the similarty between a biological neuron and the one in ANN.
d47c8746-275e-4919-ac0a-4deb2b369274,test,future,elementary school,u10,11,group 3,post test,6,11,0,i don't know,Generative model,What is the name of the neural network that can generate new examples of what it has learned but has not yet seen? <please input your answer>,Generative model. Another thing that humans have but machines seem to lack is creativity. ANN models called the generative model can create examples after learning. Generative adversarial network (GAN) learns to generate outputs indistinguishable from the real data. Images generated by GAN.
79b2907d-63a1-4213-8362-b63c8f62a11f,test,past,elementary school,u10,11,group 3,post test,5,13,0,I dont't know,The original task and the applied task have some common features,In which condition can transfer learning reduce the time to train for the new task? (Hint: not a exact example like CNN.) <please input your answer>,Transfer learning to new areas. Humans also seem to have the ability to transfer learning to new areas. A network trained for one task may be able to be trained for another task faster if the original task and the applied task have some common features. A picture showing transfer learning where the source data/labels are larger than the target data/labels.
a13ccb38-ecf6-41a1-9354-c60006865f5b,test,future,elementary school,u10,11,group 3,post test,7,12,0,ann,Generator/Discriminator,What are names of the two smaller models in the the neural network that can generate examples of what it has learned but has not yet seen <please input your answer>,GAN in details. A picture of the GAN architecture (random noise to generator to generate a fake image and a discriminator trying to discriminate that from the training image)
1cad69c2-64f6-4c78-992b-36261fd7b0b6,train,past,elementary school,u26,11,group 3,post test,3,8,0,part of a graph,"numbers/labels, the statistical relationships among them","In graphic models, what does nodes and lines represent? <please input your answer>",Graphical model. Graphical model is a new kind of fast-learning algorithm. Nodes: describe anything that can be represented by numbers or labels. Arrows and lines: show one node’s value ends up with the given value of another node. A picture of an example graph.
84648c3a-5826-439a-b433-67dd08e65c26,train,past,elementary school,u26,11,group 3,post test,4,10,0,CNN,few shot learning,What is the name of the method that enables ANNs to learn from limited examples? <please input your answer>,Few-shot learning. Few-shot learning aims to build accurate machine learning models with less training data. A picture highlighting the difference between large data training and few-shot training.
8382c348-4731-4808-8fb1-351d15c91bba,train,past,elementary school,u26,11,group 3,post test,1,4,0,/,backpropagation,Please give an example of mechanism that neurons do not have but neural networks have? <please input your answer>,"The interaction has decreased. A real neuron is made of tiny electrochemical processes that are only roughly approximated in an artificial neuron model. It is unlikely that backpropagation is going on in the brain when people learn, while backpropagation is a powerful algorithm for training ANNs. A picture of backpropagation."
e4f43aa3-d8e8-45dc-b27c-f81b78d52457,train,future,elementary school,u26,11,group 3,post test,8,17,1,6,Six,How many layers does the cortex of the human big brain have? <please input your answer>,"The structure of human brain. The “big brain” of humans is made of six layers organized into columns. We don’t precisely understand how the layers and columns work although we know how these cell types are distributed in the layers. Once we find out, the understanding of brain may change and impact ANN technology. A picture showing the six layers of a human brain."
c7f2e626-4bf0-4c64-827a-3ba51d06af84,train,past,elementary school,u26,11,group 3,post test,2,5,0,?,There are still areas where people perform much better than AI,Why should we watch for developments in neuroscience? Please list one reason. <please input your answer>,We should watch for developments in neuroscience. There are still areas where people perform much better than AI. There may be a different operating principle we can learn from biological neural networks. Two pictures that show the similarty between a biological neuron and the one in ANN.
79608a4c-059d-407b-8884-7d42ab6dd691,train,future,elementary school,u26,11,group 3,post test,6,11,0,deep learning,Generative model,What is the name of the neural network that can generate new examples of what it has learned but has not yet seen? <please input your answer>,Generative model. Another thing that humans have but machines seem to lack is creativity. ANN models called the generative model can create examples after learning. Generative adversarial network (GAN) learns to generate outputs indistinguishable from the real data. Images generated by GAN.
e1ce5c0a-17dd-4710-8cee-5b62eb89e87b,train,past,elementary school,u26,11,group 3,post test,5,13,0,by remembering,The original task and the applied task have some common features,In which condition can transfer learning reduce the time to train for the new task? (Hint: not a exact example like CNN.) <please input your answer>,Transfer learning to new areas. Humans also seem to have the ability to transfer learning to new areas. A network trained for one task may be able to be trained for another task faster if the original task and the applied task have some common features. A picture showing transfer learning where the source data/labels are larger than the target data/labels.
8297e6a5-36a8-45a0-b8c5-1c671fcf2ad4,train,future,elementary school,u26,11,group 3,post test,7,12,0,?,Generator/Discriminator,What are names of the two smaller models in the the neural network that can generate examples of what it has learned but has not yet seen <please input your answer>,GAN in details. A picture of the GAN architecture (random noise to generator to generate a fake image and a discriminator trying to discriminate that from the training image)
21df80d6-6ea4-4fb5-863c-9cf6de5bb39d,train,past,elementary school,u25,11,group 3,post test,3,8,0,Numbers and labels,"numbers/labels, the statistical relationships among them","In graphic models, what does nodes and lines represent? <please input your answer>",Graphical model. Graphical model is a new kind of fast-learning algorithm. Nodes: describe anything that can be represented by numbers or labels. Arrows and lines: show one node’s value ends up with the given value of another node. A picture of an example graph.
e0f0fac7-365f-4bf6-9e06-f629615e4b37,train,past,elementary school,u25,11,group 3,post test,4,10,1,LSL,few shot learning,What is the name of the method that enables ANNs to learn from limited examples? <please input your answer>,Few-shot learning. Few-shot learning aims to build accurate machine learning models with less training data. A picture highlighting the difference between large data training and few-shot training.
dc44fd88-0b11-46bb-ac92-ecb2ba8deab3,train,past,elementary school,u25,11,group 3,post test,1,4,1,Backpropagation,backpropagation,Please give an example of mechanism that neurons do not have but neural networks have? <please input your answer>,"The interaction has decreased. A real neuron is made of tiny electrochemical processes that are only roughly approximated in an artificial neuron model. It is unlikely that backpropagation is going on in the brain when people learn, while backpropagation is a powerful algorithm for training ANNs. A picture of backpropagation."
cac1566a-fc27-49d2-b176-bfdcf7265c2d,train,future,elementary school,u25,11,group 3,post test,8,17,1,6,Six,How many layers does the cortex of the human big brain have? <please input your answer>,"The structure of human brain. The “big brain” of humans is made of six layers organized into columns. We don’t precisely understand how the layers and columns work although we know how these cell types are distributed in the layers. Once we find out, the understanding of brain may change and impact ANN technology. A picture showing the six layers of a human brain."
24325f1e-cf24-448c-aa1b-b29e2dbd3d99,train,past,elementary school,u25,11,group 3,post test,2,5,1,People can still preform better that AI,There are still areas where people perform much better than AI,Why should we watch for developments in neuroscience? Please list one reason. <please input your answer>,We should watch for developments in neuroscience. There are still areas where people perform much better than AI. There may be a different operating principle we can learn from biological neural networks. Two pictures that show the similarty between a biological neuron and the one in ANN.
a4b194fd-ff65-4cba-abac-c8b680396714,train,future,elementary school,u25,11,group 3,post test,6,11,1,Generative model,Generative model,What is the name of the neural network that can generate new examples of what it has learned but has not yet seen? <please input your answer>,Generative model. Another thing that humans have but machines seem to lack is creativity. ANN models called the generative model can create examples after learning. Generative adversarial network (GAN) learns to generate outputs indistinguishable from the real data. Images generated by GAN.
e2114dbe-e658-4a44-86e8-2069bb186494,train,past,elementary school,u25,11,group 3,post test,5,13,0,?,The original task and the applied task have some common features,In which condition can transfer learning reduce the time to train for the new task? (Hint: not a exact example like CNN.) <please input your answer>,Transfer learning to new areas. Humans also seem to have the ability to transfer learning to new areas. A network trained for one task may be able to be trained for another task faster if the original task and the applied task have some common features. A picture showing transfer learning where the source data/labels are larger than the target data/labels.
6569989b-1d1d-4d40-8329-6d8b238191c8,train,future,elementary school,u25,11,group 3,post test,7,12,0,?,Generator/Discriminator,What are names of the two smaller models in the the neural network that can generate examples of what it has learned but has not yet seen <please input your answer>,GAN in details. A picture of the GAN architecture (random noise to generator to generate a fake image and a discriminator trying to discriminate that from the training image)
790207be-694d-4e48-8b3e-aaa5833b3181,train,past,elementary school,u42,11,group 3,post test,3,8,0,IDK,"numbers/labels, the statistical relationships among them","In graphic models, what does nodes and lines represent? <please input your answer>",Graphical model. Graphical model is a new kind of fast-learning algorithm. Nodes: describe anything that can be represented by numbers or labels. Arrows and lines: show one node’s value ends up with the given value of another node. A picture of an example graph.
b9676dfc-158a-4fc3-9d99-2ca5ec092653,train,past,elementary school,u42,11,group 3,post test,4,10,0,IDK,few shot learning,What is the name of the method that enables ANNs to learn from limited examples? <please input your answer>,Few-shot learning. Few-shot learning aims to build accurate machine learning models with less training data. A picture highlighting the difference between large data training and few-shot training.
dae82500-b565-44cc-8c4c-db635239be37,train,past,elementary school,u42,11,group 3,post test,1,4,0,IDK,backpropagation,Please give an example of mechanism that neurons do not have but neural networks have? <please input your answer>,"The interaction has decreased. A real neuron is made of tiny electrochemical processes that are only roughly approximated in an artificial neuron model. It is unlikely that backpropagation is going on in the brain when people learn, while backpropagation is a powerful algorithm for training ANNs. A picture of backpropagation."
a7615ce1-5eea-49e8-9e81-eec1279a4849,train,future,elementary school,u42,11,group 3,post test,8,17,1,6,Six,How many layers does the cortex of the human big brain have? <please input your answer>,"The structure of human brain. The “big brain” of humans is made of six layers organized into columns. We don’t precisely understand how the layers and columns work although we know how these cell types are distributed in the layers. Once we find out, the understanding of brain may change and impact ANN technology. A picture showing the six layers of a human brain."
f271f075-9000-4c9f-92fc-ecb14fcc2cef,train,past,elementary school,u42,11,group 3,post test,2,5,0,IDK,There are still areas where people perform much better than AI,Why should we watch for developments in neuroscience? Please list one reason. <please input your answer>,We should watch for developments in neuroscience. There are still areas where people perform much better than AI. There may be a different operating principle we can learn from biological neural networks. Two pictures that show the similarty between a biological neuron and the one in ANN.
d133d70d-a12b-4ed7-bb59-008e04700a01,train,future,elementary school,u42,11,group 3,post test,6,11,0,IDK,Generative model,What is the name of the neural network that can generate new examples of what it has learned but has not yet seen? <please input your answer>,Generative model. Another thing that humans have but machines seem to lack is creativity. ANN models called the generative model can create examples after learning. Generative adversarial network (GAN) learns to generate outputs indistinguishable from the real data. Images generated by GAN.
23eabbe3-b3f7-45d9-ab4d-1094bec86048,train,past,elementary school,u42,11,group 3,post test,5,13,0,IDK,The original task and the applied task have some common features,In which condition can transfer learning reduce the time to train for the new task? (Hint: not a exact example like CNN.) <please input your answer>,Transfer learning to new areas. Humans also seem to have the ability to transfer learning to new areas. A network trained for one task may be able to be trained for another task faster if the original task and the applied task have some common features. A picture showing transfer learning where the source data/labels are larger than the target data/labels.
84e0d337-5717-47c9-9a75-db42bd3ed9b8,train,future,elementary school,u42,11,group 3,post test,7,12,0,IDK,Generator/Discriminator,What are names of the two smaller models in the the neural network that can generate examples of what it has learned but has not yet seen <please input your answer>,GAN in details. A picture of the GAN architecture (random noise to generator to generate a fake image and a discriminator trying to discriminate that from the training image)
80d709cb-8fb8-4c49-9547-7dbc8ef2fd48,test,past,elementary school,u46,11,group 3,post test,3,8,1,"numbers/labels, the statistical relationships among them","numbers/labels, the statistical relationships among them","In graphic models, what does nodes and lines represent? <please input your answer>",Graphical model. Graphical model is a new kind of fast-learning algorithm. Nodes: describe anything that can be represented by numbers or labels. Arrows and lines: show one node’s value ends up with the given value of another node. A picture of an example graph.
b679d0f1-3d66-4c14-9cae-e77d159ebd47,test,past,elementary school,u46,11,group 3,post test,4,10,1,LSL,few shot learning,What is the name of the method that enables ANNs to learn from limited examples? <please input your answer>,Few-shot learning. Few-shot learning aims to build accurate machine learning models with less training data. A picture highlighting the difference between large data training and few-shot training.
6627b248-24f6-4cae-bcbe-be9989c9f458,test,past,elementary school,u46,11,group 3,post test,1,4,1,backpropagation,backpropagation,Please give an example of mechanism that neurons do not have but neural networks have? <please input your answer>,"The interaction has decreased. A real neuron is made of tiny electrochemical processes that are only roughly approximated in an artificial neuron model. It is unlikely that backpropagation is going on in the brain when people learn, while backpropagation is a powerful algorithm for training ANNs. A picture of backpropagation."
89945f93-3656-4e07-b3fa-01116479e9ba,test,future,elementary school,u46,11,group 3,post test,8,17,1,6,Six,How many layers does the cortex of the human big brain have? <please input your answer>,"The structure of human brain. The “big brain” of humans is made of six layers organized into columns. We don’t precisely understand how the layers and columns work although we know how these cell types are distributed in the layers. Once we find out, the understanding of brain may change and impact ANN technology. A picture showing the six layers of a human brain."
98e39bdd-abb2-4780-9d78-c3d13f890145,test,past,elementary school,u46,11,group 3,post test,2,5,1,There are still areas where people perform much better than AI,There are still areas where people perform much better than AI,Why should we watch for developments in neuroscience? Please list one reason. <please input your answer>,We should watch for developments in neuroscience. There are still areas where people perform much better than AI. There may be a different operating principle we can learn from biological neural networks. Two pictures that show the similarty between a biological neuron and the one in ANN.
bb3bf9b5-de0e-4318-816f-b87c107da6d0,test,future,elementary school,u46,11,group 3,post test,6,11,1,Generative model,Generative model,What is the name of the neural network that can generate new examples of what it has learned but has not yet seen? <please input your answer>,Generative model. Another thing that humans have but machines seem to lack is creativity. ANN models called the generative model can create examples after learning. Generative adversarial network (GAN) learns to generate outputs indistinguishable from the real data. Images generated by GAN.
54a896e0-4b0f-4cc9-a6a6-bf4618aa206c,test,past,elementary school,u46,11,group 3,post test,5,13,1,The original task and the applied task have some common features,The original task and the applied task have some common features,In which condition can transfer learning reduce the time to train for the new task? (Hint: not a exact example like CNN.) <please input your answer>,Transfer learning to new areas. Humans also seem to have the ability to transfer learning to new areas. A network trained for one task may be able to be trained for another task faster if the original task and the applied task have some common features. A picture showing transfer learning where the source data/labels are larger than the target data/labels.
78f49f69-2c40-4d47-aa7f-79768f8d1546,test,future,elementary school,u46,11,group 3,post test,7,12,1,generator/disctriminator,Generator/Discriminator,What are names of the two smaller models in the the neural network that can generate examples of what it has learned but has not yet seen <please input your answer>,GAN in details. A picture of the GAN architecture (random noise to generator to generate a fake image and a discriminator trying to discriminate that from the training image)
6fe8d901-7fc0-4650-bc20-1cfb9f8064ad,test,past,elementary school,u23,11,group 3,post test,3,8,0,Nodes represent value,"numbers/labels, the statistical relationships among them","In graphic models, what does nodes and lines represent? <please input your answer>",Graphical model. Graphical model is a new kind of fast-learning algorithm. Nodes: describe anything that can be represented by numbers or labels. Arrows and lines: show one node’s value ends up with the given value of another node. A picture of an example graph.
1776e024-c00e-4dad-a05b-b31f42934f62,test,past,elementary school,u23,11,group 3,post test,4,10,0,fewer something,few shot learning,What is the name of the method that enables ANNs to learn from limited examples? <please input your answer>,Few-shot learning. Few-shot learning aims to build accurate machine learning models with less training data. A picture highlighting the difference between large data training and few-shot training.
15ee0561-de45-4f03-8c34-a542c8da8148,test,past,elementary school,u23,11,group 3,post test,1,4,0,Brainwaves,backpropagation,Please give an example of mechanism that neurons do not have but neural networks have? <please input your answer>,"The interaction has decreased. A real neuron is made of tiny electrochemical processes that are only roughly approximated in an artificial neuron model. It is unlikely that backpropagation is going on in the brain when people learn, while backpropagation is a powerful algorithm for training ANNs. A picture of backpropagation."
c4824f7b-8cd3-426a-9feb-8716a53a81d8,test,future,elementary school,u23,11,group 3,post test,8,17,1,6,Six,How many layers does the cortex of the human big brain have? <please input your answer>,"The structure of human brain. The “big brain” of humans is made of six layers organized into columns. We don’t precisely understand how the layers and columns work although we know how these cell types are distributed in the layers. Once we find out, the understanding of brain may change and impact ANN technology. A picture showing the six layers of a human brain."
af116b8a-44f7-4c39-97d5-01b2d61ae065,test,past,elementary school,u23,11,group 3,post test,2,5,0,We can make our lives more convienient.,There are still areas where people perform much better than AI,Why should we watch for developments in neuroscience? Please list one reason. <please input your answer>,We should watch for developments in neuroscience. There are still areas where people perform much better than AI. There may be a different operating principle we can learn from biological neural networks. Two pictures that show the similarty between a biological neuron and the one in ANN.
c4f09ded-2383-448f-9226-edf5c4da509c,test,future,elementary school,u23,11,group 3,post test,6,11,1,Generative Model,Generative model,What is the name of the neural network that can generate new examples of what it has learned but has not yet seen? <please input your answer>,Generative model. Another thing that humans have but machines seem to lack is creativity. ANN models called the generative model can create examples after learning. Generative adversarial network (GAN) learns to generate outputs indistinguishable from the real data. Images generated by GAN.
6d496d5d-7ace-4865-8c04-75d989ad6525,test,past,elementary school,u23,11,group 3,post test,5,13,0,idk,The original task and the applied task have some common features,In which condition can transfer learning reduce the time to train for the new task? (Hint: not a exact example like CNN.) <please input your answer>,Transfer learning to new areas. Humans also seem to have the ability to transfer learning to new areas. A network trained for one task may be able to be trained for another task faster if the original task and the applied task have some common features. A picture showing transfer learning where the source data/labels are larger than the target data/labels.
eb046aad-1977-4f60-8c16-d18deed4a7e3,test,future,elementary school,u23,11,group 3,post test,7,12,1,Generative Model and Discriminator model,Generator/Discriminator,What are names of the two smaller models in the the neural network that can generate examples of what it has learned but has not yet seen <please input your answer>,GAN in details. A picture of the GAN architecture (random noise to generator to generate a fake image and a discriminator trying to discriminate that from the training image)
6dbd2183-15ad-493c-9f80-63225f9eecab,test,past,elementary school,u24,11,group 3,post test,3,8,0, ,"numbers/labels, the statistical relationships among them","In graphic models, what does nodes and lines represent? <please input your answer>",Graphical model. Graphical model is a new kind of fast-learning algorithm. Nodes: describe anything that can be represented by numbers or labels. Arrows and lines: show one node’s value ends up with the given value of another node. A picture of an example graph.
9e8f5edf-629b-4805-81a0-7620e1ce988d,test,past,elementary school,u24,11,group 3,post test,4,10,0, ,few shot learning,What is the name of the method that enables ANNs to learn from limited examples? <please input your answer>,Few-shot learning. Few-shot learning aims to build accurate machine learning models with less training data. A picture highlighting the difference between large data training and few-shot training.
5f5ba3d9-a3b7-495f-b9af-1c9d363fabca,test,past,elementary school,u24,11,group 3,post test,1,4,0, ,backpropagation,Please give an example of mechanism that neurons do not have but neural networks have? <please input your answer>,"The interaction has decreased. A real neuron is made of tiny electrochemical processes that are only roughly approximated in an artificial neuron model. It is unlikely that backpropagation is going on in the brain when people learn, while backpropagation is a powerful algorithm for training ANNs. A picture of backpropagation."
0db23ebb-d3a7-44ac-b36b-e17d5451dc07,test,future,elementary school,u24,11,group 3,post test,8,17,0,7,Six,How many layers does the cortex of the human big brain have? <please input your answer>,"The structure of human brain. The “big brain” of humans is made of six layers organized into columns. We don’t precisely understand how the layers and columns work although we know how these cell types are distributed in the layers. Once we find out, the understanding of brain may change and impact ANN technology. A picture showing the six layers of a human brain."
5771f258-4b07-4cdc-81cd-e13d6e222838,test,past,elementary school,u24,11,group 3,post test,2,5,0, ,There are still areas where people perform much better than AI,Why should we watch for developments in neuroscience? Please list one reason. <please input your answer>,We should watch for developments in neuroscience. There are still areas where people perform much better than AI. There may be a different operating principle we can learn from biological neural networks. Two pictures that show the similarty between a biological neuron and the one in ANN.
840d9b40-98c1-4f7e-8049-839003793b4c,test,future,elementary school,u24,11,group 3,post test,6,11,0, ,Generative model,What is the name of the neural network that can generate new examples of what it has learned but has not yet seen? <please input your answer>,Generative model. Another thing that humans have but machines seem to lack is creativity. ANN models called the generative model can create examples after learning. Generative adversarial network (GAN) learns to generate outputs indistinguishable from the real data. Images generated by GAN.
cdd15c1e-a0f1-4d0a-b9a5-b3a4765131b6,test,past,elementary school,u24,11,group 3,post test,5,13,0, ,The original task and the applied task have some common features,In which condition can transfer learning reduce the time to train for the new task? (Hint: not a exact example like CNN.) <please input your answer>,Transfer learning to new areas. Humans also seem to have the ability to transfer learning to new areas. A network trained for one task may be able to be trained for another task faster if the original task and the applied task have some common features. A picture showing transfer learning where the source data/labels are larger than the target data/labels.
f5a79ec9-049f-4822-960c-a5fbd9941138,test,future,elementary school,u24,11,group 3,post test,7,12,0, ,Generator/Discriminator,What are names of the two smaller models in the the neural network that can generate examples of what it has learned but has not yet seen <please input your answer>,GAN in details. A picture of the GAN architecture (random noise to generator to generate a fake image and a discriminator trying to discriminate that from the training image)
dd696117-ee42-4219-a421-8f20f8386449,train,past,elementary school,u14,1,group 1,post test,3,8,0,Deduction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
43c741fc-8b7d-4a2a-a755-09fb733128f8,train,past,elementary school,u14,1,group 1,post test,4,4,1,Supervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Birth of AI. 1956 Workshop at Dartmouth College. John McCarthy. Marvin Lee Minsky. Claude Elwood Shannon. -Name 'Artificial Intelligence' for the new field. It contains three pictures of the three people mentioned in this slide.
24809daa-20ed-4aaf-bb54-d8e83624e987,train,past,elementary school,u14,1,group 1,post test,1,9,1,False,B,Is this statement correct or wrong? 'Machines can know tomorrow's weather only by logic' <please select the best answer> A. True B. False,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
0e7a4291-e8dd-45c2-ae2e-ca41408e4c3b,train,future,elementary school,u14,1,group 1,post test,8,11,1,1/the amount of sides a dice has,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
f5c03e16-b7ca-4285-b897-73bd0b6e1726,train,future,elementary school,u14,1,group 1,post test,9,18,1,neurons,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
26d123ba-60a3-4fcc-a5e7-0215cc0fe447,train,past,elementary school,u14,1,group 1,post test,2,15,1,True,A,Is this statement correct or wrong? 'A neuron learns by changing the connection weight to a synaptic weight' <please select the best answer> A. True B. False,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
4173cf89-7dcc-4a65-a7f1-8eefc5415c88,train,future,elementary school,u14,1,group 1,post test,6,19,1,Unsupervised learning,B,Which of the three ways of learning is like learning without a teacher? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Unsupervised learning is without a teacher the ANN is given a lot of examples and tries to figure out how data can be organized. Don’t need correct answers but not possible for everything. It contains a picture of unsupervised learning.
0f2ad3ca-6535-48a3-b175-41ee063fb730,train,past,elementary school,u14,1,group 1,post test,5,18,1,Reinforcement learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
00f80152-df66-469f-8d24-6df80b7640c4,train,future,elementary school,u14,1,group 1,post test,10,9,1,a right triangle's angles sum up to 180 degrees,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
e9dd094a-b353-4a96-8c7e-8bda878a0c63,train,future,elementary school,u14,1,group 1,post test,7,2,0,"Data, infastructure, culture","Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
4b8f3a4f-6bab-4406-86c8-56e966252645,train,past,elementary school,u2,1,group 1,post test,3,8,0,Deduction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
7672568f-292b-448b-bb4a-f4daa79cd150,train,past,elementary school,u2,1,group 1,post test,4,4,0,Reinforcement learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Birth of AI. 1956 Workshop at Dartmouth College. John McCarthy. Marvin Lee Minsky. Claude Elwood Shannon. -Name 'Artificial Intelligence' for the new field. It contains three pictures of the three people mentioned in this slide.
7d847da6-742d-4511-96fd-e17e59bc04db,train,past,elementary school,u2,1,group 1,post test,1,9,0,True,B,Is this statement correct or wrong? 'Machines can know tomorrow's weather only by logic' <please select the best answer> A. True B. False,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
68865adf-49af-47af-8db1-d27f54bf9413,train,future,elementary school,u2,1,group 1,post test,8,11,1,1 in 6,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
f8f5c909-f883-44d8-9c1f-14125534400a,train,future,elementary school,u2,1,group 1,post test,9,18,1,Neurons,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
89b18074-960e-4e28-82b4-cdfadf249c93,train,past,elementary school,u2,1,group 1,post test,2,15,1,True,A,Is this statement correct or wrong? 'A neuron learns by changing the connection weight to a synaptic weight' <please select the best answer> A. True B. False,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
9542d248-5de8-41b7-acb1-203cde906dd7,train,future,elementary school,u2,1,group 1,post test,6,19,1,Unsupervised learning,B,Which of the three ways of learning is like learning without a teacher? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Unsupervised learning is without a teacher the ANN is given a lot of examples and tries to figure out how data can be organized. Don’t need correct answers but not possible for everything. It contains a picture of unsupervised learning.
89aeb02e-0931-478b-aab9-c78c565e960d,train,past,elementary school,u2,1,group 1,post test,5,18,0,Unsupervised learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
87359f20-16c7-4b08-8363-79d5de4f996b,train,future,elementary school,u2,1,group 1,post test,10,9,1,The sum of the two other angles is 90 degrees in a right triangle,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
a2ed93aa-7049-4e50-a019-b04503e2d65f,train,future,elementary school,u2,1,group 1,post test,7,2,0,"Machine learning, deep learning, and neural networks","Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
303b3371-5a83-464a-ad52-9a2363e0fbc6,train,past,elementary school,u4,1,group 1,post test,3,8,1,Induction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
0a1cdd40-626d-471d-bef7-dd8fd4ad3fd4,train,past,elementary school,u4,1,group 1,post test,4,4,1,Supervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Birth of AI. 1956 Workshop at Dartmouth College. John McCarthy. Marvin Lee Minsky. Claude Elwood Shannon. -Name 'Artificial Intelligence' for the new field. It contains three pictures of the three people mentioned in this slide.
806c7188-99f3-4d36-b4e0-0192baee514a,train,past,elementary school,u4,1,group 1,post test,1,9,0,True,B,Is this statement correct or wrong? 'Machines can know tomorrow's weather only by logic' <please select the best answer> A. True B. False,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
185d9eca-8471-45d3-b2ff-f97ac30ba632,train,future,elementary school,u4,1,group 1,post test,8,11,1,1/6,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
cb15e234-e456-4724-a033-b868ee2f0658,train,future,elementary school,u4,1,group 1,post test,9,18,1,neuron,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
7239f49d-ed45-40f4-acfa-74639f34e76b,train,past,elementary school,u4,1,group 1,post test,2,15,1,True,A,Is this statement correct or wrong? 'A neuron learns by changing the connection weight to a synaptic weight' <please select the best answer> A. True B. False,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
69df05ab-b8b9-45c3-a9fe-dae5d30e1451,train,future,elementary school,u4,1,group 1,post test,6,19,0,Supervised learning,B,Which of the three ways of learning is like learning without a teacher? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Unsupervised learning is without a teacher the ANN is given a lot of examples and tries to figure out how data can be organized. Don’t need correct answers but not possible for everything. It contains a picture of unsupervised learning.
32de107e-c3dd-438b-97f5-632beb4e3f5a,train,past,elementary school,u4,1,group 1,post test,5,18,0,Unsupervised learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
23530617-0127-42de-a176-57ead4d9ffbd,train,future,elementary school,u4,1,group 1,post test,10,9,1,one triangle,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
1c581c33-8c3b-4d84-8162-fcd284066db6,train,future,elementary school,u4,1,group 1,post test,7,2,0,"hardware,software,engineer","Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
166185e6-55f9-4fd2-9cef-9c8db4156514,train,past,elementary school,u7,1,group 2,post test,3,8,1,Induction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
b9e5f471-a694-4ce9-a7dd-f6f2516e4fce,train,past,elementary school,u7,1,group 2,post test,4,4,1,Supervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Birth of AI. 1956 Workshop at Dartmouth College. John McCarthy. Marvin Lee Minsky. Claude Elwood Shannon. -Name 'Artificial Intelligence' for the new field. It contains three pictures of the three people mentioned in this slide.
54ca7c0d-bd7e-4793-b54d-e9585646beb2,train,past,elementary school,u7,1,group 2,post test,1,9,0,True,B,Is this statement correct or wrong? 'Machines can know tomorrow's weather only by logic' <please select the best answer> A. True B. False,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
a87b3f7f-d87e-4753-b3e6-58b5c2fbef54,train,future,elementary school,u7,1,group 2,post test,8,11,1,1/6,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
3aa788d1-91b0-4b17-b528-42c6f4c793ed,train,future,elementary school,u7,1,group 2,post test,9,18,1,neurons,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
8dc76090-d4cb-4482-8aa3-16f955201cfe,train,past,elementary school,u7,1,group 2,post test,2,15,1,True,A,Is this statement correct or wrong? 'A neuron learns by changing the connection weight to a synaptic weight' <please select the best answer> A. True B. False,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
a25f1c96-7b07-49ae-b047-19de9dd2bdbd,train,future,elementary school,u7,1,group 2,post test,6,19,1,Unsupervised learning,B,Which of the three ways of learning is like learning without a teacher? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Unsupervised learning is without a teacher the ANN is given a lot of examples and tries to figure out how data can be organized. Don’t need correct answers but not possible for everything. It contains a picture of unsupervised learning.
a89a6627-3f7f-4334-a27b-0fb55785d60d,train,past,elementary school,u7,1,group 2,post test,5,18,1,Reinforcement learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
0b847040-af62-4dcf-ae8f-05c9308b2aae,train,future,elementary school,u7,1,group 2,post test,10,9,1,2 angles add up to 90,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
1b94e538-28b4-4ecf-b258-ee7f43f7b1a1,train,future,elementary school,u7,1,group 2,post test,7,2,0,"logic, data,code","Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
95b0fe38-ea6e-440c-9b56-006639ee0310,train,past,elementary school,u55,1,group 2,post test,3,8,0,Deduction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
30c7882c-1161-4b3a-8f4e-a1c19fd3b3fb,train,past,elementary school,u55,1,group 2,post test,4,4,1,Supervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Birth of AI. 1956 Workshop at Dartmouth College. John McCarthy. Marvin Lee Minsky. Claude Elwood Shannon. -Name 'Artificial Intelligence' for the new field. It contains three pictures of the three people mentioned in this slide.
b25414a0-397c-4858-aa88-45c7c6a95c97,train,past,elementary school,u55,1,group 2,post test,1,9,0,True,B,Is this statement correct or wrong? 'Machines can know tomorrow's weather only by logic' <please select the best answer> A. True B. False,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
457f15a9-9d3a-4b9e-bb1c-abf1a0b7f8ea,train,future,elementary school,u55,1,group 2,post test,8,11,0,i do not know!,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
48431f1e-d8e5-4b13-8e77-50e376e432fc,train,future,elementary school,u55,1,group 2,post test,9,18,0,i do not know!,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
094f8d37-0003-43fc-b899-db51542f00c3,train,past,elementary school,u55,1,group 2,post test,2,15,0,False,A,Is this statement correct or wrong? 'A neuron learns by changing the connection weight to a synaptic weight' <please select the best answer> A. True B. False,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
19e9929f-eda5-41d8-a77f-7d1a9690ef5f,train,future,elementary school,u55,1,group 2,post test,6,19,1,Unsupervised learning,B,Which of the three ways of learning is like learning without a teacher? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Unsupervised learning is without a teacher the ANN is given a lot of examples and tries to figure out how data can be organized. Don’t need correct answers but not possible for everything. It contains a picture of unsupervised learning.
94d44443-db06-4539-9cf1-8b825836efcb,train,past,elementary school,u55,1,group 2,post test,5,18,0,Unsupervised learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
41787bac-a6b6-442e-9251-020edbb19bfb,train,future,elementary school,u55,1,group 2,post test,10,9,0,i do not know!,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
982732af-3bba-4ef7-bfb6-fc70b4658983,train,future,elementary school,u55,1,group 2,post test,7,2,0,i do not know!,"Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
f021f25e-1dc3-4553-984c-21ac856fcc75,test,past,elementary school,u51,1,group 2,post test,3,8,0,Deduction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
d6d76d07-25c7-4b32-9de8-1df33195ddb8,test,past,elementary school,u51,1,group 2,post test,4,4,1,Supervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Birth of AI. 1956 Workshop at Dartmouth College. John McCarthy. Marvin Lee Minsky. Claude Elwood Shannon. -Name 'Artificial Intelligence' for the new field. It contains three pictures of the three people mentioned in this slide.
e1de35a1-3bc0-4482-90fc-f89f48fb1ce4,test,past,elementary school,u51,1,group 2,post test,1,9,1,False,B,Is this statement correct or wrong? 'Machines can know tomorrow's weather only by logic' <please select the best answer> A. True B. False,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
98ee1c70-6793-4b99-a020-fa3734306662,test,future,elementary school,u51,1,group 2,post test,8,11,1,1 out of 6,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
9d719001-36aa-4725-8485-8310f34dce70,test,future,elementary school,u51,1,group 2,post test,9,18,1,Neurons,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
7c6d1913-eba3-4dc6-a54e-ae6063c5c6f4,test,past,elementary school,u51,1,group 2,post test,2,15,1,True,A,Is this statement correct or wrong? 'A neuron learns by changing the connection weight to a synaptic weight' <please select the best answer> A. True B. False,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
0bb5786e-f5e7-491f-b684-d18e8425bdff,test,future,elementary school,u51,1,group 2,post test,6,19,1,Unsupervised learning,B,Which of the three ways of learning is like learning without a teacher? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Unsupervised learning is without a teacher the ANN is given a lot of examples and tries to figure out how data can be organized. Don’t need correct answers but not possible for everything. It contains a picture of unsupervised learning.
9b854140-e982-4a2b-bfce-54cb624db856,test,past,elementary school,u51,1,group 2,post test,5,18,0,Supervised learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
830a52c8-e30f-4658-b1f6-b3412fdddedd,test,future,elementary school,u51,1,group 2,post test,10,9,1,A right triangle is 180 degrees,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
b28228a8-96f8-4f6c-97bd-0ed220b2c22f,test,future,elementary school,u51,1,group 2,post test,7,2,0,"Logic,stitistics,","Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
eaa4956b-5e80-4bac-86e0-311c7ef17c2f,test,past,elementary school,u56,1,group 2,post test,3,8,1,Induction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
58ff91a8-fce7-427d-a471-5e5cf7beb0ee,test,past,elementary school,u56,1,group 2,post test,4,4,1,Supervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Birth of AI. 1956 Workshop at Dartmouth College. John McCarthy. Marvin Lee Minsky. Claude Elwood Shannon. -Name 'Artificial Intelligence' for the new field. It contains three pictures of the three people mentioned in this slide.
3fea5b5f-71e5-49de-bed5-7614efdcc8bc,test,past,elementary school,u56,1,group 2,post test,1,9,1,False,B,Is this statement correct or wrong? 'Machines can know tomorrow's weather only by logic' <please select the best answer> A. True B. False,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
4e1907c1-8967-4384-be37-d8ab165de9e2,test,future,elementary school,u56,1,group 2,post test,8,11,1,1/6,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
9d0576e5-89d8-425a-ab93-ae50ce22b32f,test,future,elementary school,u56,1,group 2,post test,9,18,1,Neuron,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
2b6977e9-9708-4aaf-995a-48f3ccec4357,test,past,elementary school,u56,1,group 2,post test,2,15,1,True,A,Is this statement correct or wrong? 'A neuron learns by changing the connection weight to a synaptic weight' <please select the best answer> A. True B. False,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
56a057c9-030b-4493-83e4-3aabf3b2fa67,test,future,elementary school,u56,1,group 2,post test,6,19,1,Unsupervised learning,B,Which of the three ways of learning is like learning without a teacher? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Unsupervised learning is without a teacher the ANN is given a lot of examples and tries to figure out how data can be organized. Don’t need correct answers but not possible for everything. It contains a picture of unsupervised learning.
8597116f-733b-4c16-96fe-ab2d25fa3b19,test,past,elementary school,u56,1,group 2,post test,5,18,0,Unsupervised learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
0247c502-7343-4436-831d-f92237057989,test,future,elementary school,u56,1,group 2,post test,10,9,1,180 degrees,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
788e7961-1649-4ffa-8210-1bd1981b47c0,test,future,elementary school,u56,1,group 2,post test,7,2,0,Don't know,"Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
8a231d39-5b72-484a-971b-0d2ef66ed9d1,train,past,elementary school,u27,1,group 2,post test,3,8,1,Induction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
be95e05b-d6b9-40a4-93ad-8940aa695e5a,train,past,elementary school,u27,1,group 2,post test,4,4,1,Supervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Birth of AI. 1956 Workshop at Dartmouth College. John McCarthy. Marvin Lee Minsky. Claude Elwood Shannon. -Name 'Artificial Intelligence' for the new field. It contains three pictures of the three people mentioned in this slide.
d5957cba-bd96-43b2-b0ef-e65e4cb65bf3,train,past,elementary school,u27,1,group 2,post test,1,9,0,True,B,Is this statement correct or wrong? 'Machines can know tomorrow's weather only by logic' <please select the best answer> A. True B. False,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
789a7c0a-2959-42e2-97e2-364ec37cae98,train,future,elementary school,u27,1,group 2,post test,8,11,1,1/6,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
3aaeab7c-513e-4474-805c-22f7d86e4acc,train,future,elementary school,u27,1,group 2,post test,9,18,1,neural ,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
a8304707-2ba7-493b-a6cb-bb32aa511f94,train,past,elementary school,u27,1,group 2,post test,2,15,1,True,A,Is this statement correct or wrong? 'A neuron learns by changing the connection weight to a synaptic weight' <please select the best answer> A. True B. False,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
381a2366-cc5b-482e-b767-371eff72e4ae,train,future,elementary school,u27,1,group 2,post test,6,19,1,Unsupervised learning,B,Which of the three ways of learning is like learning without a teacher? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Unsupervised learning is without a teacher the ANN is given a lot of examples and tries to figure out how data can be organized. Don’t need correct answers but not possible for everything. It contains a picture of unsupervised learning.
ecb3e866-3cf8-4a41-8538-77c0f91bd049,train,past,elementary school,u27,1,group 2,post test,5,18,1,Reinforcement learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
86fdddd6-1486-4a9b-a0aa-7fd782a43db2,train,future,elementary school,u27,1,group 2,post test,10,9,1,the two angle adds up to 90 degrees,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
cdd0b4cb-1f5e-48da-b891-bfa8b91f25ee,train,future,elementary school,u27,1,group 2,post test,7,2,1,"logic, statistics, neural network","Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
d18af483-8082-492f-9e61-55c54921fe18,test,past,elementary school,u1,1,group 2,post test,3,8,0,Deduction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
32f1e5c8-9b4a-453c-bfee-cea037ba3e7f,test,past,elementary school,u1,1,group 2,post test,4,4,1,Supervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Birth of AI. 1956 Workshop at Dartmouth College. John McCarthy. Marvin Lee Minsky. Claude Elwood Shannon. -Name 'Artificial Intelligence' for the new field. It contains three pictures of the three people mentioned in this slide.
54aa320d-68f1-4626-bdd2-09133c595383,test,past,elementary school,u1,1,group 2,post test,1,9,1,False,B,Is this statement correct or wrong? 'Machines can know tomorrow's weather only by logic' <please select the best answer> A. True B. False,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
86637584-efa0-4200-921a-549ec5f2e480,test,future,elementary school,u1,1,group 2,post test,8,11,1,1/ how many faced there are,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
268dc42f-ac83-4e40-a192-73ee9344a12d,test,future,elementary school,u1,1,group 2,post test,9,18,1,Neurons ,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
1af3059b-377e-47da-95b1-3a2bbafc006d,test,past,elementary school,u1,1,group 2,post test,2,15,1,True,A,Is this statement correct or wrong? 'A neuron learns by changing the connection weight to a synaptic weight' <please select the best answer> A. True B. False,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
4aca07b1-0ffe-4cb9-9950-d322d3dc65b5,test,future,elementary school,u1,1,group 2,post test,6,19,1,Unsupervised learning,B,Which of the three ways of learning is like learning without a teacher? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Unsupervised learning is without a teacher the ANN is given a lot of examples and tries to figure out how data can be organized. Don’t need correct answers but not possible for everything. It contains a picture of unsupervised learning.
136146f3-2399-4798-bd16-8a0b3b9cccb3,test,past,elementary school,u1,1,group 2,post test,5,18,1,Reinforcement learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
128ca34a-f967-40d2-9bb1-1cdc5b2c6f79,test,future,elementary school,u1,1,group 2,post test,10,9,1,A right triangle is 180 degrees ,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
37151133-24f9-41a4-b9e8-aeb5c5a28735,test,future,elementary school,u1,1,group 2,post test,7,2,0,Data Prep Cleansing,"Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
b5ecfc77-49d4-4914-8317-a8ebcc095432,train,past,elementary school,u8,1,group 2,post test,3,8,1,Induction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
b6903fee-1c4b-46fd-b5a5-eebe32aafa1b,train,past,elementary school,u8,1,group 2,post test,4,4,1,Supervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Birth of AI. 1956 Workshop at Dartmouth College. John McCarthy. Marvin Lee Minsky. Claude Elwood Shannon. -Name 'Artificial Intelligence' for the new field. It contains three pictures of the three people mentioned in this slide.
c3d01fa0-12af-4772-976b-01e2b253c076,train,past,elementary school,u8,1,group 2,post test,1,9,1,False,B,Is this statement correct or wrong? 'Machines can know tomorrow's weather only by logic' <please select the best answer> A. True B. False,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
e460ceaf-4d2b-4763-b6ff-ea2169f56784,train,future,elementary school,u8,1,group 2,post test,8,11,1,1/6,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
d67d503e-d864-4c8f-9770-075c839bd595,train,future,elementary school,u8,1,group 2,post test,9,18,1,Neuron,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
0c8ab47a-8562-406f-a3cc-458de49e2cc9,train,past,elementary school,u8,1,group 2,post test,2,15,1,True,A,Is this statement correct or wrong? 'A neuron learns by changing the connection weight to a synaptic weight' <please select the best answer> A. True B. False,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
d09bc4b2-6d51-40e0-a188-059d479168f2,train,future,elementary school,u8,1,group 2,post test,6,19,1,Unsupervised learning,B,Which of the three ways of learning is like learning without a teacher? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Unsupervised learning is without a teacher the ANN is given a lot of examples and tries to figure out how data can be organized. Don’t need correct answers but not possible for everything. It contains a picture of unsupervised learning.
326ea0b3-842d-49f4-8cce-ff73133a6196,train,past,elementary school,u8,1,group 2,post test,5,18,1,Reinforcement learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
5cefb6c9-1983-4cb3-8b6e-ea693b7f71f3,train,future,elementary school,u8,1,group 2,post test,10,9,1,The sum of the three angles of a right triangle is 180 degrees.,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
b9535f90-42e2-4a4a-b3c1-93d1a0dc36d3,train,future,elementary school,u8,1,group 2,post test,7,2,0,Did not get this one.,"Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
e9ff62ad-3ff8-4d93-948a-a40fa5b428f0,train,past,elementary school,u17,1,group 3,post test,3,8,0,Deduction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
a221e12d-2c94-42a6-8c2b-c7a08ab5cfa6,train,past,elementary school,u17,1,group 3,post test,4,4,1,Supervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Birth of AI. 1956 Workshop at Dartmouth College. John McCarthy. Marvin Lee Minsky. Claude Elwood Shannon. -Name 'Artificial Intelligence' for the new field. It contains three pictures of the three people mentioned in this slide.
61a7dee4-7ffa-4794-8072-9db4ab809920,train,past,elementary school,u17,1,group 3,post test,1,9,1,False,B,Is this statement correct or wrong? 'Machines can know tomorrow's weather only by logic' <please select the best answer> A. True B. False,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
e81cf5cf-5041-49b8-a117-1fa0b22f8999,train,future,elementary school,u17,1,group 3,post test,8,11,1,1/6,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
fd0eb1bd-8426-4cf0-ae3f-d2882430146a,train,future,elementary school,u17,1,group 3,post test,9,18,1,Neurons,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
fe9d6df6-2a9e-4e76-b09c-bd6719f5693f,train,past,elementary school,u17,1,group 3,post test,2,15,1,True,A,Is this statement correct or wrong? 'A neuron learns by changing the connection weight to a synaptic weight' <please select the best answer> A. True B. False,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
12af1987-990e-450a-9804-b96eed3cedff,train,future,elementary school,u17,1,group 3,post test,6,19,1,Unsupervised learning,B,Which of the three ways of learning is like learning without a teacher? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Unsupervised learning is without a teacher the ANN is given a lot of examples and tries to figure out how data can be organized. Don’t need correct answers but not possible for everything. It contains a picture of unsupervised learning.
b49c9258-b7fd-4634-81d3-91435a896e23,train,past,elementary school,u17,1,group 3,post test,5,18,1,Reinforcement learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
fd7bc62a-2935-48ac-a46b-5d61e1606d25,train,future,elementary school,u17,1,group 3,post test,10,9,1,The other 2 angles in the right triangle would sum up to 90 degrees,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
7581729f-a6b2-4a39-b420-51af8dcdb20c,train,future,elementary school,u17,1,group 3,post test,7,2,0,"Data, Hardware, Algorithm ","Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
4d491e6d-9627-48ba-bd66-0a08107e7f92,test,past,elementary school,u11,1,group 3,post test,3,8,0,Deduction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
21104f63-a43f-4724-a2c4-9dac635a4135,test,past,elementary school,u11,1,group 3,post test,4,4,1,Supervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Birth of AI. 1956 Workshop at Dartmouth College. John McCarthy. Marvin Lee Minsky. Claude Elwood Shannon. -Name 'Artificial Intelligence' for the new field. It contains three pictures of the three people mentioned in this slide.
b03dfe84-2f12-4f26-94bd-aa123f3ca49a,test,past,elementary school,u11,1,group 3,post test,1,9,0,True,B,Is this statement correct or wrong? 'Machines can know tomorrow's weather only by logic' <please select the best answer> A. True B. False,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
983fb79d-8477-4f37-8e52-74df564a9b6d,test,future,elementary school,u11,1,group 3,post test,8,11,1,1 out of 6,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
b409a650-66c3-46df-911c-9d7dd1868ba2,test,future,elementary school,u11,1,group 3,post test,9,18,0,?,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
fafcd92a-7aae-41cb-bac7-349e30ced9eb,test,past,elementary school,u11,1,group 3,post test,2,15,1,True,A,Is this statement correct or wrong? 'A neuron learns by changing the connection weight to a synaptic weight' <please select the best answer> A. True B. False,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
dc97bce7-8eed-4d19-923a-ef424e789990,test,future,elementary school,u11,1,group 3,post test,6,19,1,Unsupervised learning,B,Which of the three ways of learning is like learning without a teacher? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Unsupervised learning is without a teacher the ANN is given a lot of examples and tries to figure out how data can be organized. Don’t need correct answers but not possible for everything. It contains a picture of unsupervised learning.
cb8520dc-664b-4dbb-acd9-2fe0b9ceb6f4,test,past,elementary school,u11,1,group 3,post test,5,18,1,Reinforcement learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
18e13c99-9d5e-40ba-8b95-f808e0c1645d,test,future,elementary school,u11,1,group 3,post test,10,9,1,It can make 180 degrees,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
a2ada91e-e264-4fc1-89a4-320b206275fd,test,future,elementary school,u11,1,group 3,post test,7,2,0,?,"Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
9ca24634-f907-49ad-a59c-ba48fe501d80,train,past,elementary school,u30,1,group 3,post test,3,8,0,Deduction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
4036d93c-fd87-46f9-921b-f470977fa90f,train,past,elementary school,u30,1,group 3,post test,4,4,0,Reinforcement learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Birth of AI. 1956 Workshop at Dartmouth College. John McCarthy. Marvin Lee Minsky. Claude Elwood Shannon. -Name 'Artificial Intelligence' for the new field. It contains three pictures of the three people mentioned in this slide.
bbc237f8-19b4-4f97-8105-d0823c943b8d,train,past,elementary school,u30,1,group 3,post test,1,9,1,False,B,Is this statement correct or wrong? 'Machines can know tomorrow's weather only by logic' <please select the best answer> A. True B. False,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
6c8b10e1-d60b-4f98-bd32-6c6a03d27261,train,future,elementary school,u30,1,group 3,post test,8,11,0,?,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
e961a591-5a1a-4f38-9679-c1574b353a88,train,future,elementary school,u30,1,group 3,post test,9,18,1,neutrons,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
b1599adf-d558-4071-a8d5-a43c9eac64c6,train,past,elementary school,u30,1,group 3,post test,2,15,1,True,A,Is this statement correct or wrong? 'A neuron learns by changing the connection weight to a synaptic weight' <please select the best answer> A. True B. False,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
07ca5e4c-f52a-440e-b6b3-0f41d035a29c,train,future,elementary school,u30,1,group 3,post test,6,19,1,Unsupervised learning,B,Which of the three ways of learning is like learning without a teacher? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Unsupervised learning is without a teacher the ANN is given a lot of examples and tries to figure out how data can be organized. Don’t need correct answers but not possible for everything. It contains a picture of unsupervised learning.
a6002bcc-f94e-42d0-b987-fe5244517a64,train,past,elementary school,u30,1,group 3,post test,5,18,0,Supervised learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
a0c88cce-a56e-413c-96c8-9df9fcfda1f1,train,future,elementary school,u30,1,group 3,post test,10,9,0,the other angles are 45 degrees,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
2c9d0bff-ef3d-414e-b952-0634abc4f0f9,train,future,elementary school,u30,1,group 3,post test,7,2,0,"achine learning, deep learning, and neural networks.","Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
68ccac7e-b3e6-451f-9905-691a235830f1,train,past,elementary school,u22,1,group 3,post test,3,8,1,Induction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
d3765424-a8d4-4273-858e-9e227f079dda,train,past,elementary school,u22,1,group 3,post test,4,4,1,Supervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Birth of AI. 1956 Workshop at Dartmouth College. John McCarthy. Marvin Lee Minsky. Claude Elwood Shannon. -Name 'Artificial Intelligence' for the new field. It contains three pictures of the three people mentioned in this slide.
df934b49-59b6-47cf-8e2a-4f0101dfdbd5,train,past,elementary school,u22,1,group 3,post test,1,9,0,True,B,Is this statement correct or wrong? 'Machines can know tomorrow's weather only by logic' <please select the best answer> A. True B. False,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
815561da-69c0-4e6a-8695-91fe2d3c749d,train,future,elementary school,u22,1,group 3,post test,8,11,0,1,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
09b1b94e-a364-44b8-8d3e-5db0ff98bb05,train,future,elementary school,u22,1,group 3,post test,9,18,1,neurons,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
f5930766-4cc1-40fc-9a27-1a897a7f63fe,train,past,elementary school,u22,1,group 3,post test,2,15,0,False,A,Is this statement correct or wrong? 'A neuron learns by changing the connection weight to a synaptic weight' <please select the best answer> A. True B. False,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
b054551b-794d-4252-8172-7e4f2016a02c,train,future,elementary school,u22,1,group 3,post test,6,19,1,Unsupervised learning,B,Which of the three ways of learning is like learning without a teacher? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Unsupervised learning is without a teacher the ANN is given a lot of examples and tries to figure out how data can be organized. Don’t need correct answers but not possible for everything. It contains a picture of unsupervised learning.
0bf100b2-fe16-444f-9e29-0bcb5592877a,train,past,elementary school,u22,1,group 3,post test,5,18,1,Reinforcement learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
270237d1-7bf2-48eb-9dc0-0399f8e9ec2a,train,future,elementary school,u22,1,group 3,post test,10,9,1,right triangle is 180 degrees,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
239945e4-736f-464e-bdbc-dfbedd456e45,train,future,elementary school,u22,1,group 3,post test,7,2,0,input processing and output,"Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
035adb39-06c8-41e7-9d82-0f384163aa90,train,past,elementary school,u38,1,group 3,post test,3,8,0,Deduction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
b0bde5a1-a906-4711-8f5e-2a95e0f059c0,train,past,elementary school,u38,1,group 3,post test,4,4,0,Unsupervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Birth of AI. 1956 Workshop at Dartmouth College. John McCarthy. Marvin Lee Minsky. Claude Elwood Shannon. -Name 'Artificial Intelligence' for the new field. It contains three pictures of the three people mentioned in this slide.
00d1478c-a35f-4d4d-8ec0-e15887006414,train,past,elementary school,u38,1,group 3,post test,1,9,1,False,B,Is this statement correct or wrong? 'Machines can know tomorrow's weather only by logic' <please select the best answer> A. True B. False,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
ee8e36fa-e229-4974-9f9d-4a8f158245ed,train,future,elementary school,u38,1,group 3,post test,8,11,1,1 out of 6,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
c58d6722-410c-4f05-9ac6-02e78c2aaa28,train,future,elementary school,u38,1,group 3,post test,9,18,0,?,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
c9e38f7e-704a-42cd-b04b-17b54619fa67,train,past,elementary school,u38,1,group 3,post test,2,15,1,True,A,Is this statement correct or wrong? 'A neuron learns by changing the connection weight to a synaptic weight' <please select the best answer> A. True B. False,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
4fca2d6c-08c4-4450-86d8-0c7f247f2034,train,future,elementary school,u38,1,group 3,post test,6,19,0,Reinforcement learning,B,Which of the three ways of learning is like learning without a teacher? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Unsupervised learning is without a teacher the ANN is given a lot of examples and tries to figure out how data can be organized. Don’t need correct answers but not possible for everything. It contains a picture of unsupervised learning.
b3d2e729-49d6-49e4-84d6-e0f824d808d2,train,past,elementary school,u38,1,group 3,post test,5,18,0,Supervised learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
3f1825c5-2649-4e43-9b6a-1135277a0e32,train,future,elementary school,u38,1,group 3,post test,10,9,1,It can make 180 degrees,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
fedda881-cc99-475c-a471-f95e58542b64,train,future,elementary school,u38,1,group 3,post test,7,2,0,?,"Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
0d58544e-346a-4366-af66-2217d71fee06,train,past,elementary school,u15,1,group 3,post test,3,8,1,Induction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
7f87fda1-9bc4-4b61-b14d-28b6d6b52c3a,train,past,elementary school,u15,1,group 3,post test,4,4,1,Supervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Birth of AI. 1956 Workshop at Dartmouth College. John McCarthy. Marvin Lee Minsky. Claude Elwood Shannon. -Name 'Artificial Intelligence' for the new field. It contains three pictures of the three people mentioned in this slide.
ed844b9b-fe94-4581-8be4-1de1f10583d4,train,past,elementary school,u15,1,group 3,post test,1,9,1,False,B,Is this statement correct or wrong? 'Machines can know tomorrow's weather only by logic' <please select the best answer> A. True B. False,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
1d16ca7b-815d-4c31-9554-1c9d459333d3,train,future,elementary school,u15,1,group 3,post test,8,11,1,1/6,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
319fb9e1-6c16-47d0-b11e-a44807d4ba88,train,future,elementary school,u15,1,group 3,post test,9,18,1,Neurons,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
3e8be643-814d-4cab-9ddf-665452e034cd,train,past,elementary school,u15,1,group 3,post test,2,15,1,True,A,Is this statement correct or wrong? 'A neuron learns by changing the connection weight to a synaptic weight' <please select the best answer> A. True B. False,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
9bb96b52-80a4-4808-83ed-0861bc4344d6,train,future,elementary school,u15,1,group 3,post test,6,19,1,Unsupervised learning,B,Which of the three ways of learning is like learning without a teacher? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Unsupervised learning is without a teacher the ANN is given a lot of examples and tries to figure out how data can be organized. Don’t need correct answers but not possible for everything. It contains a picture of unsupervised learning.
cc9d97a6-a9b4-4909-9341-3fb5d906d441,train,past,elementary school,u15,1,group 3,post test,5,18,1,Reinforcement learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
2294e106-a934-473a-a9f7-85ad15f19499,train,future,elementary school,u15,1,group 3,post test,10,9,1,I can conclude that the sum of all the angles of a right triangle is 180 degrees.,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of common sense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
2d5f76df-ab3e-4283-afad-96b80a8a681b,train,future,elementary school,u15,1,group 3,post test,7,2,1,"Logic, statistics, and artificial neurons?","Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
3ebe3f31-724a-4249-a684-6feecdee26b7,test,past,elementary school,u58,8,group 1,post test,3,7,1,C,C,Q-Table is the main aim of steps of Q-Learning. Q-table records the long rewards for? <please select the best answer> A. different actions B. different states C. different actions taken in each state,The steps of Q-Learning. Initialize Q table. Choose an action a. Perform action. Measure reward. Update Q. Go back to Choose an action a. At the end of the training: Good Q* table. Q-table is a table that records Q-values. Q-value: the maximum expectation of long-term rewards for different actions taken in each state. Value: the total reward that an agent can expect to collect from that state and onwards into the future.
8836cbe8-dd65-4f20-89f9-46cd7a8a00cb,test,past,elementary school,u58,8,group 1,post test,4,9,1,A,A,"If the value in the current state is only indicated by the current reward, which of these formulas should we use to calculate Q value? <please select the best answer> A. Q=r B. Q_new = Q_old + 0.1*(r-Q_old)","Q-learning details. A simple situation: The current reward is the only indicator of the value in the current situation. A picture of a cheese at cell (2,1) in a 3x6 maze. A table of with entries corresponding to action/state where the actions are going up/down/left/right with the entries corresponding to state (1,1) being -1,+100,N/A,-1 and N/A,-1,N/A,+100 for state (3,1)."
656f9d08-f83b-459b-bcdf-ed616e36f40f,test,past,elementary school,u58,8,group 1,post test,1,3,1,B,B,True or False: The “reward” in the V-Learning means the total reward that an agent can expect to collect from that state and onwards into the future. <please select the best answer> A. True   B. False,"Quick review: reinforcement learning and V-learning. A picture showing 3 types of machine learning: unsupervised, supervised, and reinforcement. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent. Reward: the instantaneous benefit of being in a specific state, Value: the total reward that an agent can expect to collect from that state and onwards into the future. V-learning learns the value for different situations, i.e. how good the situation is."
e2cf60c4-d5c7-4d2c-b809-be82192e8b5c,test,future,elementary school,u58,8,group 1,post test,8,18,0,B,C,Which kind of sensors bounce pulses of light off the car’s surroundings to measure distances? <please select the best answer> A. Radar sensors B. Video cameras C. Lidar sensors D. Ultrasonic sensors,How do autonumous cars work? Lidar (light detection and ranging) sensors bounce pulses of light off the car’s surroundings to measure distances. Ultrasonic sensors in the wheels detect curbs and other vehicles when parking. A picture of lidar. A picture of Ultrasonic sensors.
b66a1513-b685-47d3-8c76-f0a6482d6c25,test,future,elementary school,u58,8,group 1,post test,9,4,0,C,D,"An agent is at state (1,1), and the Q-table is as follows. Which of the actions should the agent take? Content of Q-table: The rewards of action going right/left/up/down at state (1,1) are 10,25,-10,30 respectively. The rewards of action going right/left/up/down at state (1,2) are 20,-10,15,25 respectively. The rewards of action going right/left/up/down at state (2,1) are 30,10,15,-10 respectively. The rewards of action going right/left/up/down at state (2,2) are 25,30,10,-10 respectively. <please select the best answer> A. going right B. going left C. going up D. going down","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
f763fdec-0b65-4d35-8451-ac1429919efb,test,past,elementary school,u58,8,group 1,post test,2,4,0,qwqdwef,Action,"Both V-learning and Q-learning determine how good the new state is , but Q-learning learns the evaluation specific to something in addition to the state. What is it? <please input your answer>","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
87b13777-1553-4bac-ba8a-e2719ed04099,test,future,elementary school,u58,8,group 1,post test,6,20,0,wd,The responsibility for crashes or something else that applies or some else,Can you name one issue or challenge that involves autonomous cars? <please input your answer>,Challenges with autonomous cars. Accident Liability: Who is liable for accidents caused by an autonomous car? Artificial vs. Emotional Intelligence: Human drivers rely on subtle cues and non-verbal communication to make split-second judgment calls and predict behaviors. A picture of a car crash.
ad1b5d96-db8f-4ae5-9732-192868523010,test,past,elementary school,u58,8,group 1,post test,5,15,0,e,"Of the Level 0-2, the human monitors the driving environment, of the level 3-5, the autonomous cars can monitors the driving environment.",The Society of Automotive Engineers (SAE) currently defines 6 levels of driving automation. Please describe the main difference between Level 0-2 and Level 3-5? <please input your answer>,6 levels of driving automation. The Society of Automotive Engineers (SAE) currently defines 6 levels of drving automation ranging from Level 0 (fully manual) to Level 5 (fully autonomous). Level 0-2: The human monitors the driving environment. Level 3-5: The automated system monitors the driving environment. A picture of the 6 levels of driving automation.
9658238e-6b66-4eae-88e2-a750a5681aff,test,future,elementary school,u58,8,group 1,post test,10,11,1,B,B,"About how to choose action in the initial state, which of the approaches aim to collect the most reward you already know about? <please select the best answer> A. Exploration   B. Exploitation",A missing point: how to choose action? Exploration: Explore new area in the environment. Exploitation: Collect the most reward you already know about. Two animations showing two different total rewards a agent could get by choosing different actions.
b449822d-d552-4e10-9ba6-a1f6d48a30a8,test,future,elementary school,u58,8,group 1,post test,7,16,0,d,"Environments: Many components. Traffic lights, pedestrian Actions: Brake, accelerate, turn left",Autonomous cars are under the framework. Please list some kinds of “environments” and “actions” in the situation of autonomous cars? <please input your answer>,"Under the framework of reinforcement learning. Agent: The car or the computer inside the car. Environment: Many components. Traffic lights, pedestrian, other cars, road signs... State: Current location, green/red light, position of pedstrain, speed limit... Action: Brake, accelerate, turn left... Reward: No accident. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent where the agent is the car and the environment is the world."
dc5f05bd-877a-4de4-9ddd-740e1f73a9e5,test,past,elementary school,u19,8,group 1,post test,3,7,1,C,C,Q-Table is the main aim of steps of Q-Learning. Q-table records the long rewards for? <please select the best answer> A. different actions B. different states C. different actions taken in each state,The steps of Q-Learning. Initialize Q table. Choose an action a. Perform action. Measure reward. Update Q. Go back to Choose an action a. At the end of the training: Good Q* table. Q-table is a table that records Q-values. Q-value: the maximum expectation of long-term rewards for different actions taken in each state. Value: the total reward that an agent can expect to collect from that state and onwards into the future.
35ad76f3-2cc0-4877-b4eb-8819f2069cfa,test,past,elementary school,u19,8,group 1,post test,4,9,1,A,A,"If the value in the current state is only indicated by the current reward, which of these formulas should we use to calculate Q value? <please select the best answer> A. Q=r B. Q_new = Q_old + 0.1*(r-Q_old)","Q-learning details. A simple situation: The current reward is the only indicator of the value in the current situation. A picture of a cheese at cell (2,1) in a 3x6 maze. A table of with entries corresponding to action/state where the actions are going up/down/left/right with the entries corresponding to state (1,1) being -1,+100,N/A,-1 and N/A,-1,N/A,+100 for state (3,1)."
15f14ff0-5ea8-44b6-95a1-e07997372f45,test,past,elementary school,u19,8,group 1,post test,1,3,1,B,B,True or False: The “reward” in the V-Learning means the total reward that an agent can expect to collect from that state and onwards into the future. <please select the best answer> A. True   B. False,"Quick review: reinforcement learning and V-learning. A picture showing 3 types of machine learning: unsupervised, supervised, and reinforcement. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent. Reward: the instantaneous benefit of being in a specific state, Value: the total reward that an agent can expect to collect from that state and onwards into the future. V-learning learns the value for different situations, i.e. how good the situation is."
6fc2d85d-75e3-4063-8d7e-e2b6920d274a,test,future,elementary school,u19,8,group 1,post test,8,18,1,C,C,Which kind of sensors bounce pulses of light off the car’s surroundings to measure distances? <please select the best answer> A. Radar sensors B. Video cameras C. Lidar sensors D. Ultrasonic sensors,How do autonumous cars work? Lidar (light detection and ranging) sensors bounce pulses of light off the car’s surroundings to measure distances. Ultrasonic sensors in the wheels detect curbs and other vehicles when parking. A picture of lidar. A picture of Ultrasonic sensors.
4ea0e1df-25f8-455c-bf9f-49b4d353e6b9,test,future,elementary school,u19,8,group 1,post test,9,4,1,D,D,"An agent is at state (1,1), and the Q-table is as follows. Which of the actions should the agent take? Content of Q-table: The rewards of action going right/left/up/down at state (1,1) are 10,25,-10,30 respectively. The rewards of action going right/left/up/down at state (1,2) are 20,-10,15,25 respectively. The rewards of action going right/left/up/down at state (2,1) are 30,10,15,-10 respectively. The rewards of action going right/left/up/down at state (2,2) are 25,30,10,-10 respectively. <please select the best answer> A. going right B. going left C. going up D. going down","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
079a2511-a5d1-4379-9ad4-6301b3687b94,test,past,elementary school,u19,8,group 1,post test,2,4,0,atnoumous car,Action,"Both V-learning and Q-learning determine how good the new state is , but Q-learning learns the evaluation specific to something in addition to the state. What is it? <please input your answer>","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
f72dccb5-0e17-49df-b2bb-2e0e0a5edc3f,test,future,elementary school,u19,8,group 1,post test,6,20,0,d,The responsibility for crashes or something else that applies or some else,Can you name one issue or challenge that involves autonomous cars? <please input your answer>,Challenges with autonomous cars. Accident Liability: Who is liable for accidents caused by an autonomous car? Artificial vs. Emotional Intelligence: Human drivers rely on subtle cues and non-verbal communication to make split-second judgment calls and predict behaviors. A picture of a car crash.
071693db-eda4-4d28-a6ae-81bc27242c9e,test,past,elementary school,u19,8,group 1,post test,5,15,0,-,"Of the Level 0-2, the human monitors the driving environment, of the level 3-5, the autonomous cars can monitors the driving environment.",The Society of Automotive Engineers (SAE) currently defines 6 levels of driving automation. Please describe the main difference between Level 0-2 and Level 3-5? <please input your answer>,6 levels of driving automation. The Society of Automotive Engineers (SAE) currently defines 6 levels of drving automation ranging from Level 0 (fully manual) to Level 5 (fully autonomous). Level 0-2: The human monitors the driving environment. Level 3-5: The automated system monitors the driving environment. A picture of the 6 levels of driving automation.
2e8a59e2-3d7e-41d6-b4b7-5338471ecfd3,test,future,elementary school,u19,8,group 1,post test,10,11,1,B,B,"About how to choose action in the initial state, which of the approaches aim to collect the most reward you already know about? <please select the best answer> A. Exploration   B. Exploitation",A missing point: how to choose action? Exploration: Explore new area in the environment. Exploitation: Collect the most reward you already know about. Two animations showing two different total rewards a agent could get by choosing different actions.
5cccaff9-627d-4874-b20a-1cab151e0a34,test,future,elementary school,u19,8,group 1,post test,7,16,0,d,"Environments: Many components. Traffic lights, pedestrian Actions: Brake, accelerate, turn left",Autonomous cars are under the framework. Please list some kinds of “environments” and “actions” in the situation of autonomous cars? <please input your answer>,"Under the framework of reinforcement learning. Agent: The car or the computer inside the car. Environment: Many components. Traffic lights, pedestrian, other cars, road signs... State: Current location, green/red light, position of pedstrain, speed limit... Action: Brake, accelerate, turn left... Reward: No accident. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent where the agent is the car and the environment is the world."
835c36f5-2aa4-4833-b809-2f2c73864c6e,test,past,elementary school,u5,8,group 2,post test,3,7,1,C,C,Q-Table is the main aim of steps of Q-Learning. Q-table records the long rewards for? <please select the best answer> A. different actions B. different states C. different actions taken in each state,The steps of Q-Learning. Initialize Q table. Choose an action a. Perform action. Measure reward. Update Q. Go back to Choose an action a. At the end of the training: Good Q* table. Q-table is a table that records Q-values. Q-value: the maximum expectation of long-term rewards for different actions taken in each state. Value: the total reward that an agent can expect to collect from that state and onwards into the future.
751c5e88-7cb4-48cc-9aa2-d380e7b7a938,test,past,elementary school,u5,8,group 2,post test,4,9,1,A,A,"If the value in the current state is only indicated by the current reward, which of these formulas should we use to calculate Q value? <please select the best answer> A. Q=r B. Q_new = Q_old + 0.1*(r-Q_old)","Q-learning details. A simple situation: The current reward is the only indicator of the value in the current situation. A picture of a cheese at cell (2,1) in a 3x6 maze. A table of with entries corresponding to action/state where the actions are going up/down/left/right with the entries corresponding to state (1,1) being -1,+100,N/A,-1 and N/A,-1,N/A,+100 for state (3,1)."
cc8d7529-bdeb-4e21-b2e1-988804cb8357,test,past,elementary school,u5,8,group 2,post test,1,3,0,A,B,True or False: The “reward” in the V-Learning means the total reward that an agent can expect to collect from that state and onwards into the future. <please select the best answer> A. True   B. False,"Quick review: reinforcement learning and V-learning. A picture showing 3 types of machine learning: unsupervised, supervised, and reinforcement. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent. Reward: the instantaneous benefit of being in a specific state, Value: the total reward that an agent can expect to collect from that state and onwards into the future. V-learning learns the value for different situations, i.e. how good the situation is."
604124f3-6bdf-4516-a213-d5302d76c261,test,future,elementary school,u5,8,group 2,post test,8,18,1,C,C,Which kind of sensors bounce pulses of light off the car’s surroundings to measure distances? <please select the best answer> A. Radar sensors B. Video cameras C. Lidar sensors D. Ultrasonic sensors,How do autonumous cars work? Lidar (light detection and ranging) sensors bounce pulses of light off the car’s surroundings to measure distances. Ultrasonic sensors in the wheels detect curbs and other vehicles when parking. A picture of lidar. A picture of Ultrasonic sensors.
f8099c51-e5a5-4b2d-8434-09372d76c1d3,test,future,elementary school,u5,8,group 2,post test,9,4,0,C,D,"An agent is at state (1,1), and the Q-table is as follows. Which of the actions should the agent take? Content of Q-table: The rewards of action going right/left/up/down at state (1,1) are 10,25,-10,30 respectively. The rewards of action going right/left/up/down at state (1,2) are 20,-10,15,25 respectively. The rewards of action going right/left/up/down at state (2,1) are 30,10,15,-10 respectively. The rewards of action going right/left/up/down at state (2,2) are 25,30,10,-10 respectively. <please select the best answer> A. going right B. going left C. going up D. going down","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
a22c38ea-91ca-4bab-b3d7-faf61291e42f,test,past,elementary school,u5,8,group 2,post test,2,4,0,  ,Action,"Both V-learning and Q-learning determine how good the new state is , but Q-learning learns the evaluation specific to something in addition to the state. What is it? <please input your answer>","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
eacf3b61-185e-4dfc-9ee1-c4f9d54bdc53,test,future,elementary school,u5,8,group 2,post test,6,20,1,communicating with other drivers,The responsibility for crashes or something else that applies or some else,Can you name one issue or challenge that involves autonomous cars? <please input your answer>,Challenges with autonomous cars. Accident Liability: Who is liable for accidents caused by an autonomous car? Artificial vs. Emotional Intelligence: Human drivers rely on subtle cues and non-verbal communication to make split-second judgment calls and predict behaviors. A picture of a car crash.
1820973d-64ea-45d5-b85d-0fdec2262706,test,past,elementary school,u5,8,group 2,post test,5,15,1,0-2 requires humans to drive but 3-5 doesnt ,"Of the Level 0-2, the human monitors the driving environment, of the level 3-5, the autonomous cars can monitors the driving environment.",The Society of Automotive Engineers (SAE) currently defines 6 levels of driving automation. Please describe the main difference between Level 0-2 and Level 3-5? <please input your answer>,6 levels of driving automation. The Society of Automotive Engineers (SAE) currently defines 6 levels of drving automation ranging from Level 0 (fully manual) to Level 5 (fully autonomous). Level 0-2: The human monitors the driving environment. Level 3-5: The automated system monitors the driving environment. A picture of the 6 levels of driving automation.
29517d9d-08f5-4ada-9d6b-b5e3791a96a9,test,future,elementary school,u5,8,group 2,post test,10,11,1,B,B,"About how to choose action in the initial state, which of the approaches aim to collect the most reward you already know about? <please select the best answer> A. Exploration   B. Exploitation",A missing point: how to choose action? Exploration: Explore new area in the environment. Exploitation: Collect the most reward you already know about. Two animations showing two different total rewards a agent could get by choosing different actions.
e4485fd3-fec3-4c35-ad63-9e9a2d49f35d,test,future,elementary school,u5,8,group 2,post test,7,16,1,"construction, other cars, trees. accelerate go right go left","Environments: Many components. Traffic lights, pedestrian Actions: Brake, accelerate, turn left",Autonomous cars are under the framework. Please list some kinds of “environments” and “actions” in the situation of autonomous cars? <please input your answer>,"Under the framework of reinforcement learning. Agent: The car or the computer inside the car. Environment: Many components. Traffic lights, pedestrian, other cars, road signs... State: Current location, green/red light, position of pedstrain, speed limit... Action: Brake, accelerate, turn left... Reward: No accident. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent where the agent is the car and the environment is the world."
abaa46da-f866-450d-8ba3-c4886effe943,train,past,elementary school,u7,8,group 2,post test,3,7,1,C,C,Q-Table is the main aim of steps of Q-Learning. Q-table records the long rewards for? <please select the best answer> A. different actions B. different states C. different actions taken in each state,The steps of Q-Learning. Initialize Q table. Choose an action a. Perform action. Measure reward. Update Q. Go back to Choose an action a. At the end of the training: Good Q* table. Q-table is a table that records Q-values. Q-value: the maximum expectation of long-term rewards for different actions taken in each state. Value: the total reward that an agent can expect to collect from that state and onwards into the future.
428cce27-8623-40ee-94aa-ba688eae94e9,train,past,elementary school,u7,8,group 2,post test,4,9,1,A,A,"If the value in the current state is only indicated by the current reward, which of these formulas should we use to calculate Q value? <please select the best answer> A. Q=r B. Q_new = Q_old + 0.1*(r-Q_old)","Q-learning details. A simple situation: The current reward is the only indicator of the value in the current situation. A picture of a cheese at cell (2,1) in a 3x6 maze. A table of with entries corresponding to action/state where the actions are going up/down/left/right with the entries corresponding to state (1,1) being -1,+100,N/A,-1 and N/A,-1,N/A,+100 for state (3,1)."
4250f0ea-e4de-49de-b9e7-89367aa73799,train,past,elementary school,u7,8,group 2,post test,1,3,1,B,B,True or False: The “reward” in the V-Learning means the total reward that an agent can expect to collect from that state and onwards into the future. <please select the best answer> A. True   B. False,"Quick review: reinforcement learning and V-learning. A picture showing 3 types of machine learning: unsupervised, supervised, and reinforcement. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent. Reward: the instantaneous benefit of being in a specific state, Value: the total reward that an agent can expect to collect from that state and onwards into the future. V-learning learns the value for different situations, i.e. how good the situation is."
53fdbedc-9cde-4f98-b265-1af629b2a563,train,future,elementary school,u7,8,group 2,post test,8,18,1,C,C,Which kind of sensors bounce pulses of light off the car’s surroundings to measure distances? <please select the best answer> A. Radar sensors B. Video cameras C. Lidar sensors D. Ultrasonic sensors,How do autonumous cars work? Lidar (light detection and ranging) sensors bounce pulses of light off the car’s surroundings to measure distances. Ultrasonic sensors in the wheels detect curbs and other vehicles when parking. A picture of lidar. A picture of Ultrasonic sensors.
ca54f93a-e71a-40eb-bebb-234a1f2fdc20,train,future,elementary school,u7,8,group 2,post test,9,4,1,D,D,"An agent is at state (1,1), and the Q-table is as follows. Which of the actions should the agent take? Content of Q-table: The rewards of action going right/left/up/down at state (1,1) are 10,25,-10,30 respectively. The rewards of action going right/left/up/down at state (1,2) are 20,-10,15,25 respectively. The rewards of action going right/left/up/down at state (2,1) are 30,10,15,-10 respectively. The rewards of action going right/left/up/down at state (2,2) are 25,30,10,-10 respectively. <please select the best answer> A. going right B. going left C. going up D. going down","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
ced40b00-efde-451a-a5ee-e32e4dd1cfbd,train,past,elementary school,u7,8,group 2,post test,2,4,0,he he,Action,"Both V-learning and Q-learning determine how good the new state is , but Q-learning learns the evaluation specific to something in addition to the state. What is it? <please input your answer>","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
af4e98f0-1364-4ca7-a206-3c91bd9483b9,train,future,elementary school,u7,8,group 2,post test,6,20,0,mental freeze,The responsibility for crashes or something else that applies or some else,Can you name one issue or challenge that involves autonomous cars? <please input your answer>,Challenges with autonomous cars. Accident Liability: Who is liable for accidents caused by an autonomous car? Artificial vs. Emotional Intelligence: Human drivers rely on subtle cues and non-verbal communication to make split-second judgment calls and predict behaviors. A picture of a car crash.
d33ebe6b-b354-47e9-987a-70d0f33315a4,train,past,elementary school,u7,8,group 2,post test,5,15,0,fa,"Of the Level 0-2, the human monitors the driving environment, of the level 3-5, the autonomous cars can monitors the driving environment.",The Society of Automotive Engineers (SAE) currently defines 6 levels of driving automation. Please describe the main difference between Level 0-2 and Level 3-5? <please input your answer>,6 levels of driving automation. The Society of Automotive Engineers (SAE) currently defines 6 levels of drving automation ranging from Level 0 (fully manual) to Level 5 (fully autonomous). Level 0-2: The human monitors the driving environment. Level 3-5: The automated system monitors the driving environment. A picture of the 6 levels of driving automation.
e2bc7d4a-2551-43c8-8a5c-64596db97e23,train,future,elementary school,u7,8,group 2,post test,10,11,1,B,B,"About how to choose action in the initial state, which of the approaches aim to collect the most reward you already know about? <please select the best answer> A. Exploration   B. Exploitation",A missing point: how to choose action? Exploration: Explore new area in the environment. Exploitation: Collect the most reward you already know about. Two animations showing two different total rewards a agent could get by choosing different actions.
562dcd37-896b-4c85-a3ab-9d66ecd15146,train,future,elementary school,u7,8,group 2,post test,7,16,0,entions,"Environments: Many components. Traffic lights, pedestrian Actions: Brake, accelerate, turn left",Autonomous cars are under the framework. Please list some kinds of “environments” and “actions” in the situation of autonomous cars? <please input your answer>,"Under the framework of reinforcement learning. Agent: The car or the computer inside the car. Environment: Many components. Traffic lights, pedestrian, other cars, road signs... State: Current location, green/red light, position of pedstrain, speed limit... Action: Brake, accelerate, turn left... Reward: No accident. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent where the agent is the car and the environment is the world."
695dd8dc-245f-4693-982c-115aac758bfe,train,past,elementary school,u44,8,group 2,post test,3,7,1,C,C,Q-Table is the main aim of steps of Q-Learning. Q-table records the long rewards for? <please select the best answer> A. different actions B. different states C. different actions taken in each state,The steps of Q-Learning. Initialize Q table. Choose an action a. Perform action. Measure reward. Update Q. Go back to Choose an action a. At the end of the training: Good Q* table. Q-table is a table that records Q-values. Q-value: the maximum expectation of long-term rewards for different actions taken in each state. Value: the total reward that an agent can expect to collect from that state and onwards into the future.
91c340c4-a97f-4d56-a1ac-bebbbb62fe72,train,past,elementary school,u44,8,group 2,post test,4,9,1,A,A,"If the value in the current state is only indicated by the current reward, which of these formulas should we use to calculate Q value? <please select the best answer> A. Q=r B. Q_new = Q_old + 0.1*(r-Q_old)","Q-learning details. A simple situation: The current reward is the only indicator of the value in the current situation. A picture of a cheese at cell (2,1) in a 3x6 maze. A table of with entries corresponding to action/state where the actions are going up/down/left/right with the entries corresponding to state (1,1) being -1,+100,N/A,-1 and N/A,-1,N/A,+100 for state (3,1)."
d5c106e6-963d-420e-84db-2702e2fc7882,train,past,elementary school,u44,8,group 2,post test,1,3,1,B,B,True or False: The “reward” in the V-Learning means the total reward that an agent can expect to collect from that state and onwards into the future. <please select the best answer> A. True   B. False,"Quick review: reinforcement learning and V-learning. A picture showing 3 types of machine learning: unsupervised, supervised, and reinforcement. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent. Reward: the instantaneous benefit of being in a specific state, Value: the total reward that an agent can expect to collect from that state and onwards into the future. V-learning learns the value for different situations, i.e. how good the situation is."
daaf66b1-1e28-4307-ad7c-8e0f502c004b,train,future,elementary school,u44,8,group 2,post test,8,18,1,C,C,Which kind of sensors bounce pulses of light off the car’s surroundings to measure distances? <please select the best answer> A. Radar sensors B. Video cameras C. Lidar sensors D. Ultrasonic sensors,How do autonumous cars work? Lidar (light detection and ranging) sensors bounce pulses of light off the car’s surroundings to measure distances. Ultrasonic sensors in the wheels detect curbs and other vehicles when parking. A picture of lidar. A picture of Ultrasonic sensors.
24a997a7-780f-424d-a1f6-2741570b848c,train,future,elementary school,u44,8,group 2,post test,9,4,1,D,D,"An agent is at state (1,1), and the Q-table is as follows. Which of the actions should the agent take? Content of Q-table: The rewards of action going right/left/up/down at state (1,1) are 10,25,-10,30 respectively. The rewards of action going right/left/up/down at state (1,2) are 20,-10,15,25 respectively. The rewards of action going right/left/up/down at state (2,1) are 30,10,15,-10 respectively. The rewards of action going right/left/up/down at state (2,2) are 25,30,10,-10 respectively. <please select the best answer> A. going right B. going left C. going up D. going down","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
0e108bc2-3e06-4f39-ad30-3598774cdfe7,train,past,elementary school,u44,8,group 2,post test,2,4,1,how good it is to perform an action in a given sate,Action,"Both V-learning and Q-learning determine how good the new state is , but Q-learning learns the evaluation specific to something in addition to the state. What is it? <please input your answer>","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
013b1bc1-99d6-4b12-803e-fc013c8c667b,train,future,elementary school,u44,8,group 2,post test,6,20,1,accident liability,The responsibility for crashes or something else that applies or some else,Can you name one issue or challenge that involves autonomous cars? <please input your answer>,Challenges with autonomous cars. Accident Liability: Who is liable for accidents caused by an autonomous car? Artificial vs. Emotional Intelligence: Human drivers rely on subtle cues and non-verbal communication to make split-second judgment calls and predict behaviors. A picture of a car crash.
84cf73ec-1681-4ba1-b28e-9a654544bd7e,train,past,elementary school,u44,8,group 2,post test,5,15,1,the human monitors the driving environment for 0-2,"Of the Level 0-2, the human monitors the driving environment, of the level 3-5, the autonomous cars can monitors the driving environment.",The Society of Automotive Engineers (SAE) currently defines 6 levels of driving automation. Please describe the main difference between Level 0-2 and Level 3-5? <please input your answer>,6 levels of driving automation. The Society of Automotive Engineers (SAE) currently defines 6 levels of drving automation ranging from Level 0 (fully manual) to Level 5 (fully autonomous). Level 0-2: The human monitors the driving environment. Level 3-5: The automated system monitors the driving environment. A picture of the 6 levels of driving automation.
eb9d71cd-5390-4564-a3ff-d5a366d11750,train,future,elementary school,u44,8,group 2,post test,10,11,1,B,B,"About how to choose action in the initial state, which of the approaches aim to collect the most reward you already know about? <please select the best answer> A. Exploration   B. Exploitation",A missing point: how to choose action? Exploration: Explore new area in the environment. Exploitation: Collect the most reward you already know about. Two animations showing two different total rewards a agent could get by choosing different actions.
fb16ac16-d7b4-401d-855e-37b24fa5de61,train,future,elementary school,u44,8,group 2,post test,7,16,1,"other cars, road signs, left, right","Environments: Many components. Traffic lights, pedestrian Actions: Brake, accelerate, turn left",Autonomous cars are under the framework. Please list some kinds of “environments” and “actions” in the situation of autonomous cars? <please input your answer>,"Under the framework of reinforcement learning. Agent: The car or the computer inside the car. Environment: Many components. Traffic lights, pedestrian, other cars, road signs... State: Current location, green/red light, position of pedstrain, speed limit... Action: Brake, accelerate, turn left... Reward: No accident. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent where the agent is the car and the environment is the world."
b3403217-ace0-4d6a-b827-5410ffd430ef,train,past,elementary school,u26,8,group 3,post test,3,7,1,C,C,Q-Table is the main aim of steps of Q-Learning. Q-table records the long rewards for? <please select the best answer> A. different actions B. different states C. different actions taken in each state,The steps of Q-Learning. Initialize Q table. Choose an action a. Perform action. Measure reward. Update Q. Go back to Choose an action a. At the end of the training: Good Q* table. Q-table is a table that records Q-values. Q-value: the maximum expectation of long-term rewards for different actions taken in each state. Value: the total reward that an agent can expect to collect from that state and onwards into the future.
ac9f062e-6900-42f5-b777-fba411722be8,train,past,elementary school,u26,8,group 3,post test,4,9,1,A,A,"If the value in the current state is only indicated by the current reward, which of these formulas should we use to calculate Q value? <please select the best answer> A. Q=r B. Q_new = Q_old + 0.1*(r-Q_old)","Q-learning details. A simple situation: The current reward is the only indicator of the value in the current situation. A picture of a cheese at cell (2,1) in a 3x6 maze. A table of with entries corresponding to action/state where the actions are going up/down/left/right with the entries corresponding to state (1,1) being -1,+100,N/A,-1 and N/A,-1,N/A,+100 for state (3,1)."
b85bdcb2-5e94-4cd1-824b-00f02cbe0b63,train,past,elementary school,u26,8,group 3,post test,1,3,0,A,B,True or False: The “reward” in the V-Learning means the total reward that an agent can expect to collect from that state and onwards into the future. <please select the best answer> A. True   B. False,"Quick review: reinforcement learning and V-learning. A picture showing 3 types of machine learning: unsupervised, supervised, and reinforcement. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent. Reward: the instantaneous benefit of being in a specific state, Value: the total reward that an agent can expect to collect from that state and onwards into the future. V-learning learns the value for different situations, i.e. how good the situation is."
6ca0e07e-54c6-4dcd-b9ed-b49838c721b7,train,future,elementary school,u26,8,group 3,post test,8,18,0,D,C,Which kind of sensors bounce pulses of light off the car’s surroundings to measure distances? <please select the best answer> A. Radar sensors B. Video cameras C. Lidar sensors D. Ultrasonic sensors,How do autonumous cars work? Lidar (light detection and ranging) sensors bounce pulses of light off the car’s surroundings to measure distances. Ultrasonic sensors in the wheels detect curbs and other vehicles when parking. A picture of lidar. A picture of Ultrasonic sensors.
f2055c69-15b7-48a0-8bd1-ce05493fb6aa,train,future,elementary school,u26,8,group 3,post test,9,4,0,C,D,"An agent is at state (1,1), and the Q-table is as follows. Which of the actions should the agent take? Content of Q-table: The rewards of action going right/left/up/down at state (1,1) are 10,25,-10,30 respectively. The rewards of action going right/left/up/down at state (1,2) are 20,-10,15,25 respectively. The rewards of action going right/left/up/down at state (2,1) are 30,10,15,-10 respectively. The rewards of action going right/left/up/down at state (2,2) are 25,30,10,-10 respectively. <please select the best answer> A. going right B. going left C. going up D. going down","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
2a10df6b-ebb0-472a-a318-2b105ffb0dd6,train,past,elementary school,u26,8,group 3,post test,2,4,0,?,Action,"Both V-learning and Q-learning determine how good the new state is , but Q-learning learns the evaluation specific to something in addition to the state. What is it? <please input your answer>","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
850b1701-2ea4-4eb6-99a0-59bca85a96dc,train,future,elementary school,u26,8,group 3,post test,6,20,0,?,The responsibility for crashes or something else that applies or some else,Can you name one issue or challenge that involves autonomous cars? <please input your answer>,Challenges with autonomous cars. Accident Liability: Who is liable for accidents caused by an autonomous car? Artificial vs. Emotional Intelligence: Human drivers rely on subtle cues and non-verbal communication to make split-second judgment calls and predict behaviors. A picture of a car crash.
85bf1534-2113-402f-8454-f6148c55f2a0,train,past,elementary school,u26,8,group 3,post test,5,15,0,?,"Of the Level 0-2, the human monitors the driving environment, of the level 3-5, the autonomous cars can monitors the driving environment.",The Society of Automotive Engineers (SAE) currently defines 6 levels of driving automation. Please describe the main difference between Level 0-2 and Level 3-5? <please input your answer>,6 levels of driving automation. The Society of Automotive Engineers (SAE) currently defines 6 levels of drving automation ranging from Level 0 (fully manual) to Level 5 (fully autonomous). Level 0-2: The human monitors the driving environment. Level 3-5: The automated system monitors the driving environment. A picture of the 6 levels of driving automation.
5fd96274-553d-494f-adb2-0ebab6944e9f,train,future,elementary school,u26,8,group 3,post test,10,11,1,B,B,"About how to choose action in the initial state, which of the approaches aim to collect the most reward you already know about? <please select the best answer> A. Exploration   B. Exploitation",A missing point: how to choose action? Exploration: Explore new area in the environment. Exploitation: Collect the most reward you already know about. Two animations showing two different total rewards a agent could get by choosing different actions.
5d624737-c306-499c-ad2c-33c2b72e481f,train,future,elementary school,u26,8,group 3,post test,7,16,0,?,"Environments: Many components. Traffic lights, pedestrian Actions: Brake, accelerate, turn left",Autonomous cars are under the framework. Please list some kinds of “environments” and “actions” in the situation of autonomous cars? <please input your answer>,"Under the framework of reinforcement learning. Agent: The car or the computer inside the car. Environment: Many components. Traffic lights, pedestrian, other cars, road signs... State: Current location, green/red light, position of pedstrain, speed limit... Action: Brake, accelerate, turn left... Reward: No accident. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent where the agent is the car and the environment is the world."
7ad1d778-8712-47b3-9042-6f097dbe9d67,train,past,elementary school,u25,8,group 3,post test,3,7,1,C,C,Q-Table is the main aim of steps of Q-Learning. Q-table records the long rewards for? <please select the best answer> A. different actions B. different states C. different actions taken in each state,The steps of Q-Learning. Initialize Q table. Choose an action a. Perform action. Measure reward. Update Q. Go back to Choose an action a. At the end of the training: Good Q* table. Q-table is a table that records Q-values. Q-value: the maximum expectation of long-term rewards for different actions taken in each state. Value: the total reward that an agent can expect to collect from that state and onwards into the future.
c29ffb5d-d43c-41c4-8baf-bcf655a149a4,train,past,elementary school,u25,8,group 3,post test,4,9,0,B,A,"If the value in the current state is only indicated by the current reward, which of these formulas should we use to calculate Q value? <please select the best answer> A. Q=r B. Q_new = Q_old + 0.1*(r-Q_old)","Q-learning details. A simple situation: The current reward is the only indicator of the value in the current situation. A picture of a cheese at cell (2,1) in a 3x6 maze. A table of with entries corresponding to action/state where the actions are going up/down/left/right with the entries corresponding to state (1,1) being -1,+100,N/A,-1 and N/A,-1,N/A,+100 for state (3,1)."
2a669481-1851-4f1f-a700-3dfcfe980ace,train,past,elementary school,u25,8,group 3,post test,1,3,1,B,B,True or False: The “reward” in the V-Learning means the total reward that an agent can expect to collect from that state and onwards into the future. <please select the best answer> A. True   B. False,"Quick review: reinforcement learning and V-learning. A picture showing 3 types of machine learning: unsupervised, supervised, and reinforcement. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent. Reward: the instantaneous benefit of being in a specific state, Value: the total reward that an agent can expect to collect from that state and onwards into the future. V-learning learns the value for different situations, i.e. how good the situation is."
9ddfc38c-09c4-4248-a28c-f5993312b133,train,future,elementary school,u25,8,group 3,post test,8,18,1,C,C,Which kind of sensors bounce pulses of light off the car’s surroundings to measure distances? <please select the best answer> A. Radar sensors B. Video cameras C. Lidar sensors D. Ultrasonic sensors,How do autonumous cars work? Lidar (light detection and ranging) sensors bounce pulses of light off the car’s surroundings to measure distances. Ultrasonic sensors in the wheels detect curbs and other vehicles when parking. A picture of lidar. A picture of Ultrasonic sensors.
e0c5f937-a4f5-489f-99e2-5ed465bff51e,train,future,elementary school,u25,8,group 3,post test,9,4,1,D,D,"An agent is at state (1,1), and the Q-table is as follows. Which of the actions should the agent take? Content of Q-table: The rewards of action going right/left/up/down at state (1,1) are 10,25,-10,30 respectively. The rewards of action going right/left/up/down at state (1,2) are 20,-10,15,25 respectively. The rewards of action going right/left/up/down at state (2,1) are 30,10,15,-10 respectively. The rewards of action going right/left/up/down at state (2,2) are 25,30,10,-10 respectively. <please select the best answer> A. going right B. going left C. going up D. going down","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
a30a1e9d-e1a4-4089-92d1-e4dd6bc8b6d2,train,past,elementary school,u25,8,group 3,post test,2,4,0,?,Action,"Both V-learning and Q-learning determine how good the new state is , but Q-learning learns the evaluation specific to something in addition to the state. What is it? <please input your answer>","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
3fae7aa1-1efe-43c9-8f2d-9bf6a32ab466,train,future,elementary school,u25,8,group 3,post test,6,20,1,Non human like steering,The responsibility for crashes or something else that applies or some else,Can you name one issue or challenge that involves autonomous cars? <please input your answer>,Challenges with autonomous cars. Accident Liability: Who is liable for accidents caused by an autonomous car? Artificial vs. Emotional Intelligence: Human drivers rely on subtle cues and non-verbal communication to make split-second judgment calls and predict behaviors. A picture of a car crash.
87559846-e471-4c01-846d-abfd2cd250ed,train,past,elementary school,u25,8,group 3,post test,5,15,0,?,"Of the Level 0-2, the human monitors the driving environment, of the level 3-5, the autonomous cars can monitors the driving environment.",The Society of Automotive Engineers (SAE) currently defines 6 levels of driving automation. Please describe the main difference between Level 0-2 and Level 3-5? <please input your answer>,6 levels of driving automation. The Society of Automotive Engineers (SAE) currently defines 6 levels of drving automation ranging from Level 0 (fully manual) to Level 5 (fully autonomous). Level 0-2: The human monitors the driving environment. Level 3-5: The automated system monitors the driving environment. A picture of the 6 levels of driving automation.
abf30348-f90a-4d01-ab1e-aadffc3923f1,train,future,elementary school,u25,8,group 3,post test,10,11,1,B,B,"About how to choose action in the initial state, which of the approaches aim to collect the most reward you already know about? <please select the best answer> A. Exploration   B. Exploitation",A missing point: how to choose action? Exploration: Explore new area in the environment. Exploitation: Collect the most reward you already know about. Two animations showing two different total rewards a agent could get by choosing different actions.
824a4635-1979-4a80-ab1a-2af2aea0c131,train,future,elementary school,u25,8,group 3,post test,7,16,0,?,"Environments: Many components. Traffic lights, pedestrian Actions: Brake, accelerate, turn left",Autonomous cars are under the framework. Please list some kinds of “environments” and “actions” in the situation of autonomous cars? <please input your answer>,"Under the framework of reinforcement learning. Agent: The car or the computer inside the car. Environment: Many components. Traffic lights, pedestrian, other cars, road signs... State: Current location, green/red light, position of pedstrain, speed limit... Action: Brake, accelerate, turn left... Reward: No accident. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent where the agent is the car and the environment is the world."
67b5df6f-5943-4607-a75b-083ec3d6a7c7,train,past,elementary school,u22,8,group 3,post test,3,7,1,C,C,Q-Table is the main aim of steps of Q-Learning. Q-table records the long rewards for? <please select the best answer> A. different actions B. different states C. different actions taken in each state,The steps of Q-Learning. Initialize Q table. Choose an action a. Perform action. Measure reward. Update Q. Go back to Choose an action a. At the end of the training: Good Q* table. Q-table is a table that records Q-values. Q-value: the maximum expectation of long-term rewards for different actions taken in each state. Value: the total reward that an agent can expect to collect from that state and onwards into the future.
b4030483-d06d-4887-b45e-0f6b107a3d7b,train,past,elementary school,u22,8,group 3,post test,4,9,0,B,A,"If the value in the current state is only indicated by the current reward, which of these formulas should we use to calculate Q value? <please select the best answer> A. Q=r B. Q_new = Q_old + 0.1*(r-Q_old)","Q-learning details. A simple situation: The current reward is the only indicator of the value in the current situation. A picture of a cheese at cell (2,1) in a 3x6 maze. A table of with entries corresponding to action/state where the actions are going up/down/left/right with the entries corresponding to state (1,1) being -1,+100,N/A,-1 and N/A,-1,N/A,+100 for state (3,1)."
5d3d3643-9efa-4ec7-b8f7-b61d1b081899,train,past,elementary school,u22,8,group 3,post test,1,3,0,A,B,True or False: The “reward” in the V-Learning means the total reward that an agent can expect to collect from that state and onwards into the future. <please select the best answer> A. True   B. False,"Quick review: reinforcement learning and V-learning. A picture showing 3 types of machine learning: unsupervised, supervised, and reinforcement. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent. Reward: the instantaneous benefit of being in a specific state, Value: the total reward that an agent can expect to collect from that state and onwards into the future. V-learning learns the value for different situations, i.e. how good the situation is."
f2cdd710-f8ba-4222-98a6-bd981cb99278,train,future,elementary school,u22,8,group 3,post test,8,18,0,B,C,Which kind of sensors bounce pulses of light off the car’s surroundings to measure distances? <please select the best answer> A. Radar sensors B. Video cameras C. Lidar sensors D. Ultrasonic sensors,How do autonumous cars work? Lidar (light detection and ranging) sensors bounce pulses of light off the car’s surroundings to measure distances. Ultrasonic sensors in the wheels detect curbs and other vehicles when parking. A picture of lidar. A picture of Ultrasonic sensors.
8a3cff56-8178-4008-9fbd-29e0461000d9,train,future,elementary school,u22,8,group 3,post test,9,4,0,A,D,"An agent is at state (1,1), and the Q-table is as follows. Which of the actions should the agent take? Content of Q-table: The rewards of action going right/left/up/down at state (1,1) are 10,25,-10,30 respectively. The rewards of action going right/left/up/down at state (1,2) are 20,-10,15,25 respectively. The rewards of action going right/left/up/down at state (2,1) are 30,10,15,-10 respectively. The rewards of action going right/left/up/down at state (2,2) are 25,30,10,-10 respectively. <please select the best answer> A. going right B. going left C. going up D. going down","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
670e39c1-1c6d-4aa0-9493-b048abd72295,train,past,elementary school,u22,8,group 3,post test,2,4,0,h,Action,"Both V-learning and Q-learning determine how good the new state is , but Q-learning learns the evaluation specific to something in addition to the state. What is it? <please input your answer>","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
82396971-e154-4688-b3ca-d65e3d99da25,train,future,elementary school,u22,8,group 3,post test,6,20,1,weather,The responsibility for crashes or something else that applies or some else,Can you name one issue or challenge that involves autonomous cars? <please input your answer>,Challenges with autonomous cars. Accident Liability: Who is liable for accidents caused by an autonomous car? Artificial vs. Emotional Intelligence: Human drivers rely on subtle cues and non-verbal communication to make split-second judgment calls and predict behaviors. A picture of a car crash.
dd4d4aa4-7d24-46b4-95a8-fa8fa10a9cce,train,past,elementary school,u22,8,group 3,post test,5,15,1,3 to 5 lets the person do less work while 0 to2 lets the person do most of the work while the computer helps it,"Of the Level 0-2, the human monitors the driving environment, of the level 3-5, the autonomous cars can monitors the driving environment.",The Society of Automotive Engineers (SAE) currently defines 6 levels of driving automation. Please describe the main difference between Level 0-2 and Level 3-5? <please input your answer>,6 levels of driving automation. The Society of Automotive Engineers (SAE) currently defines 6 levels of drving automation ranging from Level 0 (fully manual) to Level 5 (fully autonomous). Level 0-2: The human monitors the driving environment. Level 3-5: The automated system monitors the driving environment. A picture of the 6 levels of driving automation.
e48a4125-dc38-4f2f-9792-fa08f935992e,train,future,elementary school,u22,8,group 3,post test,10,11,1,B,B,"About how to choose action in the initial state, which of the approaches aim to collect the most reward you already know about? <please select the best answer> A. Exploration   B. Exploitation",A missing point: how to choose action? Exploration: Explore new area in the environment. Exploitation: Collect the most reward you already know about. Two animations showing two different total rewards a agent could get by choosing different actions.
b9bc9aa6-e09d-40ec-a71d-721af0539bce,train,future,elementary school,u22,8,group 3,post test,7,16,0,red an green light,"Environments: Many components. Traffic lights, pedestrian Actions: Brake, accelerate, turn left",Autonomous cars are under the framework. Please list some kinds of “environments” and “actions” in the situation of autonomous cars? <please input your answer>,"Under the framework of reinforcement learning. Agent: The car or the computer inside the car. Environment: Many components. Traffic lights, pedestrian, other cars, road signs... State: Current location, green/red light, position of pedstrain, speed limit... Action: Brake, accelerate, turn left... Reward: No accident. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent where the agent is the car and the environment is the world."
a66345e9-216c-4e42-9b3a-d8223f137ea6,test,past,elementary school,u23,8,group 3,post test,3,7,1,C,C,Q-Table is the main aim of steps of Q-Learning. Q-table records the long rewards for? <please select the best answer> A. different actions B. different states C. different actions taken in each state,The steps of Q-Learning. Initialize Q table. Choose an action a. Perform action. Measure reward. Update Q. Go back to Choose an action a. At the end of the training: Good Q* table. Q-table is a table that records Q-values. Q-value: the maximum expectation of long-term rewards for different actions taken in each state. Value: the total reward that an agent can expect to collect from that state and onwards into the future.
4f279f01-d4b1-4a66-adb2-8f993bf1d54a,test,past,elementary school,u23,8,group 3,post test,4,9,1,A,A,"If the value in the current state is only indicated by the current reward, which of these formulas should we use to calculate Q value? <please select the best answer> A. Q=r B. Q_new = Q_old + 0.1*(r-Q_old)","Q-learning details. A simple situation: The current reward is the only indicator of the value in the current situation. A picture of a cheese at cell (2,1) in a 3x6 maze. A table of with entries corresponding to action/state where the actions are going up/down/left/right with the entries corresponding to state (1,1) being -1,+100,N/A,-1 and N/A,-1,N/A,+100 for state (3,1)."
18c05389-4a44-40fb-833e-9ed131b09cd6,test,past,elementary school,u23,8,group 3,post test,1,3,1,B,B,True or False: The “reward” in the V-Learning means the total reward that an agent can expect to collect from that state and onwards into the future. <please select the best answer> A. True   B. False,"Quick review: reinforcement learning and V-learning. A picture showing 3 types of machine learning: unsupervised, supervised, and reinforcement. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent. Reward: the instantaneous benefit of being in a specific state, Value: the total reward that an agent can expect to collect from that state and onwards into the future. V-learning learns the value for different situations, i.e. how good the situation is."
d59414c8-b6ad-4f88-81b7-95c85a704b3a,test,future,elementary school,u23,8,group 3,post test,8,18,1,C,C,Which kind of sensors bounce pulses of light off the car’s surroundings to measure distances? <please select the best answer> A. Radar sensors B. Video cameras C. Lidar sensors D. Ultrasonic sensors,How do autonumous cars work? Lidar (light detection and ranging) sensors bounce pulses of light off the car’s surroundings to measure distances. Ultrasonic sensors in the wheels detect curbs and other vehicles when parking. A picture of lidar. A picture of Ultrasonic sensors.
ad0a56ba-3db3-4439-8ae8-93fd4414885b,test,future,elementary school,u23,8,group 3,post test,9,4,1,D,D,"An agent is at state (1,1), and the Q-table is as follows. Which of the actions should the agent take? Content of Q-table: The rewards of action going right/left/up/down at state (1,1) are 10,25,-10,30 respectively. The rewards of action going right/left/up/down at state (1,2) are 20,-10,15,25 respectively. The rewards of action going right/left/up/down at state (2,1) are 30,10,15,-10 respectively. The rewards of action going right/left/up/down at state (2,2) are 25,30,10,-10 respectively. <please select the best answer> A. going right B. going left C. going up D. going down","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
882812e2-0f5c-41ad-a4f4-284a94807342,test,past,elementary school,u23,8,group 3,post test,2,4,0,idk,Action,"Both V-learning and Q-learning determine how good the new state is , but Q-learning learns the evaluation specific to something in addition to the state. What is it? <please input your answer>","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
bad1da01-0d3f-41d9-ae1f-3fb61f0ab89c,test,future,elementary school,u23,8,group 3,post test,6,20,0,idk,The responsibility for crashes or something else that applies or some else,Can you name one issue or challenge that involves autonomous cars? <please input your answer>,Challenges with autonomous cars. Accident Liability: Who is liable for accidents caused by an autonomous car? Artificial vs. Emotional Intelligence: Human drivers rely on subtle cues and non-verbal communication to make split-second judgment calls and predict behaviors. A picture of a car crash.
4ef75879-4bf8-49bd-a60e-b57561d99e7f,test,past,elementary school,u23,8,group 3,post test,5,15,1,"0-2 is manual, 3-5 is auto","Of the Level 0-2, the human monitors the driving environment, of the level 3-5, the autonomous cars can monitors the driving environment.",The Society of Automotive Engineers (SAE) currently defines 6 levels of driving automation. Please describe the main difference between Level 0-2 and Level 3-5? <please input your answer>,6 levels of driving automation. The Society of Automotive Engineers (SAE) currently defines 6 levels of drving automation ranging from Level 0 (fully manual) to Level 5 (fully autonomous). Level 0-2: The human monitors the driving environment. Level 3-5: The automated system monitors the driving environment. A picture of the 6 levels of driving automation.
00c07415-12ab-4ec4-b890-fae3e09d6bcb,test,future,elementary school,u23,8,group 3,post test,10,11,1,B,B,"About how to choose action in the initial state, which of the approaches aim to collect the most reward you already know about? <please select the best answer> A. Exploration   B. Exploitation",A missing point: how to choose action? Exploration: Explore new area in the environment. Exploitation: Collect the most reward you already know about. Two animations showing two different total rewards a agent could get by choosing different actions.
a12c1a63-70f9-4f35-971b-1e5a8976262e,test,future,elementary school,u23,8,group 3,post test,7,16,0,idk,"Environments: Many components. Traffic lights, pedestrian Actions: Brake, accelerate, turn left",Autonomous cars are under the framework. Please list some kinds of “environments” and “actions” in the situation of autonomous cars? <please input your answer>,"Under the framework of reinforcement learning. Agent: The car or the computer inside the car. Environment: Many components. Traffic lights, pedestrian, other cars, road signs... State: Current location, green/red light, position of pedstrain, speed limit... Action: Brake, accelerate, turn left... Reward: No accident. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent where the agent is the car and the environment is the world."
ec7a8d16-3ac1-4f62-8752-e0447970ef42,test,past,elementary school,u24,8,group 3,post test,3,7,0,A,C,Q-Table is the main aim of steps of Q-Learning. Q-table records the long rewards for? <please select the best answer> A. different actions B. different states C. different actions taken in each state,The steps of Q-Learning. Initialize Q table. Choose an action a. Perform action. Measure reward. Update Q. Go back to Choose an action a. At the end of the training: Good Q* table. Q-table is a table that records Q-values. Q-value: the maximum expectation of long-term rewards for different actions taken in each state. Value: the total reward that an agent can expect to collect from that state and onwards into the future.
6ccc228b-4381-42c9-836c-63594e15bb0f,test,past,elementary school,u24,8,group 3,post test,4,9,1,A,A,"If the value in the current state is only indicated by the current reward, which of these formulas should we use to calculate Q value? <please select the best answer> A. Q=r B. Q_new = Q_old + 0.1*(r-Q_old)","Q-learning details. A simple situation: The current reward is the only indicator of the value in the current situation. A picture of a cheese at cell (2,1) in a 3x6 maze. A table of with entries corresponding to action/state where the actions are going up/down/left/right with the entries corresponding to state (1,1) being -1,+100,N/A,-1 and N/A,-1,N/A,+100 for state (3,1)."
d80765e4-49a4-4aaf-9a07-783c38fa6a9e,test,past,elementary school,u24,8,group 3,post test,1,3,1,B,B,True or False: The “reward” in the V-Learning means the total reward that an agent can expect to collect from that state and onwards into the future. <please select the best answer> A. True   B. False,"Quick review: reinforcement learning and V-learning. A picture showing 3 types of machine learning: unsupervised, supervised, and reinforcement. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent. Reward: the instantaneous benefit of being in a specific state, Value: the total reward that an agent can expect to collect from that state and onwards into the future. V-learning learns the value for different situations, i.e. how good the situation is."
b2e7055a-b9b7-454f-b750-1670d4e6a644,test,future,elementary school,u24,8,group 3,post test,8,18,0,B,C,Which kind of sensors bounce pulses of light off the car’s surroundings to measure distances? <please select the best answer> A. Radar sensors B. Video cameras C. Lidar sensors D. Ultrasonic sensors,How do autonumous cars work? Lidar (light detection and ranging) sensors bounce pulses of light off the car’s surroundings to measure distances. Ultrasonic sensors in the wheels detect curbs and other vehicles when parking. A picture of lidar. A picture of Ultrasonic sensors.
e4d76fdc-0d63-4845-99f7-91dc553cc124,test,future,elementary school,u24,8,group 3,post test,9,4,1,D,D,"An agent is at state (1,1), and the Q-table is as follows. Which of the actions should the agent take? Content of Q-table: The rewards of action going right/left/up/down at state (1,1) are 10,25,-10,30 respectively. The rewards of action going right/left/up/down at state (1,2) are 20,-10,15,25 respectively. The rewards of action going right/left/up/down at state (2,1) are 30,10,15,-10 respectively. The rewards of action going right/left/up/down at state (2,2) are 25,30,10,-10 respectively. <please select the best answer> A. going right B. going left C. going up D. going down","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
66146cc9-70d9-453e-b52c-8e9848335c0a,test,past,elementary school,u24,8,group 3,post test,2,4,0, ,Action,"Both V-learning and Q-learning determine how good the new state is , but Q-learning learns the evaluation specific to something in addition to the state. What is it? <please input your answer>","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
e1630c1b-4e99-40cc-a830-bfca7f5e67e5,test,future,elementary school,u24,8,group 3,post test,6,20,0, ,The responsibility for crashes or something else that applies or some else,Can you name one issue or challenge that involves autonomous cars? <please input your answer>,Challenges with autonomous cars. Accident Liability: Who is liable for accidents caused by an autonomous car? Artificial vs. Emotional Intelligence: Human drivers rely on subtle cues and non-verbal communication to make split-second judgment calls and predict behaviors. A picture of a car crash.
72b1df5d-cf77-4354-9b12-e51ccb185b3f,test,past,elementary school,u24,8,group 3,post test,5,15,0, ,"Of the Level 0-2, the human monitors the driving environment, of the level 3-5, the autonomous cars can monitors the driving environment.",The Society of Automotive Engineers (SAE) currently defines 6 levels of driving automation. Please describe the main difference between Level 0-2 and Level 3-5? <please input your answer>,6 levels of driving automation. The Society of Automotive Engineers (SAE) currently defines 6 levels of drving automation ranging from Level 0 (fully manual) to Level 5 (fully autonomous). Level 0-2: The human monitors the driving environment. Level 3-5: The automated system monitors the driving environment. A picture of the 6 levels of driving automation.
263ebdbf-e9de-4cf8-af8e-16b705dc86c1,test,future,elementary school,u24,8,group 3,post test,10,11,1,B,B,"About how to choose action in the initial state, which of the approaches aim to collect the most reward you already know about? <please select the best answer> A. Exploration   B. Exploitation",A missing point: how to choose action? Exploration: Explore new area in the environment. Exploitation: Collect the most reward you already know about. Two animations showing two different total rewards a agent could get by choosing different actions.
6d1117e6-1768-4b95-9ffd-3bd3835b3113,test,future,elementary school,u24,8,group 3,post test,7,16,0, ,"Environments: Many components. Traffic lights, pedestrian Actions: Brake, accelerate, turn left",Autonomous cars are under the framework. Please list some kinds of “environments” and “actions” in the situation of autonomous cars? <please input your answer>,"Under the framework of reinforcement learning. Agent: The car or the computer inside the car. Environment: Many components. Traffic lights, pedestrian, other cars, road signs... State: Current location, green/red light, position of pedstrain, speed limit... Action: Brake, accelerate, turn left... Reward: No accident. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent where the agent is the car and the environment is the world."
ac955887-88b5-474d-94f4-b1221dc39663,train,past,elementary school,u60,9,group 1,post test,3,4,0, ,Linguistic analysis / Database / Web content retrieval,Please cite a component of voice-controlled assistant that it needs for normal work. <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
dd567e12-16b7-454b-bdd3-630a04a88a81,train,past,elementary school,u60,9,group 1,post test,4,6,1,No,No,Is the accuracy of 95% enough for voice recognition? <please input your answer>,Recognition Accuracy. We first need a system to recognize speech when creating a voice-controlled personal assistant. The accuracy of speech recognition is very demanding. 95% is not good. 99% is good. A picture of The Telephone Game to show the importance of speech recongition accuracy.
b324ea08-278f-4ac1-9e5f-4eb0dc0bab68,train,past,elementary school,u60,9,group 1,post test,1,4,1,Speech recognition,Speech recognition,What is the first main component of a virtual assistant? <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
295fe937-3f2b-43bb-9c9a-8330aa38baa9,train,future,elementary school,u60,9,group 1,post test,8,15,0, ,Unfolding,What should we do when we want to train an RNN? <please input your answer>,"Training an RNN. Training an RNN by using backpropagation is more complicated than training an ANN with no loops. Unfolding: The loops are removed by duplicating parts of the neural network whenever they represent different parts of the sentence. After unfolding, we can train the RNN the way we train ANNs without loops. A picture illustrating the concept of unfolding."
afd73d64-fd8c-4485-af94-02a6a61ac347,train,future,elementary school,u60,9,group 1,post test,9,22,1,long-short term memory,Long Short-Term Memory,What does LSTM stand for? <please input your answer>,Q&A. Lecture 9.
0b2674b2-d734-44f5-be11-bda74c2897db,train,past,elementary school,u60,9,group 1,post test,2,20,1,Speech generation,Speech generation,What is the last main component of a virtual assistant? <please input your answer>,Voice Synthesis. Voice Synthesis is the final stage of a voice-controlled personal assistant. Speech synthesis is accomplished using an RNN that converts a series of linguistic sounds into a series of spectrum. A picture of chat history of a human with a bot.
bfa9dda1-72ef-4d00-b253-5d565eee41df,train,future,elementary school,u60,9,group 1,post test,6,11,1,"(0,0,1,0,1)","(0,0,1,0,1)","Take five words {Cats, Dogs, bark, meow, eat} Take three sentences, “Dogs bark” “Cats eat” “Dogs eat” How to express the words after the “Dogs”? <please input your answer>","Words Representation. Method: finding out how often the word appears after which words and before which words by going through a huge data set. E.g. Words: {Cats, Dogs, Bark, Meow, Eat}. Phrases: {'Cats meow,' 'Dogs bark,' 'Cats eat,' 'Dogs eat'}. Result:'Cats' is often before 'meow' and 'eat', which can be expressed as (0,0,0,1,1). 'Cats' doesn’t often appear after any words, which can be expressed as (0,0,0,0,0). 'Cat” = (0,0,0,0,0, 0,0,0,1,1). A picture of a word cloud. A picture breaking down the grammar of an English sentence."
caa3cd59-4a3f-4475-986c-f77671459546,train,past,elementary school,u60,9,group 1,post test,5,10,0, ,Assigning different neurons to different words,How are the words represented in an ANN? <please input your answer>,"How Should the Words be Represented in an ANN? Question: Why not type the words into a computer as a string of the alphabet for input? Assigning different neurons to different words. Then, add more information relating to each word: Represent a word with a group of words the original word is often used with. E.g. 'Cats' with 'meow' 'walk'. A picture of word cloud. A picture of a word connected to other words that it is related to."
459b3ee6-2462-48e7-a96d-4404bd7af0ab,train,future,elementary school,u60,9,group 1,post test,10,22,0, ,"The input, the short-term memory, and the output","Compared to regular RNN, LSTM has better control over its three components. What are they? <please input your answer>",Q&A. Lecture 9.
26e36850-3b40-4a87-94f8-7f903ac516e8,train,future,elementary school,u60,9,group 1,post test,7,14,0, ,A loop,What does an RNN have that a simple three-layer neural network doesn’t have? <please input your answer>,Recurrent Neural Network. The network is called a Recurrent Neural Network (RNN) because it has a loop in the connection to feed the previous activations back to the input. This network receives one word at a time and is trained to generate an output each time using supervised learning with additional 'desired outputs'. Another usage: They can also be trained to represent phrases and sentences. A picture of RNN.
4e990f68-0e74-443c-9d92-2aff50a47b7a,train,past,elementary school,u31,9,group 1,post test,3,4,1,A microphone,Linguistic analysis / Database / Web content retrieval,Please cite a component of voice-controlled assistant that it needs for normal work. <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
fd9847a5-83b0-4f4c-97b3-3a11d0ed2294,train,past,elementary school,u31,9,group 1,post test,4,6,1,No,No,Is the accuracy of 95% enough for voice recognition? <please input your answer>,Recognition Accuracy. We first need a system to recognize speech when creating a voice-controlled personal assistant. The accuracy of speech recognition is very demanding. 95% is not good. 99% is good. A picture of The Telephone Game to show the importance of speech recongition accuracy.
878bc44a-0ca0-4132-9fe6-70e6f2535ff5,train,past,elementary school,u31,9,group 1,post test,1,4,1,Speech recognition,Speech recognition,What is the first main component of a virtual assistant? <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
aa8752d2-7e2b-4377-a9b4-9bab63649917,train,future,elementary school,u31,9,group 1,post test,8,15,0,forgot,Unfolding,What should we do when we want to train an RNN? <please input your answer>,"Training an RNN. Training an RNN by using backpropagation is more complicated than training an ANN with no loops. Unfolding: The loops are removed by duplicating parts of the neural network whenever they represent different parts of the sentence. After unfolding, we can train the RNN the way we train ANNs without loops. A picture illustrating the concept of unfolding."
d35c3551-3d22-414f-b19e-487a4e69184e,train,future,elementary school,u31,9,group 1,post test,9,22,0,forgot,Long Short-Term Memory,What does LSTM stand for? <please input your answer>,Q&A. Lecture 9.
d50621bc-4af5-4bbb-8c61-e0fa8f5dfe9d,train,past,elementary school,u31,9,group 1,post test,2,20,1,Speech generation,Speech generation,What is the last main component of a virtual assistant? <please input your answer>,Voice Synthesis. Voice Synthesis is the final stage of a voice-controlled personal assistant. Speech synthesis is accomplished using an RNN that converts a series of linguistic sounds into a series of spectrum. A picture of chat history of a human with a bot.
20688141-8810-4543-b1ae-8651938740ff,train,future,elementary school,u31,9,group 1,post test,6,11,1,"(0,0,1,0,1)","(0,0,1,0,1)","Take five words {Cats, Dogs, bark, meow, eat} Take three sentences, “Dogs bark” “Cats eat” “Dogs eat” How to express the words after the “Dogs”? <please input your answer>","Words Representation. Method: finding out how often the word appears after which words and before which words by going through a huge data set. E.g. Words: {Cats, Dogs, Bark, Meow, Eat}. Phrases: {'Cats meow,' 'Dogs bark,' 'Cats eat,' 'Dogs eat'}. Result:'Cats' is often before 'meow' and 'eat', which can be expressed as (0,0,0,1,1). 'Cats' doesn’t often appear after any words, which can be expressed as (0,0,0,0,0). 'Cat” = (0,0,0,0,0, 0,0,0,1,1). A picture of a word cloud. A picture breaking down the grammar of an English sentence."
97deb82b-9f0e-4833-8bca-b942a1d87b0a,train,past,elementary school,u31,9,group 1,post test,5,10,0,I forgot,Assigning different neurons to different words,How are the words represented in an ANN? <please input your answer>,"How Should the Words be Represented in an ANN? Question: Why not type the words into a computer as a string of the alphabet for input? Assigning different neurons to different words. Then, add more information relating to each word: Represent a word with a group of words the original word is often used with. E.g. 'Cats' with 'meow' 'walk'. A picture of word cloud. A picture of a word connected to other words that it is related to."
6e368192-ebc0-4348-97e6-69d32757db77,train,future,elementary school,u31,9,group 1,post test,10,22,0,forgot,"The input, the short-term memory, and the output","Compared to regular RNN, LSTM has better control over its three components. What are they? <please input your answer>",Q&A. Lecture 9.
096a0490-93fa-4b07-a144-79e230c0817e,train,future,elementary school,u31,9,group 1,post test,7,14,0,forgot,A loop,What does an RNN have that a simple three-layer neural network doesn’t have? <please input your answer>,Recurrent Neural Network. The network is called a Recurrent Neural Network (RNN) because it has a loop in the connection to feed the previous activations back to the input. This network receives one word at a time and is trained to generate an output each time using supervised learning with additional 'desired outputs'. Another usage: They can also be trained to represent phrases and sentences. A picture of RNN.
12c75910-3cc3-4d34-9802-da62732d02aa,train,past,elementary school,u44,9,group 2,post test,3,4,1,sequence processing,Linguistic analysis / Database / Web content retrieval,Please cite a component of voice-controlled assistant that it needs for normal work. <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
95533b53-594b-4797-805c-da1ebb04f17e,train,past,elementary school,u44,9,group 2,post test,4,6,1,No,No,Is the accuracy of 95% enough for voice recognition? <please input your answer>,Recognition Accuracy. We first need a system to recognize speech when creating a voice-controlled personal assistant. The accuracy of speech recognition is very demanding. 95% is not good. 99% is good. A picture of The Telephone Game to show the importance of speech recongition accuracy.
9f26643c-aff4-40f6-8b41-8f2544721907,train,past,elementary school,u44,9,group 2,post test,1,4,1,Speech recognition,Speech recognition,What is the first main component of a virtual assistant? <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
08208e3f-da32-4c06-82d8-09e79fe41046,train,future,elementary school,u44,9,group 2,post test,8,15,0,put more inputs,Unfolding,What should we do when we want to train an RNN? <please input your answer>,"Training an RNN. Training an RNN by using backpropagation is more complicated than training an ANN with no loops. Unfolding: The loops are removed by duplicating parts of the neural network whenever they represent different parts of the sentence. After unfolding, we can train the RNN the way we train ANNs without loops. A picture illustrating the concept of unfolding."
68f6afec-e5c6-4251-9744-37f61b4a2eae,train,future,elementary school,u44,9,group 2,post test,9,22,0,???,Long Short-Term Memory,What does LSTM stand for? <please input your answer>,Q&A. Lecture 9.
b0c67f6f-0f15-4248-b456-2b671b9c2fc9,train,past,elementary school,u44,9,group 2,post test,2,20,0,Speech recognition,Speech generation,What is the last main component of a virtual assistant? <please input your answer>,Voice Synthesis. Voice Synthesis is the final stage of a voice-controlled personal assistant. Speech synthesis is accomplished using an RNN that converts a series of linguistic sounds into a series of spectrum. A picture of chat history of a human with a bot.
c6789367-d146-46d6-9dfc-efae477a423b,train,future,elementary school,u44,9,group 2,post test,6,11,0,"(0,1,0,1,0,)","(0,0,1,0,1)","Take five words {Cats, Dogs, bark, meow, eat} Take three sentences, “Dogs bark” “Cats eat” “Dogs eat” How to express the words after the “Dogs”? <please input your answer>","Words Representation. Method: finding out how often the word appears after which words and before which words by going through a huge data set. E.g. Words: {Cats, Dogs, Bark, Meow, Eat}. Phrases: {'Cats meow,' 'Dogs bark,' 'Cats eat,' 'Dogs eat'}. Result:'Cats' is often before 'meow' and 'eat', which can be expressed as (0,0,0,1,1). 'Cats' doesn’t often appear after any words, which can be expressed as (0,0,0,0,0). 'Cat” = (0,0,0,0,0, 0,0,0,1,1). A picture of a word cloud. A picture breaking down the grammar of an English sentence."
f64b74fe-5f55-476a-88e6-282d7555d61c,train,past,elementary school,u44,9,group 2,post test,5,10,0,"0, and 1",Assigning different neurons to different words,How are the words represented in an ANN? <please input your answer>,"How Should the Words be Represented in an ANN? Question: Why not type the words into a computer as a string of the alphabet for input? Assigning different neurons to different words. Then, add more information relating to each word: Represent a word with a group of words the original word is often used with. E.g. 'Cats' with 'meow' 'walk'. A picture of word cloud. A picture of a word connected to other words that it is related to."
c1580cc6-498d-42f9-8c65-1cc1ed4e487a,train,future,elementary school,u44,9,group 2,post test,10,22,0,sequence processing sequence processing and speech recognition,"The input, the short-term memory, and the output","Compared to regular RNN, LSTM has better control over its three components. What are they? <please input your answer>",Q&A. Lecture 9.
1833fc1a-c942-4e8f-9895-7d7f16b0443e,train,future,elementary school,u44,9,group 2,post test,7,14,0,neural network,A loop,What does an RNN have that a simple three-layer neural network doesn’t have? <please input your answer>,Recurrent Neural Network. The network is called a Recurrent Neural Network (RNN) because it has a loop in the connection to feed the previous activations back to the input. This network receives one word at a time and is trained to generate an output each time using supervised learning with additional 'desired outputs'. Another usage: They can also be trained to represent phrases and sentences. A picture of RNN.
7191150a-f7e3-45bc-833a-b8d81206a7f8,train,past,elementary school,u7,9,group 2,post test,3,4,1,mic,Linguistic analysis / Database / Web content retrieval,Please cite a component of voice-controlled assistant that it needs for normal work. <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
b8462451-0f8f-41ed-9a86-4f3d52b213d6,train,past,elementary school,u7,9,group 2,post test,4,6,1,No,No,Is the accuracy of 95% enough for voice recognition? <please input your answer>,Recognition Accuracy. We first need a system to recognize speech when creating a voice-controlled personal assistant. The accuracy of speech recognition is very demanding. 95% is not good. 99% is good. A picture of The Telephone Game to show the importance of speech recongition accuracy.
afbe225d-9c72-48e4-a82f-61505fdf5f9b,train,past,elementary school,u7,9,group 2,post test,1,4,1,Speech recognition,Speech recognition,What is the first main component of a virtual assistant? <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
4df03d7e-1447-4ed9-a736-19cf86bc0beb,train,future,elementary school,u7,9,group 2,post test,8,15,0,fv,Unfolding,What should we do when we want to train an RNN? <please input your answer>,"Training an RNN. Training an RNN by using backpropagation is more complicated than training an ANN with no loops. Unfolding: The loops are removed by duplicating parts of the neural network whenever they represent different parts of the sentence. After unfolding, we can train the RNN the way we train ANNs without loops. A picture illustrating the concept of unfolding."
e7a76dc4-7f26-43ea-9f45-a2485f266dd5,train,future,elementary school,u7,9,group 2,post test,9,22,0,dd,Long Short-Term Memory,What does LSTM stand for? <please input your answer>,Q&A. Lecture 9.
5f37984f-907d-419a-890c-d647e3713a6b,train,past,elementary school,u7,9,group 2,post test,2,20,1,Speech generation,Speech generation,What is the last main component of a virtual assistant? <please input your answer>,Voice Synthesis. Voice Synthesis is the final stage of a voice-controlled personal assistant. Speech synthesis is accomplished using an RNN that converts a series of linguistic sounds into a series of spectrum. A picture of chat history of a human with a bot.
f87ca47b-58fd-4b6a-82e2-f0707eadd62e,train,future,elementary school,u7,9,group 2,post test,6,11,1,"(0,0,1,0,1)","(0,0,1,0,1)","Take five words {Cats, Dogs, bark, meow, eat} Take three sentences, “Dogs bark” “Cats eat” “Dogs eat” How to express the words after the “Dogs”? <please input your answer>","Words Representation. Method: finding out how often the word appears after which words and before which words by going through a huge data set. E.g. Words: {Cats, Dogs, Bark, Meow, Eat}. Phrases: {'Cats meow,' 'Dogs bark,' 'Cats eat,' 'Dogs eat'}. Result:'Cats' is often before 'meow' and 'eat', which can be expressed as (0,0,0,1,1). 'Cats' doesn’t often appear after any words, which can be expressed as (0,0,0,0,0). 'Cat” = (0,0,0,0,0, 0,0,0,1,1). A picture of a word cloud. A picture breaking down the grammar of an English sentence."
4800d052-0b2b-4c0f-b5fe-b57571faa595,train,past,elementary school,u7,9,group 2,post test,5,10,0,ft,Assigning different neurons to different words,How are the words represented in an ANN? <please input your answer>,"How Should the Words be Represented in an ANN? Question: Why not type the words into a computer as a string of the alphabet for input? Assigning different neurons to different words. Then, add more information relating to each word: Represent a word with a group of words the original word is often used with. E.g. 'Cats' with 'meow' 'walk'. A picture of word cloud. A picture of a word connected to other words that it is related to."
4d211211-d431-4506-8eb5-12d73465a2c4,train,future,elementary school,u7,9,group 2,post test,10,22,0,hh,"The input, the short-term memory, and the output","Compared to regular RNN, LSTM has better control over its three components. What are they? <please input your answer>",Q&A. Lecture 9.
ad7bad7b-8248-4a27-9924-80f0e6adfe7a,train,future,elementary school,u7,9,group 2,post test,7,14,0,tf,A loop,What does an RNN have that a simple three-layer neural network doesn’t have? <please input your answer>,Recurrent Neural Network. The network is called a Recurrent Neural Network (RNN) because it has a loop in the connection to feed the previous activations back to the input. This network receives one word at a time and is trained to generate an output each time using supervised learning with additional 'desired outputs'. Another usage: They can also be trained to represent phrases and sentences. A picture of RNN.
348b89c0-1349-4fc7-bf22-0588ec34345d,train,past,elementary school,u26,9,group 3,post test,3,4,1,It needs understand what the person is saying first before replying or even talking.,Linguistic analysis / Database / Web content retrieval,Please cite a component of voice-controlled assistant that it needs for normal work. <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
fa58fcff-3a8d-45e3-b0a6-4037d9786d71,train,past,elementary school,u26,9,group 3,post test,4,6,1,No,No,Is the accuracy of 95% enough for voice recognition? <please input your answer>,Recognition Accuracy. We first need a system to recognize speech when creating a voice-controlled personal assistant. The accuracy of speech recognition is very demanding. 95% is not good. 99% is good. A picture of The Telephone Game to show the importance of speech recongition accuracy.
0caed818-cf65-4c89-b138-ff2eee5472f8,train,past,elementary school,u26,9,group 3,post test,1,4,1,Speech recognition,Speech recognition,What is the first main component of a virtual assistant? <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
ffbbc878-67cd-4d3f-9976-9ee109253271,train,future,elementary school,u26,9,group 3,post test,8,15,0,create a session then loop,Unfolding,What should we do when we want to train an RNN? <please input your answer>,"Training an RNN. Training an RNN by using backpropagation is more complicated than training an ANN with no loops. Unfolding: The loops are removed by duplicating parts of the neural network whenever they represent different parts of the sentence. After unfolding, we can train the RNN the way we train ANNs without loops. A picture illustrating the concept of unfolding."
888e0ffc-7f56-4623-b7b1-64888b9b8f9d,train,future,elementary school,u26,9,group 3,post test,9,22,1,long-short term memory,Long Short-Term Memory,What does LSTM stand for? <please input your answer>,Q&A. Lecture 9.
6cac952b-dec4-4b76-bc8e-eb17380ec508,train,past,elementary school,u26,9,group 3,post test,2,20,1,Speech generation,Speech generation,What is the last main component of a virtual assistant? <please input your answer>,Voice Synthesis. Voice Synthesis is the final stage of a voice-controlled personal assistant. Speech synthesis is accomplished using an RNN that converts a series of linguistic sounds into a series of spectrum. A picture of chat history of a human with a bot.
05da0f9b-1002-44ae-ae77-92decfc016b5,train,future,elementary school,u26,9,group 3,post test,6,11,0,"(1,1,0,0,0)","(0,0,1,0,1)","Take five words {Cats, Dogs, bark, meow, eat} Take three sentences, “Dogs bark” “Cats eat” “Dogs eat” How to express the words after the “Dogs”? <please input your answer>","Words Representation. Method: finding out how often the word appears after which words and before which words by going through a huge data set. E.g. Words: {Cats, Dogs, Bark, Meow, Eat}. Phrases: {'Cats meow,' 'Dogs bark,' 'Cats eat,' 'Dogs eat'}. Result:'Cats' is often before 'meow' and 'eat', which can be expressed as (0,0,0,1,1). 'Cats' doesn’t often appear after any words, which can be expressed as (0,0,0,0,0). 'Cat” = (0,0,0,0,0, 0,0,0,1,1). A picture of a word cloud. A picture breaking down the grammar of an English sentence."
bb149594-4782-4dd1-b595-fbc7c7177682,train,past,elementary school,u26,9,group 3,post test,5,10,0,with nodes,Assigning different neurons to different words,How are the words represented in an ANN? <please input your answer>,"How Should the Words be Represented in an ANN? Question: Why not type the words into a computer as a string of the alphabet for input? Assigning different neurons to different words. Then, add more information relating to each word: Represent a word with a group of words the original word is often used with. E.g. 'Cats' with 'meow' 'walk'. A picture of word cloud. A picture of a word connected to other words that it is related to."
dc64a2ad-ff4f-4a5d-88a4-396843a3c8c3,train,future,elementary school,u26,9,group 3,post test,10,22,0,?,"The input, the short-term memory, and the output","Compared to regular RNN, LSTM has better control over its three components. What are they? <please input your answer>",Q&A. Lecture 9.
a8d04ccd-8ccb-4250-a23d-edb9a4820c2d,train,future,elementary school,u26,9,group 3,post test,7,14,0,a hidden layer,A loop,What does an RNN have that a simple three-layer neural network doesn’t have? <please input your answer>,Recurrent Neural Network. The network is called a Recurrent Neural Network (RNN) because it has a loop in the connection to feed the previous activations back to the input. This network receives one word at a time and is trained to generate an output each time using supervised learning with additional 'desired outputs'. Another usage: They can also be trained to represent phrases and sentences. A picture of RNN.
298d5565-ddd8-43dd-98be-100ff038d07e,train,past,elementary school,u25,9,group 3,post test,3,4,1,Speech generation,Linguistic analysis / Database / Web content retrieval,Please cite a component of voice-controlled assistant that it needs for normal work. <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
d3374256-3009-412b-8aec-f4bac7820a49,train,past,elementary school,u25,9,group 3,post test,4,6,1,No,No,Is the accuracy of 95% enough for voice recognition? <please input your answer>,Recognition Accuracy. We first need a system to recognize speech when creating a voice-controlled personal assistant. The accuracy of speech recognition is very demanding. 95% is not good. 99% is good. A picture of The Telephone Game to show the importance of speech recongition accuracy.
1e0a0aa9-a12d-4ce7-a0fe-05c49a2eac56,train,past,elementary school,u25,9,group 3,post test,1,4,1,Speech recognition,Speech recognition,What is the first main component of a virtual assistant? <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
ca368a9d-4d37-47bd-8ada-e07ff66d05ca,train,future,elementary school,u25,9,group 3,post test,8,15,0,?,Unfolding,What should we do when we want to train an RNN? <please input your answer>,"Training an RNN. Training an RNN by using backpropagation is more complicated than training an ANN with no loops. Unfolding: The loops are removed by duplicating parts of the neural network whenever they represent different parts of the sentence. After unfolding, we can train the RNN the way we train ANNs without loops. A picture illustrating the concept of unfolding."
29052bcd-34c0-4d1d-92c2-dfdea672c86b,train,future,elementary school,u25,9,group 3,post test,9,22,1,Long Short Term Memory ,Long Short-Term Memory,What does LSTM stand for? <please input your answer>,Q&A. Lecture 9.
063020d7-7a81-4c97-8a5a-e931d2d12d79,train,past,elementary school,u25,9,group 3,post test,2,20,1,Speech generation,Speech generation,What is the last main component of a virtual assistant? <please input your answer>,Voice Synthesis. Voice Synthesis is the final stage of a voice-controlled personal assistant. Speech synthesis is accomplished using an RNN that converts a series of linguistic sounds into a series of spectrum. A picture of chat history of a human with a bot.
6eb58b49-a684-42b2-b8c4-7b0d83b00fe5,train,future,elementary school,u25,9,group 3,post test,6,11,1,"(0,0,1,0,1)","(0,0,1,0,1)","Take five words {Cats, Dogs, bark, meow, eat} Take three sentences, “Dogs bark” “Cats eat” “Dogs eat” How to express the words after the “Dogs”? <please input your answer>","Words Representation. Method: finding out how often the word appears after which words and before which words by going through a huge data set. E.g. Words: {Cats, Dogs, Bark, Meow, Eat}. Phrases: {'Cats meow,' 'Dogs bark,' 'Cats eat,' 'Dogs eat'}. Result:'Cats' is often before 'meow' and 'eat', which can be expressed as (0,0,0,1,1). 'Cats' doesn’t often appear after any words, which can be expressed as (0,0,0,0,0). 'Cat” = (0,0,0,0,0, 0,0,0,1,1). A picture of a word cloud. A picture breaking down the grammar of an English sentence."
590a4b28-58b4-43f5-9092-2844c9e5c7a7,train,past,elementary school,u25,9,group 3,post test,5,10,0,Binary,Assigning different neurons to different words,How are the words represented in an ANN? <please input your answer>,"How Should the Words be Represented in an ANN? Question: Why not type the words into a computer as a string of the alphabet for input? Assigning different neurons to different words. Then, add more information relating to each word: Represent a word with a group of words the original word is often used with. E.g. 'Cats' with 'meow' 'walk'. A picture of word cloud. A picture of a word connected to other words that it is related to."
634f7a31-ba72-46bc-b921-cf3fb7b23800,train,future,elementary school,u25,9,group 3,post test,10,22,0,?,"The input, the short-term memory, and the output","Compared to regular RNN, LSTM has better control over its three components. What are they? <please input your answer>",Q&A. Lecture 9.
54af183a-6074-4fba-94a6-c1b5f666b5c1,train,future,elementary school,u25,9,group 3,post test,7,14,0,?,A loop,What does an RNN have that a simple three-layer neural network doesn’t have? <please input your answer>,Recurrent Neural Network. The network is called a Recurrent Neural Network (RNN) because it has a loop in the connection to feed the previous activations back to the input. This network receives one word at a time and is trained to generate an output each time using supervised learning with additional 'desired outputs'. Another usage: They can also be trained to represent phrases and sentences. A picture of RNN.
36487dfe-2c83-4170-9287-7f2ff2c662d8,test,past,elementary school,u46,9,group 3,post test,3,4,0,a/e/i/o/u,Linguistic analysis / Database / Web content retrieval,Please cite a component of voice-controlled assistant that it needs for normal work. <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
03331c53-13cc-46cd-a266-4a60d517a6a3,test,past,elementary school,u46,9,group 3,post test,4,6,1,No,No,Is the accuracy of 95% enough for voice recognition? <please input your answer>,Recognition Accuracy. We first need a system to recognize speech when creating a voice-controlled personal assistant. The accuracy of speech recognition is very demanding. 95% is not good. 99% is good. A picture of The Telephone Game to show the importance of speech recongition accuracy.
8f1d8bc6-f768-44c2-a21b-8297faa6aafd,test,past,elementary school,u46,9,group 3,post test,1,4,1,Speech recognition,Speech recognition,What is the first main component of a virtual assistant? <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
7652fd5d-5acd-4df9-ab10-c940ab73071b,test,future,elementary school,u46,9,group 3,post test,8,15,1,Backpropagation,Unfolding,What should we do when we want to train an RNN? <please input your answer>,"Training an RNN. Training an RNN by using backpropagation is more complicated than training an ANN with no loops. Unfolding: The loops are removed by duplicating parts of the neural network whenever they represent different parts of the sentence. After unfolding, we can train the RNN the way we train ANNs without loops. A picture illustrating the concept of unfolding."
feddca37-a8b3-47e0-97ba-2a420410761a,test,future,elementary school,u46,9,group 3,post test,9,22,1,Long Short-Term Memory,Long Short-Term Memory,What does LSTM stand for? <please input your answer>,Q&A. Lecture 9.
c8d34131-b54d-45f6-a880-b34774b43ed7,test,past,elementary school,u46,9,group 3,post test,2,20,1,Speech generation,Speech generation,What is the last main component of a virtual assistant? <please input your answer>,Voice Synthesis. Voice Synthesis is the final stage of a voice-controlled personal assistant. Speech synthesis is accomplished using an RNN that converts a series of linguistic sounds into a series of spectrum. A picture of chat history of a human with a bot.
120bcf10-92c6-4995-b198-f45450547749,test,future,elementary school,u46,9,group 3,post test,6,11,1,"(0,0,1,0,1)","(0,0,1,0,1)","Take five words {Cats, Dogs, bark, meow, eat} Take three sentences, “Dogs bark” “Cats eat” “Dogs eat” How to express the words after the “Dogs”? <please input your answer>","Words Representation. Method: finding out how often the word appears after which words and before which words by going through a huge data set. E.g. Words: {Cats, Dogs, Bark, Meow, Eat}. Phrases: {'Cats meow,' 'Dogs bark,' 'Cats eat,' 'Dogs eat'}. Result:'Cats' is often before 'meow' and 'eat', which can be expressed as (0,0,0,1,1). 'Cats' doesn’t often appear after any words, which can be expressed as (0,0,0,0,0). 'Cat” = (0,0,0,0,0, 0,0,0,1,1). A picture of a word cloud. A picture breaking down the grammar of an English sentence."
ad099b2d-529c-46f1-b0d8-66615bd1150d,test,past,elementary school,u46,9,group 3,post test,5,10,1,assign different neurons to different words,Assigning different neurons to different words,How are the words represented in an ANN? <please input your answer>,"How Should the Words be Represented in an ANN? Question: Why not type the words into a computer as a string of the alphabet for input? Assigning different neurons to different words. Then, add more information relating to each word: Represent a word with a group of words the original word is often used with. E.g. 'Cats' with 'meow' 'walk'. A picture of word cloud. A picture of a word connected to other words that it is related to."
bf527726-3c44-4aa2-8143-b700418afbda,test,future,elementary school,u46,9,group 3,post test,10,22,0,LSTM can handle the information in memory for the long period of time as compare to RNN,"The input, the short-term memory, and the output","Compared to regular RNN, LSTM has better control over its three components. What are they? <please input your answer>",Q&A. Lecture 9.
36524d45-fd7c-47b8-9765-30bd9a8f44a0,test,future,elementary school,u46,9,group 3,post test,7,14,0,Can be trained to remember complicated words and phrases,A loop,What does an RNN have that a simple three-layer neural network doesn’t have? <please input your answer>,Recurrent Neural Network. The network is called a Recurrent Neural Network (RNN) because it has a loop in the connection to feed the previous activations back to the input. This network receives one word at a time and is trained to generate an output each time using supervised learning with additional 'desired outputs'. Another usage: They can also be trained to represent phrases and sentences. A picture of RNN.
7bebe1fa-80a3-4e94-863a-d9aef4e5222a,test,past,elementary school,u23,9,group 3,post test,3,4,0, ,Linguistic analysis / Database / Web content retrieval,Please cite a component of voice-controlled assistant that it needs for normal work. <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
a0e83034-1f6c-4a89-b089-752f52e0811e,test,past,elementary school,u23,9,group 3,post test,4,6,1,No,No,Is the accuracy of 95% enough for voice recognition? <please input your answer>,Recognition Accuracy. We first need a system to recognize speech when creating a voice-controlled personal assistant. The accuracy of speech recognition is very demanding. 95% is not good. 99% is good. A picture of The Telephone Game to show the importance of speech recongition accuracy.
b0798fc5-b6c0-4ee0-a2eb-9370dbce961e,test,past,elementary school,u23,9,group 3,post test,1,4,1,Speech recognition,Speech recognition,What is the first main component of a virtual assistant? <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
8242a8cd-a8bb-456a-b27b-6f54c5d3b51b,test,future,elementary school,u23,9,group 3,post test,8,15,0,supervised learning,Unfolding,What should we do when we want to train an RNN? <please input your answer>,"Training an RNN. Training an RNN by using backpropagation is more complicated than training an ANN with no loops. Unfolding: The loops are removed by duplicating parts of the neural network whenever they represent different parts of the sentence. After unfolding, we can train the RNN the way we train ANNs without loops. A picture illustrating the concept of unfolding."
1d335fac-4ae4-4478-813e-c6d56b36d409,test,future,elementary school,u23,9,group 3,post test,9,22,0, ,Long Short-Term Memory,What does LSTM stand for? <please input your answer>,Q&A. Lecture 9.
7ae386d4-6783-46d1-b3dc-fbebcec1cba0,test,past,elementary school,u23,9,group 3,post test,2,20,1,Speech generation,Speech generation,What is the last main component of a virtual assistant? <please input your answer>,Voice Synthesis. Voice Synthesis is the final stage of a voice-controlled personal assistant. Speech synthesis is accomplished using an RNN that converts a series of linguistic sounds into a series of spectrum. A picture of chat history of a human with a bot.
1610edd5-5849-4471-9f49-e49e26b5a234,test,future,elementary school,u23,9,group 3,post test,6,11,1,"(0,0,1,0,1)","(0,0,1,0,1)","Take five words {Cats, Dogs, bark, meow, eat} Take three sentences, “Dogs bark” “Cats eat” “Dogs eat” How to express the words after the “Dogs”? <please input your answer>","Words Representation. Method: finding out how often the word appears after which words and before which words by going through a huge data set. E.g. Words: {Cats, Dogs, Bark, Meow, Eat}. Phrases: {'Cats meow,' 'Dogs bark,' 'Cats eat,' 'Dogs eat'}. Result:'Cats' is often before 'meow' and 'eat', which can be expressed as (0,0,0,1,1). 'Cats' doesn’t often appear after any words, which can be expressed as (0,0,0,0,0). 'Cat” = (0,0,0,0,0, 0,0,0,1,1). A picture of a word cloud. A picture breaking down the grammar of an English sentence."
982d9eb7-9bd2-4d56-af87-5d5b3ea900a1,test,past,elementary school,u23,9,group 3,post test,5,10,0,branched catagories,Assigning different neurons to different words,How are the words represented in an ANN? <please input your answer>,"How Should the Words be Represented in an ANN? Question: Why not type the words into a computer as a string of the alphabet for input? Assigning different neurons to different words. Then, add more information relating to each word: Represent a word with a group of words the original word is often used with. E.g. 'Cats' with 'meow' 'walk'. A picture of word cloud. A picture of a word connected to other words that it is related to."
6e90ed48-b17f-48d6-9ab6-ada0c02c61df,test,future,elementary school,u23,9,group 3,post test,10,22,0, ,"The input, the short-term memory, and the output","Compared to regular RNN, LSTM has better control over its three components. What are they? <please input your answer>",Q&A. Lecture 9.
bef6c6df-28a3-4127-881e-ae815ee6cc7f,test,future,elementary school,u23,9,group 3,post test,7,14,0, ,A loop,What does an RNN have that a simple three-layer neural network doesn’t have? <please input your answer>,Recurrent Neural Network. The network is called a Recurrent Neural Network (RNN) because it has a loop in the connection to feed the previous activations back to the input. This network receives one word at a time and is trained to generate an output each time using supervised learning with additional 'desired outputs'. Another usage: They can also be trained to represent phrases and sentences. A picture of RNN.
89466373-0fa4-4d0b-a4a0-9e7029bf6905,test,past,elementary school,u24,9,group 3,post test,3,4,0, ,Linguistic analysis / Database / Web content retrieval,Please cite a component of voice-controlled assistant that it needs for normal work. <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
78485351-f716-4044-b2da-be5f891b5b8c,test,past,elementary school,u24,9,group 3,post test,4,6,1,No,No,Is the accuracy of 95% enough for voice recognition? <please input your answer>,Recognition Accuracy. We first need a system to recognize speech when creating a voice-controlled personal assistant. The accuracy of speech recognition is very demanding. 95% is not good. 99% is good. A picture of The Telephone Game to show the importance of speech recongition accuracy.
5659bd11-66e6-472c-9f76-30b193af9583,test,past,elementary school,u24,9,group 3,post test,1,4,1,Speech recognition,Speech recognition,What is the first main component of a virtual assistant? <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
86dbb96e-7c76-411d-a22d-84f026fb03be,test,future,elementary school,u24,9,group 3,post test,8,15,0, ,Unfolding,What should we do when we want to train an RNN? <please input your answer>,"Training an RNN. Training an RNN by using backpropagation is more complicated than training an ANN with no loops. Unfolding: The loops are removed by duplicating parts of the neural network whenever they represent different parts of the sentence. After unfolding, we can train the RNN the way we train ANNs without loops. A picture illustrating the concept of unfolding."
e9aae120-e22c-43a1-8ca7-85934d25c357,test,future,elementary school,u24,9,group 3,post test,9,22,0, ,Long Short-Term Memory,What does LSTM stand for? <please input your answer>,Q&A. Lecture 9.
2fce5262-30e2-4330-90c0-536624ae00a0,test,past,elementary school,u24,9,group 3,post test,2,20,1,Speech generation,Speech generation,What is the last main component of a virtual assistant? <please input your answer>,Voice Synthesis. Voice Synthesis is the final stage of a voice-controlled personal assistant. Speech synthesis is accomplished using an RNN that converts a series of linguistic sounds into a series of spectrum. A picture of chat history of a human with a bot.
008541d5-bad7-43d8-8853-f6f0e40b2ded,test,future,elementary school,u24,9,group 3,post test,6,11,1,"(0,0,1,0,1)","(0,0,1,0,1)","Take five words {Cats, Dogs, bark, meow, eat} Take three sentences, “Dogs bark” “Cats eat” “Dogs eat” How to express the words after the “Dogs”? <please input your answer>","Words Representation. Method: finding out how often the word appears after which words and before which words by going through a huge data set. E.g. Words: {Cats, Dogs, Bark, Meow, Eat}. Phrases: {'Cats meow,' 'Dogs bark,' 'Cats eat,' 'Dogs eat'}. Result:'Cats' is often before 'meow' and 'eat', which can be expressed as (0,0,0,1,1). 'Cats' doesn’t often appear after any words, which can be expressed as (0,0,0,0,0). 'Cat” = (0,0,0,0,0, 0,0,0,1,1). A picture of a word cloud. A picture breaking down the grammar of an English sentence."
dac8a701-a53a-4bef-897f-9e08e109c077,test,past,elementary school,u24,9,group 3,post test,5,10,0, ,Assigning different neurons to different words,How are the words represented in an ANN? <please input your answer>,"How Should the Words be Represented in an ANN? Question: Why not type the words into a computer as a string of the alphabet for input? Assigning different neurons to different words. Then, add more information relating to each word: Represent a word with a group of words the original word is often used with. E.g. 'Cats' with 'meow' 'walk'. A picture of word cloud. A picture of a word connected to other words that it is related to."
a80ef118-d645-44b2-b1e2-506dd97595b4,test,future,elementary school,u24,9,group 3,post test,10,22,0, ,"The input, the short-term memory, and the output","Compared to regular RNN, LSTM has better control over its three components. What are they? <please input your answer>",Q&A. Lecture 9.
2b6ca9b5-bb93-46be-a4db-c5a8079320a6,test,future,elementary school,u24,9,group 3,post test,7,14,0, ,A loop,What does an RNN have that a simple three-layer neural network doesn’t have? <please input your answer>,Recurrent Neural Network. The network is called a Recurrent Neural Network (RNN) because it has a loop in the connection to feed the previous activations back to the input. This network receives one word at a time and is trained to generate an output each time using supervised learning with additional 'desired outputs'. Another usage: They can also be trained to represent phrases and sentences. A picture of RNN.
0d4b5530-b65b-4cd4-823c-4cdcf3f8abd3,test,past,high school,u62,6,group 1,post test,3,6,0,One-to-one connections,B,"In an ART network, the interface layer activates the category layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
c32e4f0c-2952-49a9-8ba1-fa4cd052e9ff,test,past,high school,u62,6,group 1,post test,4,3,1,clustering,cluster/classification,Please write another name for “grouping” in unsupervised learning. <please input your answer>,"Grouping. An unsupervised learning neural network can group similar inputs. Grouping is also called clustering classification or categorization. E.g., grouping images of cats and images of dogs. The picture contains an example of grouping."
1d90ccf9-5e48-41d4-9cd4-342197bc77ff,test,past,high school,u62,6,group 1,post test,1,6,1,Interface layer;Category layer,BC,"In an ART network, resonance is introduced to realize stable category formation. Resonance is established between which two layers? <please select the best answer> A. Input layer B. Interface layer C. Category layer",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
e58e55a1-198a-41dc-ac36-2de469945d23,test,future,high school,u62,6,group 1,post test,8,10,1,True,T,"True or False: The clustering of K-means is that for each sample point, find the closest center point to it. <please select the best answer> True or False",The process of k-means clustering. Step 2: For each sample point find the center point closest to it and the points closest to the same center point is a class. Thus completing a clustering. Closest to green! Closest to red! Closest to blue! It contains a picture of an example of step 2.
577b0b9e-3d38-4205-a5a3-4881771250b3,test,future,high school,u62,6,group 1,post test,9,12,1,False,F,"True or False: After each clustering, there is no need to recalculate the center points. <please select the best answer> True or False",The process of k-means clustering. Step 4: for the sample points in each category calculate the center point of these sample points as the new center points. Continue to step 2. It contains a picture of an example of step 4.
777c89e0-ddcf-40d1-90df-3303fccd9d87,test,past,high school,u62,6,group 1,post test,2,6,0,Full connections,A,"In an ART network, the input layer sends signals to the interface layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
80b0507b-dfbc-499d-9f89-d62959848c91,test,future,high school,u62,6,group 1,post test,6,16,1,Smaller,B,The unsupervised ANN that can compress usually has a middle layer that has a much ____ number of neurons. <please select the best answer> A. larger B. smaller,Unsupervised ANNs that compress. Unsupervised Work: gives the supervised ANNs inputs only ---teaching a supervised ANN to reproduce inputs. These networks usually have a middle layer that has a much smaller number of neurons making an hourglass-structure. It contains a picture of the structure of unsupervised ANNs.
2164d3ad-f505-4ced-bee6-255cd2c8985b,test,past,high school,u62,6,group 1,post test,5,4,1,Stephen Grossberg,B,Which person created Adaptive resonance theory1 (ART1)? <please select the best answer> A. David Hubel B. Stephen Grossberg C. Teuvo Kohonen,Adaptive resonance theory 1 (ART1). Adaptive resonance theory 1: an example of a neural network that performs grouping. Created by cognitive scientist Stephen Grossberg and mathematician Gail Carpenter. It contains a picture of Stephen.
39db380b-5b56-45f2-8df4-e6e3544c166b,test,future,high school,u62,6,group 1,post test,10,11,0,When a second sample k-center has the same values near it.,The categories of sample points before and after the clustering are the same,What is the end condition of the K-means algorithm? <please input your answer>,"The process of k-means clustering. Step 3: determine whether the categories of the samples points before and after the clustering are the same. If they are the same, the algorithm terminates. Otherwise, enter step 4. In this example the sample points before and after are different then we enter step 4. It contains a picture of an example of step 3."
62c102ce-3299-4825-bd03-6854f9efe21c,test,future,high school,u62,6,group 1,post test,7,9,1,False,F,True or False: The k center points are selected from sample points.<please select the best answer> True or False,"The process of k-means clustering. Step 1: select the number k of categories to be clustered and select k center points. E.g., k=3. The k center points are randomly selected on the plane. It contains a picture of an example of step 1."
0ee0865c-abd2-48d4-ab0c-ef2d330649db,train,past,high school,u63,6,group 1,post test,3,6,1,Full connections,B,"In an ART network, the interface layer activates the category layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
112770a6-7c08-4bdb-9866-37714b25b46a,train,past,high school,u63,6,group 1,post test,4,3,0,Clustering.,cluster/classification,Please write another name for “grouping” in unsupervised learning. <please input your answer>,"Grouping. An unsupervised learning neural network can group similar inputs. Grouping is also called clustering classification or categorization. E.g., grouping images of cats and images of dogs. The picture contains an example of grouping."
d564a334-30f3-490a-b4b9-4fc24bd8e87f,train,past,high school,u63,6,group 1,post test,1,6,1,Interface layer;Category layer,BC,"In an ART network, resonance is introduced to realize stable category formation. Resonance is established between which two layers? <please select the best answer> A. Input layer B. Interface layer C. Category layer",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
6dfe9fcf-835e-4623-88e8-7f2c2d912460,train,future,high school,u63,6,group 1,post test,8,10,1,True,T,"True or False: The clustering of K-means is that for each sample point, find the closest center point to it. <please select the best answer> True or False",The process of k-means clustering. Step 2: For each sample point find the center point closest to it and the points closest to the same center point is a class. Thus completing a clustering. Closest to green! Closest to red! Closest to blue! It contains a picture of an example of step 2.
17c8f8d5-2eff-4cf5-8add-95ab8a0174ad,train,future,high school,u63,6,group 1,post test,9,12,1,False,F,"True or False: After each clustering, there is no need to recalculate the center points. <please select the best answer> True or False",The process of k-means clustering. Step 4: for the sample points in each category calculate the center point of these sample points as the new center points. Continue to step 2. It contains a picture of an example of step 4.
d3c20c7c-d213-459b-8330-54725c022874,train,past,high school,u63,6,group 1,post test,2,6,1,One-to-one connections,A,"In an ART network, the input layer sends signals to the interface layer through ____. <please select the best answer> A. one-to-one connections B. full connections",Details about ART1. Input layer: sends signals to the interface layer through one-to-one connections. Interface layer: activates the category layer through full connections. Category layer: sends back activations to the interface layer through full connections. The interaction between the interface and category layer weights creates resonance. It contains a picture of the structure of ART1.
459efdc9-7440-4cc3-9375-1acfd669fc42,train,future,high school,u63,6,group 1,post test,6,16,1,Smaller,B,The unsupervised ANN that can compress usually has a middle layer that has a much ____ number of neurons. <please select the best answer> A. larger B. smaller,Unsupervised ANNs that compress. Unsupervised Work: gives the supervised ANNs inputs only ---teaching a supervised ANN to reproduce inputs. These networks usually have a middle layer that has a much smaller number of neurons making an hourglass-structure. It contains a picture of the structure of unsupervised ANNs.
ac00b581-eda8-4589-a53b-b5567be9d849,train,past,high school,u63,6,group 1,post test,5,4,1,Stephen Grossberg,B,Which person created Adaptive resonance theory1 (ART1)? <please select the best answer> A. David Hubel B. Stephen Grossberg C. Teuvo Kohonen,Adaptive resonance theory 1 (ART1). Adaptive resonance theory 1: an example of a neural network that performs grouping. Created by cognitive scientist Stephen Grossberg and mathematician Gail Carpenter. It contains a picture of Stephen.
d1127426-bf03-488d-bae6-59b8f20b7651,train,future,high school,u63,6,group 1,post test,10,11,0,"Once all the points are the same after previous clustering, the program will end.",The categories of sample points before and after the clustering are the same,What is the end condition of the K-means algorithm? <please input your answer>,"The process of k-means clustering. Step 3: determine whether the categories of the samples points before and after the clustering are the same. If they are the same, the algorithm terminates. Otherwise, enter step 4. In this example the sample points before and after are different then we enter step 4. It contains a picture of an example of step 3."
63aef1d2-d2de-434d-9ce3-030892c02dd2,train,future,high school,u63,6,group 1,post test,7,9,0,True,F,True or False: The k center points are selected from sample points.<please select the best answer> True or False,"The process of k-means clustering. Step 1: select the number k of categories to be clustered and select k center points. E.g., k=3. The k center points are randomly selected on the plane. It contains a picture of an example of step 1."
8666b322-599a-4b97-959b-5469969c30bd,train,past,high school,u64,10,group 1,post test,3,12,1,D,D,"To train a CNN that tells what is in a picture, what kind of pictures are needed? <please select the best answer> A. Pictures collected from the Internet without further information B. Pictures collected from the Internet with the data captured C. Images collected from the Internet with the geographic information D. Images collected from the Internet with category information","Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
43a3eddd-a378-426e-8ea5-d44ddacf1bc2,train,past,high school,u64,10,group 1,post test,4,14,1,B,B,What does the convolution layer do? <please select the best answer> A. It condenses the output of small regions into a single output B. It slides through the images and sums up the products of numbers C. It mimics the way neurons are only triggered by strong stimuli D. It tells what is in an image based on the information from hidden layers,"Convolution layer. The convolution layer is the core building block of the CNN. This layer performs a dot product (one-to-one) between two matrices (ordered numbers). One is the image, and the other is called kernel, mimicing the way human visual system works. A picture showing the computation process of convolution."
e196ce66-1d20-4fb4-a7e0-173db86f9da6,train,past,high school,u64,10,group 1,post test,1,8,1,A,A,Which of the following options comprises digital images stored in computers? <please select the best answer> A. Pixels B. Frames C. Videos,"Images are stored as pixels. When zooming in a picture real close, we find it is composed of mosaics. These small squares are pixels. We fill each pixel with color and then we get a picture! A picture showing the effect of zooming in a picture will get mosaics or pixels."
11085d81-f6f2-4267-be6e-65dd939f79dc,train,future,high school,u64,10,group 1,post test,8,15,1,1,1,"Recall the operations in a convolution layer. When given an image and a kernel as follows, what is the correct answer for the missing value 'x_1' in the output from the layer?. The image: [[1,1,1,1],[0,0,1,0],[0,1,0,0],[1,0,0,0]]. The kernel: [[0,1],[1,0]]. The output: [[x_1,1,2],[0,x_2,0],[2,0,0]] <please input your answer>","Convolution layer in animation and why we convolutes?Dr. Hubel and Dr. Wiesel found that some neurons fired very rapidly by watching the lines at specific angles, while other neurons responded best to the lines at different angles. The kernels (smaller matrix) are similar to the neurons: some produce larger output when given certain features like horizontal edges, while some respond to vertical edges. An animation of convolution computation."
926b4703-9d04-498d-bc5d-236b274148ed,train,future,high school,u64,10,group 1,post test,9,15,1,2,2,"Recall the operations in a convolution layer. When given an image and a kernel as follows, what is the correct answer for the missing value 'x_2' in the output from the layer?. The image: [[1,1,1,1],[0,0,1,0],[0,1,0,0],[1,0,0,0]]. The kernel: [[0,1],[1,0]]. The output: [[x_1,1,2],[0,x_2,0],[2,0,0]] <please input your answer>","Convolution layer in animation and why we convolutes?Dr. Hubel and Dr. Wiesel found that some neurons fired very rapidly by watching the lines at specific angles, while other neurons responded best to the lines at different angles. The kernels (smaller matrix) are similar to the neurons: some produce larger output when given certain features like horizontal edges, while some respond to vertical edges. An animation of convolution computation."
f69d71c5-a86d-4a9c-a001-9366a6ce2241,train,past,high school,u64,10,group 1,post test,2,9,1,D,D,"What are the three primary colors that computers use to represent other colors introduced in the lecture? <please select the best answer> A. Red, orange and yellow B. Red, green and purple C. Blue, orange and purple D. Red, green and blue","What exactly is stored in computer? Red, green and blue are three primary colors. When blend together, they can generate a full range of colors. The computer actually stores the colors of each pixel, and in our case, the value of red, green and blue. A picture showing RGB are the primary colors. A picture of a traffic sign and its corresponding pixel values representation."
1fcca5b9-32e8-4909-97e6-9dc4eb9b0678,train,future,high school,u64,10,group 1,post test,11,21,1,B,B,"If the correct category of an image is “train”, which of the following will be considered as correct under the definition of top-3 error? (From the left to the right, the probability of the answer decreases.) <please select the best answer> A. [“plane”, “motorcycle”, “bird”, “snake”, “train”] B. [“plane”, “motorcycle”, “train”, “bird”, “snake”] C. [“motorcycle”, “plane”, “snake”, “train”, “bird”] D. [“motorcycle”, “plane”, “car”, “bird”, “snake”]","AlexNet: A CNN model follows previous pattern. AlexNet won the 2012 ImageNet competition, where computers should tell what is in the picture, with a top-5 error rate of 15.3%, compared to the second place top-5 error rate of 26.2%. top-5 error: predicting 5 categories and if all are wrong, it counts as an error. A picture of AlexNet architecture. A bar graph of classification error rate vs different method groups"
cc5b6c54-3e65-400d-9769-fce59dd1b151,train,future,high school,u64,10,group 1,post test,6,17,1,C,C,"If we define a new kind of operation called leaky-ReLU, where values greater than 0 will remain unchanged, but values smaller than 0 will be replaced by 0.1 multiplies the original value. What will be the result if we apply to -10 and 5? <please select the best answer> A. -10, 0.5  B. -10, 5 C. 1, 5 D. -1, 0.5","ReLU, a math transformation. Rectified Linear Unit. output = input if input > 0, 0 otherwise. output = max(input, 0). Mimics the way how biological neurons are triggered! A picture of different numbers and their output after ReLU."
2e912ed9-4777-481c-86be-492bf1eb2bba,train,past,high school,u64,10,group 1,post test,5,17,1,C,C,"The output from a convolution layer is shown below. How many values will be changed after a ReLU layer is applied? The output from a convolution layer: 1, 7, 3, -2, -4, 5, 4, 1, 2. <please select the best answer> A. 0 B. 1 C. 2 D. 3","ReLU, a math transformation. Rectified Linear Unit. output = input if input > 0, 0 otherwise. output = max(input, 0). Mimics the way how biological neurons are triggered! A picture of different numbers and their output after ReLU."
b9aadebd-2765-4417-9147-a6db6d387d1b,train,future,high school,u64,10,group 1,post test,10,16,1,B,B,"Consider the original size of an image is 7 by 11. The size of the kernel to be applied is 3 by 3. If the stride is set to 2, what is the size of the output? <please select the best answer> A. 3 by 9 B. 3 by 5 C. 5 by 9 D. 5 by 5","Kernel size, stride and the output size. Formulas: Original size: W * H. Kernel size: K * K. Stride: S. W_old = 1 + (W-K)/S. H_old = 1 + (H-K)/S. A picture of a step in convolution."
627a4d08-ae72-4241-8863-bc255a87690e,train,future,high school,u64,10,group 1,post test,7,18,1,B,B,"The table below is a small region to apply a pooling operation. What is the correct result after max pooling? The region where max pooling is to be applied: 3,9,6,2. <please select the best answer> A. 10 B. 9 C. 6 D. 4",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
7594a128-8d36-4ddc-87ba-225702de73d8,train,past,high school,u65,10,group 1,post test,3,12,1,D,D,"To train a CNN that tells what is in a picture, what kind of pictures are needed? <please select the best answer> A. Pictures collected from the Internet without further information B. Pictures collected from the Internet with the data captured C. Images collected from the Internet with the geographic information D. Images collected from the Internet with category information","Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
ef34982f-7447-4084-aae4-90fc831e3573,train,past,high school,u65,10,group 1,post test,4,14,1,B,B,What does the convolution layer do? <please select the best answer> A. It condenses the output of small regions into a single output B. It slides through the images and sums up the products of numbers C. It mimics the way neurons are only triggered by strong stimuli D. It tells what is in an image based on the information from hidden layers,"Convolution layer. The convolution layer is the core building block of the CNN. This layer performs a dot product (one-to-one) between two matrices (ordered numbers). One is the image, and the other is called kernel, mimicing the way human visual system works. A picture showing the computation process of convolution."
2695b130-55d1-492d-8475-b222bb976cd3,train,past,high school,u65,10,group 1,post test,1,8,1,A,A,Which of the following options comprises digital images stored in computers? <please select the best answer> A. Pixels B. Frames C. Videos,"Images are stored as pixels. When zooming in a picture real close, we find it is composed of mosaics. These small squares are pixels. We fill each pixel with color and then we get a picture! A picture showing the effect of zooming in a picture will get mosaics or pixels."
ce9a5268-583c-4799-be7a-58003327acf2,train,future,high school,u65,10,group 1,post test,8,15,0,2,1,"Recall the operations in a convolution layer. When given an image and a kernel as follows, what is the correct answer for the missing value 'x_1' in the output from the layer?. The image: [[1,1,1,1],[0,0,1,0],[0,1,0,0],[1,0,0,0]]. The kernel: [[0,1],[1,0]]. The output: [[x_1,1,2],[0,x_2,0],[2,0,0]] <please input your answer>","Convolution layer in animation and why we convolutes?Dr. Hubel and Dr. Wiesel found that some neurons fired very rapidly by watching the lines at specific angles, while other neurons responded best to the lines at different angles. The kernels (smaller matrix) are similar to the neurons: some produce larger output when given certain features like horizontal edges, while some respond to vertical edges. An animation of convolution computation."
6805fb73-307b-4ce7-ad5d-f4a66dd670d1,train,future,high school,u65,10,group 1,post test,9,15,1,2,2,"Recall the operations in a convolution layer. When given an image and a kernel as follows, what is the correct answer for the missing value 'x_2' in the output from the layer?. The image: [[1,1,1,1],[0,0,1,0],[0,1,0,0],[1,0,0,0]]. The kernel: [[0,1],[1,0]]. The output: [[x_1,1,2],[0,x_2,0],[2,0,0]] <please input your answer>","Convolution layer in animation and why we convolutes?Dr. Hubel and Dr. Wiesel found that some neurons fired very rapidly by watching the lines at specific angles, while other neurons responded best to the lines at different angles. The kernels (smaller matrix) are similar to the neurons: some produce larger output when given certain features like horizontal edges, while some respond to vertical edges. An animation of convolution computation."
a685b537-400c-4c83-9d57-c8090dd50023,train,past,high school,u65,10,group 1,post test,2,9,1,D,D,"What are the three primary colors that computers use to represent other colors introduced in the lecture? <please select the best answer> A. Red, orange and yellow B. Red, green and purple C. Blue, orange and purple D. Red, green and blue","What exactly is stored in computer? Red, green and blue are three primary colors. When blend together, they can generate a full range of colors. The computer actually stores the colors of each pixel, and in our case, the value of red, green and blue. A picture showing RGB are the primary colors. A picture of a traffic sign and its corresponding pixel values representation."
d56df68e-8553-4f73-bb18-001d9f5e406c,train,future,high school,u65,10,group 1,post test,11,21,0,A,B,"If the correct category of an image is “train”, which of the following will be considered as correct under the definition of top-3 error? (From the left to the right, the probability of the answer decreases.) <please select the best answer> A. [“plane”, “motorcycle”, “bird”, “snake”, “train”] B. [“plane”, “motorcycle”, “train”, “bird”, “snake”] C. [“motorcycle”, “plane”, “snake”, “train”, “bird”] D. [“motorcycle”, “plane”, “car”, “bird”, “snake”]","AlexNet: A CNN model follows previous pattern. AlexNet won the 2012 ImageNet competition, where computers should tell what is in the picture, with a top-5 error rate of 15.3%, compared to the second place top-5 error rate of 26.2%. top-5 error: predicting 5 categories and if all are wrong, it counts as an error. A picture of AlexNet architecture. A bar graph of classification error rate vs different method groups"
030c8ba8-5925-4584-9a2d-d5dba5babed5,train,future,high school,u65,10,group 1,post test,6,17,1,C,C,"If we define a new kind of operation called leaky-ReLU, where values greater than 0 will remain unchanged, but values smaller than 0 will be replaced by 0.1 multiplies the original value. What will be the result if we apply to -10 and 5? <please select the best answer> A. -10, 0.5  B. -10, 5 C. 1, 5 D. -1, 0.5","ReLU, a math transformation. Rectified Linear Unit. output = input if input > 0, 0 otherwise. output = max(input, 0). Mimics the way how biological neurons are triggered! A picture of different numbers and their output after ReLU."
9dd4b225-3365-4152-83c1-cec340e36351,train,past,high school,u65,10,group 1,post test,5,17,0,D,C,"The output from a convolution layer is shown below. How many values will be changed after a ReLU layer is applied? The output from a convolution layer: 1, 7, 3, -2, -4, 5, 4, 1, 2. <please select the best answer> A. 0 B. 1 C. 2 D. 3","ReLU, a math transformation. Rectified Linear Unit. output = input if input > 0, 0 otherwise. output = max(input, 0). Mimics the way how biological neurons are triggered! A picture of different numbers and their output after ReLU."
23e60d72-5769-4a25-ac64-17cb9a5a81fb,train,future,high school,u65,10,group 1,post test,10,16,0,C,B,"Consider the original size of an image is 7 by 11. The size of the kernel to be applied is 3 by 3. If the stride is set to 2, what is the size of the output? <please select the best answer> A. 3 by 9 B. 3 by 5 C. 5 by 9 D. 5 by 5","Kernel size, stride and the output size. Formulas: Original size: W * H. Kernel size: K * K. Stride: S. W_old = 1 + (W-K)/S. H_old = 1 + (H-K)/S. A picture of a step in convolution."
e230dc08-8e5d-4421-8e14-dc6e082b7364,train,future,high school,u65,10,group 1,post test,7,18,0,A,B,"The table below is a small region to apply a pooling operation. What is the correct result after max pooling? The region where max pooling is to be applied: 3,9,6,2. <please select the best answer> A. 10 B. 9 C. 6 D. 4",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
4a25a0db-6fba-48ae-9a8e-abd0b7543fd1,test,past,high school,u66,10,group 1,post test,3,12,1,D,D,"To train a CNN that tells what is in a picture, what kind of pictures are needed? <please select the best answer> A. Pictures collected from the Internet without further information B. Pictures collected from the Internet with the data captured C. Images collected from the Internet with the geographic information D. Images collected from the Internet with category information","Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
4e550bdd-e873-4902-9d3f-a4eef6cacca5,test,past,high school,u66,10,group 1,post test,4,14,1,B,B,What does the convolution layer do? <please select the best answer> A. It condenses the output of small regions into a single output B. It slides through the images and sums up the products of numbers C. It mimics the way neurons are only triggered by strong stimuli D. It tells what is in an image based on the information from hidden layers,"Convolution layer. The convolution layer is the core building block of the CNN. This layer performs a dot product (one-to-one) between two matrices (ordered numbers). One is the image, and the other is called kernel, mimicing the way human visual system works. A picture showing the computation process of convolution."
45fef47a-591b-4c22-b376-37a25bce0aa0,test,past,high school,u66,10,group 1,post test,1,8,1,A,A,Which of the following options comprises digital images stored in computers? <please select the best answer> A. Pixels B. Frames C. Videos,"Images are stored as pixels. When zooming in a picture real close, we find it is composed of mosaics. These small squares are pixels. We fill each pixel with color and then we get a picture! A picture showing the effect of zooming in a picture will get mosaics or pixels."
40cad8c0-7398-400d-8bf1-c3129996c8c6,test,future,high school,u66,10,group 1,post test,8,15,1,1,1,"Recall the operations in a convolution layer. When given an image and a kernel as follows, what is the correct answer for the missing value 'x_1' in the output from the layer?. The image: [[1,1,1,1],[0,0,1,0],[0,1,0,0],[1,0,0,0]]. The kernel: [[0,1],[1,0]]. The output: [[x_1,1,2],[0,x_2,0],[2,0,0]] <please input your answer>","Convolution layer in animation and why we convolutes?Dr. Hubel and Dr. Wiesel found that some neurons fired very rapidly by watching the lines at specific angles, while other neurons responded best to the lines at different angles. The kernels (smaller matrix) are similar to the neurons: some produce larger output when given certain features like horizontal edges, while some respond to vertical edges. An animation of convolution computation."
416af01d-5aaf-4624-8fc7-434e6ef240cc,test,future,high school,u66,10,group 1,post test,9,15,1,2,2,"Recall the operations in a convolution layer. When given an image and a kernel as follows, what is the correct answer for the missing value 'x_2' in the output from the layer?. The image: [[1,1,1,1],[0,0,1,0],[0,1,0,0],[1,0,0,0]]. The kernel: [[0,1],[1,0]]. The output: [[x_1,1,2],[0,x_2,0],[2,0,0]] <please input your answer>","Convolution layer in animation and why we convolutes?Dr. Hubel and Dr. Wiesel found that some neurons fired very rapidly by watching the lines at specific angles, while other neurons responded best to the lines at different angles. The kernels (smaller matrix) are similar to the neurons: some produce larger output when given certain features like horizontal edges, while some respond to vertical edges. An animation of convolution computation."
9ff05c1c-eb38-467d-aaf5-dbff3715c119,test,past,high school,u66,10,group 1,post test,2,9,1,D,D,"What are the three primary colors that computers use to represent other colors introduced in the lecture? <please select the best answer> A. Red, orange and yellow B. Red, green and purple C. Blue, orange and purple D. Red, green and blue","What exactly is stored in computer? Red, green and blue are three primary colors. When blend together, they can generate a full range of colors. The computer actually stores the colors of each pixel, and in our case, the value of red, green and blue. A picture showing RGB are the primary colors. A picture of a traffic sign and its corresponding pixel values representation."
c4e3db13-b8fd-4f25-92fd-24d2a134fa26,test,future,high school,u66,10,group 1,post test,11,21,1,B,B,"If the correct category of an image is “train”, which of the following will be considered as correct under the definition of top-3 error? (From the left to the right, the probability of the answer decreases.) <please select the best answer> A. [“plane”, “motorcycle”, “bird”, “snake”, “train”] B. [“plane”, “motorcycle”, “train”, “bird”, “snake”] C. [“motorcycle”, “plane”, “snake”, “train”, “bird”] D. [“motorcycle”, “plane”, “car”, “bird”, “snake”]","AlexNet: A CNN model follows previous pattern. AlexNet won the 2012 ImageNet competition, where computers should tell what is in the picture, with a top-5 error rate of 15.3%, compared to the second place top-5 error rate of 26.2%. top-5 error: predicting 5 categories and if all are wrong, it counts as an error. A picture of AlexNet architecture. A bar graph of classification error rate vs different method groups"
7af5d76c-6954-4338-8d26-57a23d3defb0,test,future,high school,u66,10,group 1,post test,6,17,0,D,C,"If we define a new kind of operation called leaky-ReLU, where values greater than 0 will remain unchanged, but values smaller than 0 will be replaced by 0.1 multiplies the original value. What will be the result if we apply to -10 and 5? <please select the best answer> A. -10, 0.5  B. -10, 5 C. 1, 5 D. -1, 0.5","ReLU, a math transformation. Rectified Linear Unit. output = input if input > 0, 0 otherwise. output = max(input, 0). Mimics the way how biological neurons are triggered! A picture of different numbers and their output after ReLU."
cd3d2581-2f0b-4282-8c36-d69982237b91,test,past,high school,u66,10,group 1,post test,5,17,1,C,C,"The output from a convolution layer is shown below. How many values will be changed after a ReLU layer is applied? The output from a convolution layer: 1, 7, 3, -2, -4, 5, 4, 1, 2. <please select the best answer> A. 0 B. 1 C. 2 D. 3","ReLU, a math transformation. Rectified Linear Unit. output = input if input > 0, 0 otherwise. output = max(input, 0). Mimics the way how biological neurons are triggered! A picture of different numbers and their output after ReLU."
b8e152f5-a280-4b70-982f-57e5dc9ac178,test,future,high school,u66,10,group 1,post test,10,16,1,B,B,"Consider the original size of an image is 7 by 11. The size of the kernel to be applied is 3 by 3. If the stride is set to 2, what is the size of the output? <please select the best answer> A. 3 by 9 B. 3 by 5 C. 5 by 9 D. 5 by 5","Kernel size, stride and the output size. Formulas: Original size: W * H. Kernel size: K * K. Stride: S. W_old = 1 + (W-K)/S. H_old = 1 + (H-K)/S. A picture of a step in convolution."
01bb209a-f46d-489b-82bf-d8a00a478c07,test,future,high school,u66,10,group 1,post test,7,18,1,B,B,"The table below is a small region to apply a pooling operation. What is the correct result after max pooling? The region where max pooling is to be applied: 3,9,6,2. <please select the best answer> A. 10 B. 9 C. 6 D. 4",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
39a0fae0-d815-41ff-9599-ef831ec86c24,train,past,high school,u67,10,group 1,post test,3,12,0,C,D,"To train a CNN that tells what is in a picture, what kind of pictures are needed? <please select the best answer> A. Pictures collected from the Internet without further information B. Pictures collected from the Internet with the data captured C. Images collected from the Internet with the geographic information D. Images collected from the Internet with category information","Neural networks (CNN) learn from labelled images. The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. A picture showing labelled images as inputs to a CNN to let the CNN learn what are planes and what are automobiles."
db6cb9c1-e89d-4f68-bdeb-9de770f33640,train,past,high school,u67,10,group 1,post test,4,14,0,A,B,What does the convolution layer do? <please select the best answer> A. It condenses the output of small regions into a single output B. It slides through the images and sums up the products of numbers C. It mimics the way neurons are only triggered by strong stimuli D. It tells what is in an image based on the information from hidden layers,"Convolution layer. The convolution layer is the core building block of the CNN. This layer performs a dot product (one-to-one) between two matrices (ordered numbers). One is the image, and the other is called kernel, mimicing the way human visual system works. A picture showing the computation process of convolution."
5a9a690f-67bf-4e26-a80e-d0212e1b617c,train,past,high school,u67,10,group 1,post test,1,8,1,A,A,Which of the following options comprises digital images stored in computers? <please select the best answer> A. Pixels B. Frames C. Videos,"Images are stored as pixels. When zooming in a picture real close, we find it is composed of mosaics. These small squares are pixels. We fill each pixel with color and then we get a picture! A picture showing the effect of zooming in a picture will get mosaics or pixels."
86432da8-9b0d-438b-8876-3ed65d065b0e,train,future,high school,u67,10,group 1,post test,8,15,1,1,1,"Recall the operations in a convolution layer. When given an image and a kernel as follows, what is the correct answer for the missing value 'x_1' in the output from the layer?. The image: [[1,1,1,1],[0,0,1,0],[0,1,0,0],[1,0,0,0]]. The kernel: [[0,1],[1,0]]. The output: [[x_1,1,2],[0,x_2,0],[2,0,0]] <please input your answer>","Convolution layer in animation and why we convolutes?Dr. Hubel and Dr. Wiesel found that some neurons fired very rapidly by watching the lines at specific angles, while other neurons responded best to the lines at different angles. The kernels (smaller matrix) are similar to the neurons: some produce larger output when given certain features like horizontal edges, while some respond to vertical edges. An animation of convolution computation."
70b71a1a-fb91-4708-a7f9-a76d73011b14,train,future,high school,u67,10,group 1,post test,9,15,0,3,2,"Recall the operations in a convolution layer. When given an image and a kernel as follows, what is the correct answer for the missing value 'x_2' in the output from the layer?. The image: [[1,1,1,1],[0,0,1,0],[0,1,0,0],[1,0,0,0]]. The kernel: [[0,1],[1,0]]. The output: [[x_1,1,2],[0,x_2,0],[2,0,0]] <please input your answer>","Convolution layer in animation and why we convolutes?Dr. Hubel and Dr. Wiesel found that some neurons fired very rapidly by watching the lines at specific angles, while other neurons responded best to the lines at different angles. The kernels (smaller matrix) are similar to the neurons: some produce larger output when given certain features like horizontal edges, while some respond to vertical edges. An animation of convolution computation."
c82d40ea-c9d6-458c-9b97-17ad54700cfd,train,past,high school,u67,10,group 1,post test,2,9,1,D,D,"What are the three primary colors that computers use to represent other colors introduced in the lecture? <please select the best answer> A. Red, orange and yellow B. Red, green and purple C. Blue, orange and purple D. Red, green and blue","What exactly is stored in computer? Red, green and blue are three primary colors. When blend together, they can generate a full range of colors. The computer actually stores the colors of each pixel, and in our case, the value of red, green and blue. A picture showing RGB are the primary colors. A picture of a traffic sign and its corresponding pixel values representation."
40c0a20e-b010-4b13-93f1-3a2a9fb3a352,train,future,high school,u67,10,group 1,post test,11,21,0,C,B,"If the correct category of an image is “train”, which of the following will be considered as correct under the definition of top-3 error? (From the left to the right, the probability of the answer decreases.) <please select the best answer> A. [“plane”, “motorcycle”, “bird”, “snake”, “train”] B. [“plane”, “motorcycle”, “train”, “bird”, “snake”] C. [“motorcycle”, “plane”, “snake”, “train”, “bird”] D. [“motorcycle”, “plane”, “car”, “bird”, “snake”]","AlexNet: A CNN model follows previous pattern. AlexNet won the 2012 ImageNet competition, where computers should tell what is in the picture, with a top-5 error rate of 15.3%, compared to the second place top-5 error rate of 26.2%. top-5 error: predicting 5 categories and if all are wrong, it counts as an error. A picture of AlexNet architecture. A bar graph of classification error rate vs different method groups"
9974b4da-c673-4cdb-b04c-4e1a8a4c608a,train,future,high school,u67,10,group 1,post test,6,17,0,B,C,"If we define a new kind of operation called leaky-ReLU, where values greater than 0 will remain unchanged, but values smaller than 0 will be replaced by 0.1 multiplies the original value. What will be the result if we apply to -10 and 5? <please select the best answer> A. -10, 0.5  B. -10, 5 C. 1, 5 D. -1, 0.5","ReLU, a math transformation. Rectified Linear Unit. output = input if input > 0, 0 otherwise. output = max(input, 0). Mimics the way how biological neurons are triggered! A picture of different numbers and their output after ReLU."
1d916265-2857-4f8a-88e1-6dfc2444f29e,train,past,high school,u67,10,group 1,post test,5,17,1,C,C,"The output from a convolution layer is shown below. How many values will be changed after a ReLU layer is applied? The output from a convolution layer: 1, 7, 3, -2, -4, 5, 4, 1, 2. <please select the best answer> A. 0 B. 1 C. 2 D. 3","ReLU, a math transformation. Rectified Linear Unit. output = input if input > 0, 0 otherwise. output = max(input, 0). Mimics the way how biological neurons are triggered! A picture of different numbers and their output after ReLU."
d0938cd8-ecd0-4be9-a5e0-2edc24af43fb,train,future,high school,u67,10,group 1,post test,10,16,0,C,B,"Consider the original size of an image is 7 by 11. The size of the kernel to be applied is 3 by 3. If the stride is set to 2, what is the size of the output? <please select the best answer> A. 3 by 9 B. 3 by 5 C. 5 by 9 D. 5 by 5","Kernel size, stride and the output size. Formulas: Original size: W * H. Kernel size: K * K. Stride: S. W_old = 1 + (W-K)/S. H_old = 1 + (H-K)/S. A picture of a step in convolution."
067f1ceb-690e-4100-ab95-3dd72a1bb4b5,train,future,high school,u67,10,group 1,post test,7,18,0,C,B,"The table below is a small region to apply a pooling operation. What is the correct result after max pooling? The region where max pooling is to be applied: 3,9,6,2. <please select the best answer> A. 10 B. 9 C. 6 D. 4",Pooling layer. Pooling condense the output of small regions of neurons into a single output. This helps simplify the following layers and reduces the number of parameters that the model needs to learn. Max pooling: take the largest number (maximum) in the region. Average pooling: take the average of the numbers in the region. A picture showing max pooling and average pooling.
04dc2f4e-56f8-4db1-93cf-36c5162e5e2f,test,past,high school,u62,5,group 1,post test,3,16,0,1.00 / 1,A,"For an SOFM, if the input pattern is [0.2, -0.1, 0.3, 0.2, 0.91], the neuron with which weight has the largest activation? <please select the best answer> A. [0.2, 0.1, 0.3, 0.2, 0.91] B. [0.2, -0.1, 0.5, 0.2, 0.69] C. [-0.5, 0.5, 0.3, 0.2, -0.61]",How an SOFM learns. Step 1. Set the weights of each neuron (dots on the plane as the right figure shows) to small random values. E.g. [0.2 -0.1 0.5 0.2 0.69] [-0.5 0.5 0.3 0.2 -0.61] and so on. Step 2. All neurons get activated by a new input pattern. Compute the activations by taking the weighted sum of the input. E.g. if the input pattern is [0.2 -0.1 0.3 0.2 0.91] then the neuron with weight [0.2 -0.1 0.5 0.2 0.69]. Activation will be: 0.2*0.2 + (-0.1)*(-0.1) + 0.5*0.3 +0.2*0.2 +0.69*0.91 = 0.868. The picture contains an example of SOFM.
372c85ed-58f5-4ac7-bbec-c1c0bcba456d,test,past,high school,u62,5,group 1,post test,4,4,1,False,False,"True or false: 'In the application of unsupervised learning, unsupervised learning can determine what is illegal.' <please select the best answer> True or False",Other Application Scenarios. Unusual bank users found. Some people use bank accounts to commit illegal acts. It is difficult to find out these bank users through human analysis. Unsupervised learning helps us to quickly classify behaviors. We can quickly exclude normal users and conduct in-depth analysis of abnormal behaviors in a more targeted manner.
b593d06f-8358-44ba-b555-7b79d2afcde0,test,past,high school,u62,5,group 1,post test,1,3,1,Desired output,C,What is the data given during supervised learning but not in unsupervised learning? <please select the best answer> A. Input B. Connection weight C. Desirable output,Unsupervised learning. Supervised Learning: Requires a teacher to tell the ANN the correct answer. Unsupervised Learning: Learns by examples without the correct answer. E.g. ANNs are given images of apple and images of orange without being told what the fruit is. ANN learns to group them into apples and oranges. It contains a picture of an example of unsupervised learning.
83e7065e-72b8-4720-9d62-9eb9bd73ec1c,test,future,high school,u62,5,group 1,post test,8,11,0,It can do it by placing it at a same height in the map.,Similar inputs are placed in nearby locations.,How can an SOFM place similar inputs? <please input your answer>,"Self-Organizing Feature Map (SOFM). SOFM learns to create a neural map: Similar inputs are placed in nearby locations. Inputs presented more frequently occupy more areas. The more a specific type of input is seen, the more minute differences among the inputs belonging to that type are represented in the map. It contains a picture of SOFM."
ead752d8-d25d-4f3a-9fa2-fe7b9c07a228,test,future,high school,u62,5,group 1,post test,9,11,0,The map shrinks and becomes more specialized the more the input is given.,The corresponding area becomes larger.,"In an SOFM, what happens to the map if one kind of input is given more frequently than others? <please input your answer>","Self-Organizing Feature Map (SOFM). SOFM learns to create a neural map: Similar inputs are placed in nearby locations. Inputs presented more frequently occupy more areas. The more a specific type of input is seen, the more minute differences among the inputs belonging to that type are represented in the map. It contains a picture of SOFM."
d1afb971-3217-400f-a7e2-efd5b9779533,test,past,high school,u62,5,group 1,post test,2,7,1,Colors,A,"If the unsupervised ANNs that are given images of apples and images of oranges learn to group them into apples and oranges, which feature is useful? <please select the best answer> A. Colors B. Round C. Shiny","Features. Why this grouping is feasible? ---apples (oranges) are similar to each other. Features: Characteristics of the objects selected to make all the inputs widely different from each other. ANN has to pay attention to useful features! Useful (important): colors, textures. Unreliable: round, shiny."
05e3c624-6c31-454c-ba32-5ac275ca6769,test,future,high school,u62,5,group 1,post test,6,15,1,Shrink,A,"In the process of SOFM learning, how will the radius change? <please select the best answer> A. Shrink B. Expand","How an SOFM learns. SOFM learns by being exposed to input samples. Similar inputs activate nearby neurons, the neighborhood shrinks as the network learns more samples. The inputs are the same size: the sum of the squares of numbers in each input data is 1. E.g. (0.2 -0.1 0.5 0.2 0.69). The picture contains an example of SOFM."
d48fcee3-72b8-4281-b0b3-1d319801326e,test,past,high school,u62,5,group 1,post test,5,8,1,Color;Shape,AB,"In the process of using unsupervised learning to classify pictures of bananas and pictures of apples, which of the following features do you think is/are useful? Multiple answers can be chosen. <please select the answer> A. Color B. Shape C. Ear",Features. What should good features look like? The samples have to be quite different in this feature. E.g. color (useful) round (unreliable). The feature that is highly correlated with the target sample. E.g. color (useful) ear shape (unreliable).
21549451-b1ab-4152-811a-e5d95da2fc50,test,future,high school,u62,5,group 1,post test,10,12,0,Comparing the difference between people who pass and fail a test.,"Primary sensory area, or primary visual cortex",Please give an example of a self-organized structure. <please input your answer>,Example of Self-Organized Structure. Primary sensory area: Two-dimensional map of the body preserves the topology of the body similar to the map of an SOFM. The relative area size of each part of the body is determined by how much that part is used.
f9622819-9de4-43f3-bf43-7422644cf96d,test,future,high school,u62,5,group 1,post test,7,19,0,Because it will adjust the map according to the first weight you assigned it to.,The initial neighbor size will cover the entire plane.,"In the first step of the SOFM learning, why can we set the weight to be random without affecting the result? <please input your answer>","Some notes for SOFM. Initially the weights are random, the neighborhood covers the whole neural plane. The input weights to all neurons will be set to the average of all the input patterns. When the neighborhood area starts to shrink, some specialization of different areas occurs."
9a82ded8-55a9-4825-9ec9-16eadeb9122a,train,past,high school,u63,5,group 1,post test,3,16,0,0.00 / 1,A,"For an SOFM, if the input pattern is [0.2, -0.1, 0.3, 0.2, 0.91], the neuron with which weight has the largest activation? <please select the best answer> A. [0.2, 0.1, 0.3, 0.2, 0.91] B. [0.2, -0.1, 0.5, 0.2, 0.69] C. [-0.5, 0.5, 0.3, 0.2, -0.61]",How an SOFM learns. Step 1. Set the weights of each neuron (dots on the plane as the right figure shows) to small random values. E.g. [0.2 -0.1 0.5 0.2 0.69] [-0.5 0.5 0.3 0.2 -0.61] and so on. Step 2. All neurons get activated by a new input pattern. Compute the activations by taking the weighted sum of the input. E.g. if the input pattern is [0.2 -0.1 0.3 0.2 0.91] then the neuron with weight [0.2 -0.1 0.5 0.2 0.69]. Activation will be: 0.2*0.2 + (-0.1)*(-0.1) + 0.5*0.3 +0.2*0.2 +0.69*0.91 = 0.868. The picture contains an example of SOFM.
a5c02bdd-af9c-4be8-a310-52fb9735c3a6,train,past,high school,u63,5,group 1,post test,4,4,1,False,False,"True or false: 'In the application of unsupervised learning, unsupervised learning can determine what is illegal.' <please select the best answer> True or False",Other Application Scenarios. Unusual bank users found. Some people use bank accounts to commit illegal acts. It is difficult to find out these bank users through human analysis. Unsupervised learning helps us to quickly classify behaviors. We can quickly exclude normal users and conduct in-depth analysis of abnormal behaviors in a more targeted manner.
e351b0ba-750a-4a01-940d-787bf8f555f4,train,past,high school,u63,5,group 1,post test,1,3,1,Desired output,C,What is the data given during supervised learning but not in unsupervised learning? <please select the best answer> A. Input B. Connection weight C. Desirable output,Unsupervised learning. Supervised Learning: Requires a teacher to tell the ANN the correct answer. Unsupervised Learning: Learns by examples without the correct answer. E.g. ANNs are given images of apple and images of orange without being told what the fruit is. ANN learns to group them into apples and oranges. It contains a picture of an example of unsupervised learning.
92d95305-e722-480d-bbe2-515c66d69a83,train,future,high school,u63,5,group 1,post test,8,11,0,A SOFM can place similar inputs on a plane next to each other. ,Similar inputs are placed in nearby locations.,How can an SOFM place similar inputs? <please input your answer>,"Self-Organizing Feature Map (SOFM). SOFM learns to create a neural map: Similar inputs are placed in nearby locations. Inputs presented more frequently occupy more areas. The more a specific type of input is seen, the more minute differences among the inputs belonging to that type are represented in the map. It contains a picture of SOFM."
410862f9-7ea6-4db6-90bc-12ec8b567c6a,train,future,high school,u63,5,group 1,post test,9,11,0,That kind of input will take up more space on the map.,The corresponding area becomes larger.,"In an SOFM, what happens to the map if one kind of input is given more frequently than others? <please input your answer>","Self-Organizing Feature Map (SOFM). SOFM learns to create a neural map: Similar inputs are placed in nearby locations. Inputs presented more frequently occupy more areas. The more a specific type of input is seen, the more minute differences among the inputs belonging to that type are represented in the map. It contains a picture of SOFM."
36704a4e-bf36-4e93-bf4a-ecf509188f65,train,past,high school,u63,5,group 1,post test,2,7,1,Colors,A,"If the unsupervised ANNs that are given images of apples and images of oranges learn to group them into apples and oranges, which feature is useful? <please select the best answer> A. Colors B. Round C. Shiny","Features. Why this grouping is feasible? ---apples (oranges) are similar to each other. Features: Characteristics of the objects selected to make all the inputs widely different from each other. ANN has to pay attention to useful features! Useful (important): colors, textures. Unreliable: round, shiny."
7d3dc0b7-e049-44b3-836c-031eb38292c7,train,future,high school,u63,5,group 1,post test,6,15,1,Shrink,A,"In the process of SOFM learning, how will the radius change? <please select the best answer> A. Shrink B. Expand","How an SOFM learns. SOFM learns by being exposed to input samples. Similar inputs activate nearby neurons, the neighborhood shrinks as the network learns more samples. The inputs are the same size: the sum of the squares of numbers in each input data is 1. E.g. (0.2 -0.1 0.5 0.2 0.69). The picture contains an example of SOFM."
c1e66a14-bad9-4d75-8ed7-f39803822b0e,train,past,high school,u63,5,group 1,post test,5,8,1,Color;Shape,AB,"In the process of using unsupervised learning to classify pictures of bananas and pictures of apples, which of the following features do you think is/are useful? Multiple answers can be chosen. <please select the answer> A. Color B. Shape C. Ear",Features. What should good features look like? The samples have to be quite different in this feature. E.g. color (useful) round (unreliable). The feature that is highly correlated with the target sample. E.g. color (useful) ear shape (unreliable).
6b8ab774-3c2a-4d30-8173-c699517c4dc9,train,future,high school,u63,5,group 1,post test,10,12,0,The primary visual cortex is an example of a self-organized structure. ,"Primary sensory area, or primary visual cortex",Please give an example of a self-organized structure. <please input your answer>,Example of Self-Organized Structure. Primary sensory area: Two-dimensional map of the body preserves the topology of the body similar to the map of an SOFM. The relative area size of each part of the body is determined by how much that part is used.
b0e28601-583e-45f0-b2d0-ff2f439ce27a,train,future,high school,u63,5,group 1,post test,7,19,0,The weights can be random initially since the neighborhood covers all the neurons.,The initial neighbor size will cover the entire plane.,"In the first step of the SOFM learning, why can we set the weight to be random without affecting the result? <please input your answer>","Some notes for SOFM. Initially the weights are random, the neighborhood covers the whole neural plane. The input weights to all neurons will be set to the average of all the input patterns. When the neighborhood area starts to shrink, some specialization of different areas occurs."
50d0aaea-6838-4f2c-ae3c-cdb020c8c045,train,past,high school,u63,4,group 1,post test,3,6,0,Outlook;Temperature;Wind,AB,"In this form below, which features can we select to decide whether people enjoy tennis? <please select the best answer> A. Outlook B. Temperature C. Humidity D. Wind; Form: table of features and tennis enjoyment",More details of a decision tree. In the prediction a certain attribute is used to make a judgment at the internal nodes of the tree. According to the judgment result which branch to enter is decided. When it reaches the leaf node the classification result is obtained. It contains a picture of the decision tree.
d0ec2e31-e028-4821-992c-4529ea3c02d5,train,past,high school,u63,4,group 1,post test,4,13,1,We should classify a new example based on which point it is closest to. ,Label x with the label of the closest example to x,"In the I-Nearest-Neighbor method, how should we classify a new example? <please input your answer>",I-Nearest-Neighbor (1NN). To classify a new example x: Label x with the label of the closest example to x in the training set. Closest to red class. Euclidean Distance. It contains a picture of 1NN.
8bdb279e-258e-4ec0-b99d-29a6593f281f,train,past,high school,u63,4,group 1,post test,1,3,1,Physical characteristics,features,"What do humans use to classify objects, for instance, pictures of fruits? <please input your answer>",How do humans classify. Humans use objects’ characteristics to classify objects resulting in the label of objects.
304efce0-21d9-4d10-818a-c31ad538ad60,train,past,high school,u63,4,group 1,post test,2,5,1,"Leaf node, Classes, and Internal nodes. The internal nodes in this tree are the outlook, wind, and humidity. The leaf nodes are sunny, overcast, and rain. ","Internal node, branch, leaf node (Internal node: Outlook, Humidity, Wind Branch: Sunny, Overcast... Leaf node: Yes, No)","The picture below shows a decision tree, please list three kinds of elements of a decision tree? And please give examples of each node type in this decision tree? Picture: decision tree of weather. <please input your answer>",The structure of a decision tree. Internal node. Branch. Leaf node. It contains a picture of the structure of a decision tree.
ade96780-d7b6-4607-b1fe-2b32fd1a57c3,train,future,high school,u63,4,group 1,post test,6,18,1,"As K increases from 1, the decision boundary will get smoother and will not be as cluttered. If K is too small, the clusters will have a lot of noise. If K is too large, there will be many wrong labels.",K is too small: overfit K is too big: underfit,Please describe how the effect of the KNN algorithm changes as k increases from 1. What kind of problems will occur when K is too small and when K is too large? <please input your answer>,The Effect of K. Choose best k on the validation set. (Often set k as an odd number). It contains a graph of choosing the best k.
baa96ffc-bcf2-4bd2-beea-f16d992d8b48,train,past,high school,u63,4,group 1,post test,5,14,1,Red,A,"In this image about the process of KNN algorithm, which cluster should Xj be classified to? <please select the best answer> A. Red B. Green C. Blue; Image: KNN algorithm graph",K-Nearest-Neighbors (KNN). x is closest to a red point. But most of the next closest points are blue. If we only consider the closest point the result won’t be accurate enough. It contains a picture of KNN.
1708adef-27b2-4937-a34f-7aaf520f51a3,test,past,high school,u62,4,group 1,post test,3,6,0,Outlook;Wind,AB,"In this form below, which features can we select to decide whether people enjoy tennis? <please select the best answer> A. Outlook B. Temperature C. Humidity D. Wind; Form: table of features and tennis enjoyment",More details of a decision tree. In the prediction a certain attribute is used to make a judgment at the internal nodes of the tree. According to the judgment result which branch to enter is decided. When it reaches the leaf node the classification result is obtained. It contains a picture of the decision tree.
ea4114e2-8e42-497e-ac99-2daecab278b1,test,past,high school,u62,4,group 1,post test,4,13,1,Find a property that's closest to one thing.,Label x with the label of the closest example to x,"In the I-Nearest-Neighbor method, how should we classify a new example? <please input your answer>",I-Nearest-Neighbor (1NN). To classify a new example x: Label x with the label of the closest example to x in the training set. Closest to red class. Euclidean Distance. It contains a picture of 1NN.
ce66bc23-150e-4efc-a971-b8e336e0bca7,test,past,high school,u62,4,group 1,post test,1,3,1,properties.,features,"What do humans use to classify objects, for instance, pictures of fruits? <please input your answer>",How do humans classify. Humans use objects’ characteristics to classify objects resulting in the label of objects.
2720b579-a968-497d-8c0b-8df107ac041a,test,past,high school,u62,4,group 1,post test,2,5,1,"outlook, humidity, wind. Outlook: Overcast, Humidity: normal, Wind: strong","Internal node, branch, leaf node (Internal node: Outlook, Humidity, Wind Branch: Sunny, Overcast... Leaf node: Yes, No)","The picture below shows a decision tree, please list three kinds of elements of a decision tree? And please give examples of each node type in this decision tree? Picture: decision tree of weather. <please input your answer>",The structure of a decision tree. Internal node. Branch. Leaf node. It contains a picture of the structure of a decision tree.
ac01e2bd-59e3-47c6-929e-b4e01e3d8184,test,future,high school,u62,4,group 1,post test,6,18,1,"The property is farther away from another object. If it's too small or large, the computer cannot tell which property has the majority of objects because it's too close or too far away from the property.",K is too small: overfit K is too big: underfit,Please describe how the effect of the KNN algorithm changes as k increases from 1. What kind of problems will occur when K is too small and when K is too large? <please input your answer>,The Effect of K. Choose best k on the validation set. (Often set k as an odd number). It contains a graph of choosing the best k.
9b8c038d-29a5-48d7-893f-dc3c37ad5eb1,test,past,high school,u62,4,group 1,post test,5,14,1,Red,A,"In this image about the process of KNN algorithm, which cluster should Xj be classified to? <please select the best answer> A. Red B. Green C. Blue; Image: KNN algorithm graph",K-Nearest-Neighbors (KNN). x is closest to a red point. But most of the next closest points are blue. If we only consider the closest point the result won’t be accurate enough. It contains a picture of KNN.
878d43fe-b35e-4d79-a5fe-ea90a6b9ba74,train,past,high school,u68,4,group 1,post test,3,6,0,Outlook,AB,"In this form below, which features can we select to decide whether people enjoy tennis? <please select the best answer> A. Outlook B. Temperature C. Humidity D. Wind; Form: table of features and tennis enjoyment",More details of a decision tree. In the prediction a certain attribute is used to make a judgment at the internal nodes of the tree. According to the judgment result which branch to enter is decided. When it reaches the leaf node the classification result is obtained. It contains a picture of the decision tree.
c68e21f2-180a-4ad5-b74e-48626e7674c9,train,past,high school,u68,4,group 1,post test,4,13,1,closer points in feature space have similar semantics,Label x with the label of the closest example to x,"In the I-Nearest-Neighbor method, how should we classify a new example? <please input your answer>",I-Nearest-Neighbor (1NN). To classify a new example x: Label x with the label of the closest example to x in the training set. Closest to red class. Euclidean Distance. It contains a picture of 1NN.
20d1e600-b1f4-4c85-99a6-567b1aaa6c54,train,past,high school,u68,4,group 1,post test,1,3,1,"Decision tree: based on characteristics of the fruits (color, shape, taste, etc.), humans will classify and label the fruits",features,"What do humans use to classify objects, for instance, pictures of fruits? <please input your answer>",How do humans classify. Humans use objects’ characteristics to classify objects resulting in the label of objects.
fc7c19e4-1a47-42cd-88dc-0b79a8ae80ce,train,past,high school,u68,4,group 1,post test,2,5,1,"internal node, branch, leaf node; internal node here is attribute (humidity, wind), and leaf node is the classification of each branch (yes or no depending on humidity and wind)","Internal node, branch, leaf node (Internal node: Outlook, Humidity, Wind Branch: Sunny, Overcast... Leaf node: Yes, No)","The picture below shows a decision tree, please list three kinds of elements of a decision tree? And please give examples of each node type in this decision tree? Picture: decision tree of weather. <please input your answer>",The structure of a decision tree. Internal node. Branch. Leaf node. It contains a picture of the structure of a decision tree.
a22ae88c-f782-4bad-920e-9f9fe5b2c29d,train,future,high school,u68,4,group 1,post test,6,18,1,"Increasing K simplified the decision boundary, meaning less emphasis on individual points. When k is too small, noise increases, which affects the decision.",K is too small: overfit K is too big: underfit,Please describe how the effect of the KNN algorithm changes as k increases from 1. What kind of problems will occur when K is too small and when K is too large? <please input your answer>,The Effect of K. Choose best k on the validation set. (Often set k as an odd number). It contains a graph of choosing the best k.
328658cc-f989-46c2-83fc-c79c826930c9,train,past,high school,u68,4,group 1,post test,5,14,1,Red,A,"In this image about the process of KNN algorithm, which cluster should Xj be classified to? <please select the best answer> A. Red B. Green C. Blue; Image: KNN algorithm graph",K-Nearest-Neighbors (KNN). x is closest to a red point. But most of the next closest points are blue. If we only consider the closest point the result won’t be accurate enough. It contains a picture of KNN.
4d2e968a-86f9-4ba6-82ff-8bf43e2eec33,test,past,high school,u69,4,group 2,post test,3,6,0,Outlook,AB,"In this form below, which features can we select to decide whether people enjoy tennis? <please select the best answer> A. Outlook B. Temperature C. Humidity D. Wind; Form: table of features and tennis enjoyment",More details of a decision tree. In the prediction a certain attribute is used to make a judgment at the internal nodes of the tree. According to the judgment result which branch to enter is decided. When it reaches the leaf node the classification result is obtained. It contains a picture of the decision tree.
32f368fd-18a5-4ec0-ba31-662459e373f6,test,past,high school,u69,4,group 2,post test,4,13,0,By finding the closest neighbor,Label x with the label of the closest example to x,"In the I-Nearest-Neighbor method, how should we classify a new example? <please input your answer>",I-Nearest-Neighbor (1NN). To classify a new example x: Label x with the label of the closest example to x in the training set. Closest to red class. Euclidean Distance. It contains a picture of 1NN.
2d8ec7ad-346f-4136-b690-397fddc1f990,test,past,high school,u69,4,group 2,post test,1,3,0,decision trees?,features,"What do humans use to classify objects, for instance, pictures of fruits? <please input your answer>",How do humans classify. Humans use objects’ characteristics to classify objects resulting in the label of objects.
df117e3c-1fcc-4f7d-ac1a-f6fcc52fc0fb,test,past,high school,u69,4,group 2,post test,2,5,1,"Internal node(humidity),branch(sunny), leaf node (no)","Internal node, branch, leaf node (Internal node: Outlook, Humidity, Wind Branch: Sunny, Overcast... Leaf node: Yes, No)","The picture below shows a decision tree, please list three kinds of elements of a decision tree? And please give examples of each node type in this decision tree? Picture: decision tree of weather. <please input your answer>",The structure of a decision tree. Internal node. Branch. Leaf node. It contains a picture of the structure of a decision tree.
c3d54826-5675-41c6-b222-d96bc4328462,test,future,high school,u69,4,group 2,post test,6,18,1,"it gets more accurate until a certain point, then the error pecentage starts getting larger",K is too small: overfit K is too big: underfit,Please describe how the effect of the KNN algorithm changes as k increases from 1. What kind of problems will occur when K is too small and when K is too large? <please input your answer>,The Effect of K. Choose best k on the validation set. (Often set k as an odd number). It contains a graph of choosing the best k.
e32c4578-9c82-4886-9913-89691630105d,test,past,high school,u69,4,group 2,post test,5,14,1,Red,A,"In this image about the process of KNN algorithm, which cluster should Xj be classified to? <please select the best answer> A. Red B. Green C. Blue; Image: KNN algorithm graph",K-Nearest-Neighbors (KNN). x is closest to a red point. But most of the next closest points are blue. If we only consider the closest point the result won’t be accurate enough. It contains a picture of KNN.
0762a678-88ad-4dd8-bd46-527384f7267f,train,past,high school,u64,12,group 1,post test,3,7,0,A,B,Which one of the following methods is suitable for robots that work on Mars to achieve autonomousness? <please select the best answer> A. Spike neural networks B. Q-learning C. K-nearest neighbors D. Recurrent neural networks,"Usage in dangerous situations. Situations human want to avoid: Old minefields, automobile factories, other planets... AI can make machines in these situations more autonomous and useful. A picture of Curious, a robot that was sent to Mars."
72ee6b9f-3d93-4a5d-ab68-a9a98e56cb4a,train,past,high school,u64,12,group 1,post test,4,9,0,not sure,We should read with caution because a fair amount of hype is often involved,What should we notice when we are faced with AI-related news? <please input your answer>,"Summary. The real-world aplication using AI have just begun, and AI technology hasn’t fully matured and been tested. AI-related news should be read with caution. A picture of a robot."
cebf3656-b792-4df9-8066-9418b1b6a542,train,past,high school,u64,12,group 1,post test,1,4,0,D,C,"To help biologists to understand the vast amount of data, AI can generate a knowledge graph. Which is a helpful scheme to build such knowledge? <please select the best answer> A. Reinforcement learning B. Supervised learning C. Unsupervised learning D. Few-shot learning","Medicine. finding new drugs. medical diagnoses. With the vast knowledge of paintents , and chemical sturctures sotred in databases, AI system can search for potentially effective treatments more quickly than human experts can. A video about AI usage in medicine."
a51708de-7124-4945-9608-a078373fc365,train,future,high school,u64,12,group 1,post test,8,15,1,D,D,Which of the following best describes artificial general intelligence (AGI)? <please select the best answer> A. Computer programs that experience sentience or consciousness. B. Any program that is designed to solve exactly one problem. C. A computer agent with the ability to sense and the ability to act. D. An intelligent agent to learn any task that a human being can.,"Artificial general intelligence (AGI). AGI is a generic, human-like intelligence that can tackle problems by developing and applying general congnitive abilities across different areas. Many people think that the progress in AI will be made only by tackling specific problems, not by trying to advance machine intelligence in general. A picture of a robot trying to solve complex math/physics problems."
8a2ef1c6-16c9-4752-a869-1c2e21281a14,train,future,high school,u64,12,group 1,post test,9,13,1,consider the spike timings rather than just spike frequency,Spike neurons take as input spikes while tradition neurons take as input continuous value,What is the most significant difference between spike neural networks and traditional neural networks? <please input your answer>,"Supporting hardware. Spiking neural networks: They consider the spike timings rather than just the spiking frequency, which is an important feature of biological neural networls. An animation demonstrating spiking neural networks."
28549642-d4b9-4c14-abe4-44db83cb8076,train,past,high school,u64,12,group 1,post test,2,5,1,C,C,"Considering the given example, which one of the following opinions correctly describes the entity and related information? Example: SpaceX is an aerospace manufacturer and space transport services company headquartered in California. It was founded in 2002 by entrepreneur and investor Elon Musk with the goal of reducing space transportation costs and enabling the colonization of Mars. <please select the best answer> A. Entrepreneur (“Elon Musk”, “SpaceX”, “California”) B. Entrepreneur (“Elon Musk”, “California”, “2002”) C. Company (“SpaceX”, “California”, “Elon Musk”) D. Company (“SpaceX”, “Mars”, “Elon Musk”)","Natural language application. machine translation. natural language interfaces. AI systems extract knowledge from natural language texts. E.g., Q: The headquarters of BHP Billiton Limited, and the global headquarters of the combined BHP Billiton Group, are located in Melbourne, Australia. A: headquarters('“'BHP Biliton Limited', 'Melbourne, Australia') A cartoon picture showing that."
4f9c3900-36a9-4ee2-80b7-229b7b2f9198,train,future,high school,u64,12,group 1,post test,6,14,1,"qubits can represent numbers at the same time, allowing them to consider many possible combinations simultaneously",Qubits can represent combinations simultaneously.,Why do quantum computers outperform existing traditional computers in problems related to a large number of combinations? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
45a09300-c6bd-41fd-9104-91b4d56761ce,train,past,high school,u64,12,group 1,post test,5,14,1,qubits,Quantum bit/Qubit,What is the basic unit of memory in quantum computers? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
514cb48a-1349-4975-a3b7-867bd87a3dc1,train,future,high school,u64,12,group 1,post test,10,19,0,D,B,"Which of the following descriptions about developing AI with caution is incorrect? <please select the best answer> A. Autonomous driving has safety issues related to the measurement of doing well and liability. B. With more sensitive sensors and more autonomous control, robots are sure to have personalities and consciousness at some point. C. Stephen Hawking, Elon Musk and Bill Gates have warned that AI may spell the end to human intelligence. D. We should be smart enough to use AI and wise enough to plan our future so that using AI will enrich our lives.","Ethical issues. If AI are developed with more sensitive sensors and more autonomous control, will robots, at some point, start to have personalities and consciousness? Should we worry about respecting their opinions or their will for existence? A picture of 2 robots."
1e3451dc-fc1e-4e72-ae67-5703f99cdc03,train,future,high school,u64,12,group 1,post test,7,11,1,takes a long time to perform more extensive research on the human brain,We must do more research on the human brain side,What is the reason that development in brain-AI communication takes a long time? <please input your answer>,Integrate with our brains. We expect our brains will be able to communicate with AI through implanted electrodes to expand out cognitive capabilities. Development in this direction may take many years because we must do more research on the human brain side. A picture of a human brain but it's digital.
3019fd7c-bd9a-4929-87c4-3f53004e7653,train,past,high school,u65,12,group 1,post test,3,7,0,A,B,Which one of the following methods is suitable for robots that work on Mars to achieve autonomousness? <please select the best answer> A. Spike neural networks B. Q-learning C. K-nearest neighbors D. Recurrent neural networks,"Usage in dangerous situations. Situations human want to avoid: Old minefields, automobile factories, other planets... AI can make machines in these situations more autonomous and useful. A picture of Curious, a robot that was sent to Mars."
a36b4a8e-1749-4608-a600-5d18594e622b,train,past,high school,u65,12,group 1,post test,4,9,1,Sometimes it's misleading,We should read with caution because a fair amount of hype is often involved,What should we notice when we are faced with AI-related news? <please input your answer>,"Summary. The real-world aplication using AI have just begun, and AI technology hasn’t fully matured and been tested. AI-related news should be read with caution. A picture of a robot."
0cb01655-b3eb-453b-b8e1-a00b2d38cf04,train,past,high school,u65,12,group 1,post test,1,4,0,D,C,"To help biologists to understand the vast amount of data, AI can generate a knowledge graph. Which is a helpful scheme to build such knowledge? <please select the best answer> A. Reinforcement learning B. Supervised learning C. Unsupervised learning D. Few-shot learning","Medicine. finding new drugs. medical diagnoses. With the vast knowledge of paintents , and chemical sturctures sotred in databases, AI system can search for potentially effective treatments more quickly than human experts can. A video about AI usage in medicine."
1470b864-254f-4f74-8ba2-2eab5c3de039,train,future,high school,u65,12,group 1,post test,8,15,0,A,D,Which of the following best describes artificial general intelligence (AGI)? <please select the best answer> A. Computer programs that experience sentience or consciousness. B. Any program that is designed to solve exactly one problem. C. A computer agent with the ability to sense and the ability to act. D. An intelligent agent to learn any task that a human being can.,"Artificial general intelligence (AGI). AGI is a generic, human-like intelligence that can tackle problems by developing and applying general congnitive abilities across different areas. Many people think that the progress in AI will be made only by tackling specific problems, not by trying to advance machine intelligence in general. A picture of a robot trying to solve complex math/physics problems."
739484f7-4a54-4bcd-b16e-2f03378f8157,train,future,high school,u65,12,group 1,post test,9,13,0,I don't know,Spike neurons take as input spikes while tradition neurons take as input continuous value,What is the most significant difference between spike neural networks and traditional neural networks? <please input your answer>,"Supporting hardware. Spiking neural networks: They consider the spike timings rather than just the spiking frequency, which is an important feature of biological neural networls. An animation demonstrating spiking neural networks."
7e22efaa-f2fb-4340-be81-0d9d47f73a18,train,past,high school,u65,12,group 1,post test,2,5,1,C,C,"Considering the given example, which one of the following opinions correctly describes the entity and related information? Example: SpaceX is an aerospace manufacturer and space transport services company headquartered in California. It was founded in 2002 by entrepreneur and investor Elon Musk with the goal of reducing space transportation costs and enabling the colonization of Mars. <please select the best answer> A. Entrepreneur (“Elon Musk”, “SpaceX”, “California”) B. Entrepreneur (“Elon Musk”, “California”, “2002”) C. Company (“SpaceX”, “California”, “Elon Musk”) D. Company (“SpaceX”, “Mars”, “Elon Musk”)","Natural language application. machine translation. natural language interfaces. AI systems extract knowledge from natural language texts. E.g., Q: The headquarters of BHP Billiton Limited, and the global headquarters of the combined BHP Billiton Group, are located in Melbourne, Australia. A: headquarters('“'BHP Biliton Limited', 'Melbourne, Australia') A cartoon picture showing that."
d220a913-92ee-4b2e-9067-d19ce4f227a0,train,future,high school,u65,12,group 1,post test,6,14,1,The qubits can represent multiple values at the same time,Qubits can represent combinations simultaneously.,Why do quantum computers outperform existing traditional computers in problems related to a large number of combinations? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
e2256b57-32a5-463d-84b8-538bd71d4bc9,train,past,high school,u65,12,group 1,post test,5,14,1,Qubits,Quantum bit/Qubit,What is the basic unit of memory in quantum computers? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
c3b5404d-3b7c-4028-b152-d89d89060131,train,future,high school,u65,12,group 1,post test,10,19,1,B,B,"Which of the following descriptions about developing AI with caution is incorrect? <please select the best answer> A. Autonomous driving has safety issues related to the measurement of doing well and liability. B. With more sensitive sensors and more autonomous control, robots are sure to have personalities and consciousness at some point. C. Stephen Hawking, Elon Musk and Bill Gates have warned that AI may spell the end to human intelligence. D. We should be smart enough to use AI and wise enough to plan our future so that using AI will enrich our lives.","Ethical issues. If AI are developed with more sensitive sensors and more autonomous control, will robots, at some point, start to have personalities and consciousness? Should we worry about respecting their opinions or their will for existence? A picture of 2 robots."
26c055d3-c2dd-4c85-a37e-0173cc4803bf,train,future,high school,u65,12,group 1,post test,7,11,0,It's complicated,We must do more research on the human brain side,What is the reason that development in brain-AI communication takes a long time? <please input your answer>,Integrate with our brains. We expect our brains will be able to communicate with AI through implanted electrodes to expand out cognitive capabilities. Development in this direction may take many years because we must do more research on the human brain side. A picture of a human brain but it's digital.
96f85551-2655-42ff-92c4-1a109b9c447b,test,past,high school,u66,12,group 1,post test,3,7,1,B,B,Which one of the following methods is suitable for robots that work on Mars to achieve autonomousness? <please select the best answer> A. Spike neural networks B. Q-learning C. K-nearest neighbors D. Recurrent neural networks,"Usage in dangerous situations. Situations human want to avoid: Old minefields, automobile factories, other planets... AI can make machines in these situations more autonomous and useful. A picture of Curious, a robot that was sent to Mars."
08b4de01-3b02-4e92-8f20-e4e71394ff89,test,past,high school,u66,12,group 1,post test,4,9,1,We should notice how it can benefit us and how to use it wisely. ,We should read with caution because a fair amount of hype is often involved,What should we notice when we are faced with AI-related news? <please input your answer>,"Summary. The real-world aplication using AI have just begun, and AI technology hasn’t fully matured and been tested. AI-related news should be read with caution. A picture of a robot."
3a8adb5c-7299-4079-a4aa-26356c7bed99,test,past,high school,u66,12,group 1,post test,1,4,1,C,C,"To help biologists to understand the vast amount of data, AI can generate a knowledge graph. Which is a helpful scheme to build such knowledge? <please select the best answer> A. Reinforcement learning B. Supervised learning C. Unsupervised learning D. Few-shot learning","Medicine. finding new drugs. medical diagnoses. With the vast knowledge of paintents , and chemical sturctures sotred in databases, AI system can search for potentially effective treatments more quickly than human experts can. A video about AI usage in medicine."
cf168095-55b8-46ca-ad15-409aa942ef62,test,future,high school,u66,12,group 1,post test,8,15,1,D,D,Which of the following best describes artificial general intelligence (AGI)? <please select the best answer> A. Computer programs that experience sentience or consciousness. B. Any program that is designed to solve exactly one problem. C. A computer agent with the ability to sense and the ability to act. D. An intelligent agent to learn any task that a human being can.,"Artificial general intelligence (AGI). AGI is a generic, human-like intelligence that can tackle problems by developing and applying general congnitive abilities across different areas. Many people think that the progress in AI will be made only by tackling specific problems, not by trying to advance machine intelligence in general. A picture of a robot trying to solve complex math/physics problems."
b8caed75-bb6c-4872-9ddf-854d384767e0,test,future,high school,u66,12,group 1,post test,9,13,1,Spike neural networks take in consideration the timing of spikes. ,Spike neurons take as input spikes while tradition neurons take as input continuous value,What is the most significant difference between spike neural networks and traditional neural networks? <please input your answer>,"Supporting hardware. Spiking neural networks: They consider the spike timings rather than just the spiking frequency, which is an important feature of biological neural networls. An animation demonstrating spiking neural networks."
2cdbbaca-0c36-432c-9838-4ae64b6b252a,test,past,high school,u66,12,group 1,post test,2,5,1,C,C,"Considering the given example, which one of the following opinions correctly describes the entity and related information? Example: SpaceX is an aerospace manufacturer and space transport services company headquartered in California. It was founded in 2002 by entrepreneur and investor Elon Musk with the goal of reducing space transportation costs and enabling the colonization of Mars. <please select the best answer> A. Entrepreneur (“Elon Musk”, “SpaceX”, “California”) B. Entrepreneur (“Elon Musk”, “California”, “2002”) C. Company (“SpaceX”, “California”, “Elon Musk”) D. Company (“SpaceX”, “Mars”, “Elon Musk”)","Natural language application. machine translation. natural language interfaces. AI systems extract knowledge from natural language texts. E.g., Q: The headquarters of BHP Billiton Limited, and the global headquarters of the combined BHP Billiton Group, are located in Melbourne, Australia. A: headquarters('“'BHP Biliton Limited', 'Melbourne, Australia') A cartoon picture showing that."
3377a4da-e2d1-4c77-836c-9786d227be33,test,future,high school,u66,12,group 1,post test,6,14,1,Quantum computers can look at a lot more combinations at once. ,Qubits can represent combinations simultaneously.,Why do quantum computers outperform existing traditional computers in problems related to a large number of combinations? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
0a83f6aa-054c-4bbf-ba76-34917854fbf2,test,past,high school,u66,12,group 1,post test,5,14,1,Qubit.,Quantum bit/Qubit,What is the basic unit of memory in quantum computers? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
d0d021e9-4fb3-4fc9-86a4-2eb92d12b1d5,test,future,high school,u66,12,group 1,post test,10,19,0,A,B,"Which of the following descriptions about developing AI with caution is incorrect? <please select the best answer> A. Autonomous driving has safety issues related to the measurement of doing well and liability. B. With more sensitive sensors and more autonomous control, robots are sure to have personalities and consciousness at some point. C. Stephen Hawking, Elon Musk and Bill Gates have warned that AI may spell the end to human intelligence. D. We should be smart enough to use AI and wise enough to plan our future so that using AI will enrich our lives.","Ethical issues. If AI are developed with more sensitive sensors and more autonomous control, will robots, at some point, start to have personalities and consciousness? Should we worry about respecting their opinions or their will for existence? A picture of 2 robots."
63a96f53-5ffc-45ed-8e4e-f390dfdf400f,test,future,high school,u66,12,group 1,post test,7,11,1,"To develop brain-AI communication, we must learn more about the human brain.",We must do more research on the human brain side,What is the reason that development in brain-AI communication takes a long time? <please input your answer>,Integrate with our brains. We expect our brains will be able to communicate with AI through implanted electrodes to expand out cognitive capabilities. Development in this direction may take many years because we must do more research on the human brain side. A picture of a human brain but it's digital.
629da96a-38fe-4b21-ad48-b2887d293309,train,past,high school,u67,12,group 1,post test,3,7,0,A,B,Which one of the following methods is suitable for robots that work on Mars to achieve autonomousness? <please select the best answer> A. Spike neural networks B. Q-learning C. K-nearest neighbors D. Recurrent neural networks,"Usage in dangerous situations. Situations human want to avoid: Old minefields, automobile factories, other planets... AI can make machines in these situations more autonomous and useful. A picture of Curious, a robot that was sent to Mars."
23eb4167-b6b9-4a92-8d5f-755233bebe30,train,past,high school,u67,12,group 1,post test,4,9,0,?,We should read with caution because a fair amount of hype is often involved,What should we notice when we are faced with AI-related news? <please input your answer>,"Summary. The real-world aplication using AI have just begun, and AI technology hasn’t fully matured and been tested. AI-related news should be read with caution. A picture of a robot."
d66f0bb1-6471-4514-b8a4-15d59d638f31,train,past,high school,u67,12,group 1,post test,1,4,0,A,C,"To help biologists to understand the vast amount of data, AI can generate a knowledge graph. Which is a helpful scheme to build such knowledge? <please select the best answer> A. Reinforcement learning B. Supervised learning C. Unsupervised learning D. Few-shot learning","Medicine. finding new drugs. medical diagnoses. With the vast knowledge of paintents , and chemical sturctures sotred in databases, AI system can search for potentially effective treatments more quickly than human experts can. A video about AI usage in medicine."
4a3e20ae-f77c-4577-9d3e-27058f4f9b8b,train,future,high school,u67,12,group 1,post test,8,15,0,B,D,Which of the following best describes artificial general intelligence (AGI)? <please select the best answer> A. Computer programs that experience sentience or consciousness. B. Any program that is designed to solve exactly one problem. C. A computer agent with the ability to sense and the ability to act. D. An intelligent agent to learn any task that a human being can.,"Artificial general intelligence (AGI). AGI is a generic, human-like intelligence that can tackle problems by developing and applying general congnitive abilities across different areas. Many people think that the progress in AI will be made only by tackling specific problems, not by trying to advance machine intelligence in general. A picture of a robot trying to solve complex math/physics problems."
bad3cba1-8302-4c6b-a3ef-088e0df098d2,train,future,high school,u67,12,group 1,post test,9,13,0,?,Spike neurons take as input spikes while tradition neurons take as input continuous value,What is the most significant difference between spike neural networks and traditional neural networks? <please input your answer>,"Supporting hardware. Spiking neural networks: They consider the spike timings rather than just the spiking frequency, which is an important feature of biological neural networls. An animation demonstrating spiking neural networks."
c7144031-910e-4205-9532-9b0ffcbddcda,train,past,high school,u67,12,group 1,post test,2,5,0,D,C,"Considering the given example, which one of the following opinions correctly describes the entity and related information? Example: SpaceX is an aerospace manufacturer and space transport services company headquartered in California. It was founded in 2002 by entrepreneur and investor Elon Musk with the goal of reducing space transportation costs and enabling the colonization of Mars. <please select the best answer> A. Entrepreneur (“Elon Musk”, “SpaceX”, “California”) B. Entrepreneur (“Elon Musk”, “California”, “2002”) C. Company (“SpaceX”, “California”, “Elon Musk”) D. Company (“SpaceX”, “Mars”, “Elon Musk”)","Natural language application. machine translation. natural language interfaces. AI systems extract knowledge from natural language texts. E.g., Q: The headquarters of BHP Billiton Limited, and the global headquarters of the combined BHP Billiton Group, are located in Melbourne, Australia. A: headquarters('“'BHP Biliton Limited', 'Melbourne, Australia') A cartoon picture showing that."
6c67cf85-2834-4b2a-a92e-6ba22224f42b,train,future,high school,u67,12,group 1,post test,6,14,0,?,Qubits can represent combinations simultaneously.,Why do quantum computers outperform existing traditional computers in problems related to a large number of combinations? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
9b90293d-10ef-4da9-b417-18484dd33605,train,past,high school,u67,12,group 1,post test,5,14,0,?,Quantum bit/Qubit,What is the basic unit of memory in quantum computers? <please input your answer>,"Quantum computer. Quantum computers will be faster and smaller. Traditional: Bits. Quantum: Qubits. Represent numbers at the same time. In situations where there are a large number of possible combinations, quantum computers can consider them simultaneously. A picture of a futuristic chip."
22f9759b-bcfd-4832-ab0d-830600b02e66,train,future,high school,u67,12,group 1,post test,10,19,1,B,B,"Which of the following descriptions about developing AI with caution is incorrect? <please select the best answer> A. Autonomous driving has safety issues related to the measurement of doing well and liability. B. With more sensitive sensors and more autonomous control, robots are sure to have personalities and consciousness at some point. C. Stephen Hawking, Elon Musk and Bill Gates have warned that AI may spell the end to human intelligence. D. We should be smart enough to use AI and wise enough to plan our future so that using AI will enrich our lives.","Ethical issues. If AI are developed with more sensitive sensors and more autonomous control, will robots, at some point, start to have personalities and consciousness? Should we worry about respecting their opinions or their will for existence? A picture of 2 robots."
3f73ff72-1182-491e-9a81-bf75318c78ff,train,future,high school,u67,12,group 1,post test,7,11,0,?,We must do more research on the human brain side,What is the reason that development in brain-AI communication takes a long time? <please input your answer>,Integrate with our brains. We expect our brains will be able to communicate with AI through implanted electrodes to expand out cognitive capabilities. Development in this direction may take many years because we must do more research on the human brain side. A picture of a human brain but it's digital.
a25a6d27-98fb-4758-a04b-6635f2dbe052,train,past,high school,u70,2,group 1,post test,3,5,1,True,T,"For an OR logic gate, if the inputs are '0' and '1', then the output is 1. <please select the best answer> True or False",Logic gates. Boolean function assume values from a two-element set {01}. Logic gates are physical electronic devices implementing a Boolean function. AND. OR. NOT. It contains three pictures of logic gates.
2de373c9-8101-4058-937d-2534a1426254,train,past,high school,u70,2,group 1,post test,4,8,1,False,F,Frank Rosenblatt came up with the first learning theory. <please select the best answer> True or False,Ability to learn. Intelligent machines must be able to learn just like the human brain. Donald Hebb the first learning theory The Organization of Behavior (1949). When two neurons get excited together the connection weights increase. Frank Rosenblatt the first ANN model with learning capability perceptron in 1957. It was designed and realized as an image recognition machine
cd000631-0e1f-4f82-b106-676dd5894d0d,train,past,high school,u70,2,group 1,post test,1,3,1,True,T,"The reticular theory was advocated by physician Camillo Golgi, who invented a groundbreaking method for observing the nervous system. <please select the best answer> True or False",Knows the neural network of brain. The reticular theory: the nervous system was a continuous network. Camillo Golgi invented a groundbreaking method for observing the nervous system. Camillo Golgi (1843-1926). It contains two pictures of Camillo and neurons.
d57b593b-1079-4198-93fd-79da2635cd22,train,future,high school,u70,2,group 1,post test,8,6,0,cant remember ,Neuron,McCulloch and Pitts found what to be like the basic building block that can be used to build any complex logical circuits? <please input your answer>,"neuron could act as a logic gate. McCulloch and Pitts thought each neuron could act as a logic gate and that it could be combined to form a complex computing system. McCulloch and Pitts. A neuron can receive inputs from other neurons, weighs and accumulates them, and decides whether or not to produce an output. It contains three pictures of McCulloch and neurons."
0333ea08-8e36-42ea-9527-d9d81df48ae6,train,future,high school,u70,2,group 1,post test,9,8,0,cant remember,The connection strength,"When two neurons get excited together, what is increased? The input, the output, or the connection strength? <please input your answer>",Ability to learn. Intelligent machines must be able to learn just like the human brain. Donald Hebb the first learning theory The Organization of Behavior (1949). When two neurons get excited together the connection weights increase. Frank Rosenblatt the first ANN model with learning capability perceptron in 1957. It was designed and realized as an image recognition machine
7b076d2a-5837-4a70-9158-1ba3f21d917a,train,past,high school,u70,2,group 1,post test,2,5,1,False,F,"For an AND logic gate, if the inputs are '0' and '1', then the output is 1. <please select the best answer> True or False",Logic gates. Boolean function assume values from a two-element set {01}. Logic gates are physical electronic devices implementing a Boolean function. AND. OR. NOT. It contains three pictures of logic gates.
de4aad93-2afd-4543-912e-3f84a358c353,train,future,high school,u70,2,group 1,post test,6,17,1,False,F,"For the current state of ANNs, it is easy to interpret what ANNs are doing. <please select the best answer> True or False",Current state of ANNs. Interpretability. It’s difficult to interpret what ANNs are doing raises safety concerns. Generalizability. ANNs don’t generalize when they encounter inputs different from those they are trained on. It contains a picture of autonomous driving.
2d00be79-7ace-4c3f-b3c9-91b644260ec1,train,past,high school,u70,2,group 1,post test,5,10,0,True,F,The first neural networks winter is because of that training ANNs takes a lot of computation and computing power was limited in that era. <please select the best answer> True or False,The first neural networks winter. Rosenblatt could not come up with an effective algorithm for adjusting the weights in the intermediate layer neurons. It was easy to adjust the weights to the output there were no effective ways to adjust the weights in earlier layers (hidden layers). It contains a picture of the neural network.
bcc40df8-fd63-4ec5-839c-d9c3378abad6,train,future,high school,u70,2,group 1,post test,10,12,0,cant remember,Backpropagation,What is the algorithm that contributed to the end of the first neural network winter? <please input your answer>,The second neural networks boom. Several people found ways to train multiple layer neural networks through a technique called backpropagation. ANNs with multiple layers could be trained to yield outputs closer to the desired output values. Backpropagation provides an effective way to change hidden connections to reduce output errors. It contains a picture of the backpropagation.
d41ee40e-c581-4cec-91b9-2c4224bf3b01,train,future,high school,u70,2,group 1,post test,7,17,1,True,T,ANNs of the current state don't have a good generalization. <please select the best answer> True or False,Current state of ANNs. Interpretability. It’s difficult to interpret what ANNs are doing raises safety concerns. Generalizability. ANNs don’t generalize when they encounter inputs different from those they are trained on. It contains a picture of autonomous driving.
2515b060-d348-426b-aba0-c16381e2add6,train,past,high school,u71,2,group 1,post test,3,5,0,False,T,"For an OR logic gate, if the inputs are '0' and '1', then the output is 1. <please select the best answer> True or False",Logic gates. Boolean function assume values from a two-element set {01}. Logic gates are physical electronic devices implementing a Boolean function. AND. OR. NOT. It contains three pictures of logic gates.
2562b187-5d17-43bb-b557-e3670038f4b9,train,past,high school,u71,2,group 1,post test,4,8,0,True,F,Frank Rosenblatt came up with the first learning theory. <please select the best answer> True or False,Ability to learn. Intelligent machines must be able to learn just like the human brain. Donald Hebb the first learning theory The Organization of Behavior (1949). When two neurons get excited together the connection weights increase. Frank Rosenblatt the first ANN model with learning capability perceptron in 1957. It was designed and realized as an image recognition machine
388ca8d7-cca7-4784-99d6-83b56b14bef0,train,past,high school,u71,2,group 1,post test,1,3,1,True,T,"The reticular theory was advocated by physician Camillo Golgi, who invented a groundbreaking method for observing the nervous system. <please select the best answer> True or False",Knows the neural network of brain. The reticular theory: the nervous system was a continuous network. Camillo Golgi invented a groundbreaking method for observing the nervous system. Camillo Golgi (1843-1926). It contains two pictures of Camillo and neurons.
dd9e6ab2-76e8-435c-a542-0c555a7299f0,train,future,high school,u71,2,group 1,post test,8,6,0,not sure,Neuron,McCulloch and Pitts found what to be like the basic building block that can be used to build any complex logical circuits? <please input your answer>,"neuron could act as a logic gate. McCulloch and Pitts thought each neuron could act as a logic gate and that it could be combined to form a complex computing system. McCulloch and Pitts. A neuron can receive inputs from other neurons, weighs and accumulates them, and decides whether or not to produce an output. It contains three pictures of McCulloch and neurons."
7a51fea6-f543-4be5-9435-d36b103b49e1,train,future,high school,u71,2,group 1,post test,9,8,1,The Connectino Strentgh,The connection strength,"When two neurons get excited together, what is increased? The input, the output, or the connection strength? <please input your answer>",Ability to learn. Intelligent machines must be able to learn just like the human brain. Donald Hebb the first learning theory The Organization of Behavior (1949). When two neurons get excited together the connection weights increase. Frank Rosenblatt the first ANN model with learning capability perceptron in 1957. It was designed and realized as an image recognition machine
df89af50-5eaa-490d-8abc-f54206ad90db,train,past,high school,u71,2,group 1,post test,2,5,0,True,F,"For an AND logic gate, if the inputs are '0' and '1', then the output is 1. <please select the best answer> True or False",Logic gates. Boolean function assume values from a two-element set {01}. Logic gates are physical electronic devices implementing a Boolean function. AND. OR. NOT. It contains three pictures of logic gates.
b50a891f-5373-452b-bba8-9e25189954db,train,future,high school,u71,2,group 1,post test,6,17,1,False,F,"For the current state of ANNs, it is easy to interpret what ANNs are doing. <please select the best answer> True or False",Current state of ANNs. Interpretability. It’s difficult to interpret what ANNs are doing raises safety concerns. Generalizability. ANNs don’t generalize when they encounter inputs different from those they are trained on. It contains a picture of autonomous driving.
d6f58fb0-8bb2-47da-aacf-264e383a2280,train,past,high school,u71,2,group 1,post test,5,10,0,True,F,The first neural networks winter is because of that training ANNs takes a lot of computation and computing power was limited in that era. <please select the best answer> True or False,The first neural networks winter. Rosenblatt could not come up with an effective algorithm for adjusting the weights in the intermediate layer neurons. It was easy to adjust the weights to the output there were no effective ways to adjust the weights in earlier layers (hidden layers). It contains a picture of the neural network.
c1bb288f-9413-464b-a1cf-3d14a78c5b27,train,future,high school,u71,2,group 1,post test,10,12,0,not sure,Backpropagation,What is the algorithm that contributed to the end of the first neural network winter? <please input your answer>,The second neural networks boom. Several people found ways to train multiple layer neural networks through a technique called backpropagation. ANNs with multiple layers could be trained to yield outputs closer to the desired output values. Backpropagation provides an effective way to change hidden connections to reduce output errors. It contains a picture of the backpropagation.
4bda22fd-385b-4d82-ac6b-b5a47fcf0319,train,future,high school,u71,2,group 1,post test,7,17,0,,T,ANNs of the current state don't have a good generalization. <please select the best answer> True or False,Current state of ANNs. Interpretability. It’s difficult to interpret what ANNs are doing raises safety concerns. Generalizability. ANNs don’t generalize when they encounter inputs different from those they are trained on. It contains a picture of autonomous driving.
f14ae20e-b12f-459e-95b7-f4f49987d233,train,past,high school,u70,3,group 1,post test,3,12,0,increase,A,"If the desired change is positive, and the input is -1, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
31138508-473e-4c88-ab10-8ca48a2d85d1,train,past,high school,u70,3,group 1,post test,4,16,0,1.0,B,"After many iterations of learning, what value does the output of the '+' artificial neuron in response to 'x' become closer to? <please select the best answer> A. 1.0 B. 0.0 C. 1.5 D. -1.0",Summary. ANNs work by training the network for samples 'x' and '+' repeatedly. The output of the artificial neuron will become closer and closer to the desired output. It contains a table of relationship between input and neuron.
2080b723-6e3b-4318-9ba6-aae95280c3d2,train,past,high school,u70,3,group 1,post test,1,2,0,Supervised learning,BC,Which of the following learning methods involves learning from a teacher? <please select the answer> A. Unsupervised learning B. Supervised learning C. Reinforcement learning ,Outline. Supervised learning: learning from a teacher. Computing the output. Comparing the output to the desired output. Changing the connection weight. Backpropagation.
1112be0f-358f-4144-be78-beccc75b30b6,train,future,high school,u70,3,group 1,post test,8,21,0,,B,"If the inner state is -1, what will the output be after the ReLU (Rectified Linear Unit)? <please select the best answer> A. -1 B. 0 C. 1",Change in the Computation. Rectified Linear Unit (ReLU) is one of the commonly used transformations. Given an inner state Mimics the way how biological neurons are triggered!
b878fcd9-b09b-4da4-bc04-a380eb2cfa15,train,future,high school,u70,3,group 1,post test,9,5,0,,Desired outputs are not given for these 'in between' neurons,"If there is more than one layer of artificial neurons--- that is, if neurons are between the input and the output neurons--- the delta rule can't be used. Why not? Each artificial neuron has computable inputs and an output. What is missing? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
c258db25-1888-4a56-8a94-04c575c9ca82,train,past,high school,u70,3,group 1,post test,2,5,0,desired change;input,ABC,Which of the following options are required to determine the change of one connection in the delta rule? <please select the answer> A. learning constant B. desired change C. input D. connection weight,The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
a883e782-27f1-4975-be83-0db14a2e450c,train,future,high school,u70,3,group 1,post test,11,22,0,,"error: 1-(0.5*1)=0.5, weight change: 0.01 *0.5* 1*1 = 0.005","In a supervised ANN, the input is 0.5, the weight is 1, and we use ReLU (Rectified Linear Unit) as the hat of a neuron. The desired output is 1 and we set the learning rate as 0.01. Please calculate the weight change of the process. <please input your answer>",Change in the Computation. The output is 0.05 (not changed by ReLU because it is > 0). The desired output change: 0.95 Error: the deviation of the actual output from the desired output. (the desired change)
14c9cdc8-c08a-47e2-9057-0f25177151b0,train,future,high school,u70,3,group 1,post test,6,5,0,,0.2,"If the target output is 0.5 and the computed output is 0.3, what would the desired change be? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
08070bbe-63ba-4565-986d-329cc260da5a,train,past,high school,u70,3,group 1,post test,5,15,0,,0.4,"If the input of a single-layer ANN model is 1,0,1; and the weight of inputs is 0.1, 0.2, 0.3; what is the output of the single-layer ANN model? <please input your answer>",Example 3: Weight change for the 'x' neuron. After applying the delta rule the weight pattern of the 'x' artificial neuron will be. It contains a picture of calculation.
beee7b2f-8179-4477-9b5a-5959eebcffe2,train,future,high school,u70,3,group 1,post test,10,23,0,,"As the output becomes closer to the desired output, the desired change will become smaller.","If supervised learning works, the weight change will become smaller and smaller. Why? <please input your answer>",Change in the Computation. contribution ratio: the ratio between the inner state change and the output change. the weight change proportional to: input * contribution ratio * error = 1*1*0.95
169cc9b0-c9b9-41e6-9add-8df227fed0c8,train,future,high school,u70,3,group 1,post test,12,18,0,,Train incoming connection weights to middle/non-input layers,What was backpropagation developed to do? <please input your answer>,Backpropagation. Backpropagation was developed to train incoming connection weights to hidden layers. It provides a method to train multilayer neural networks.
0011e7ec-42a3-4d70-bcbd-9886606ba076,train,future,high school,u70,3,group 1,post test,7,5,0,,D,"Let the learning constant be 0.2, the desired change to be 0.3, and the input to be 1, then the change of weight will be? <please select the best answer> A. 0.02 B. 0.04 C. 0.05 D. 0.06",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
8a9827ae-bad0-44c6-b95b-69e14e0a5a5f,test,past,high school,u62,3,group 1,post test,3,12,1,decrease,A,"If the desired change is positive, and the input is -1, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
801d6242-fc75-429a-9d4b-8d0b8c04e653,test,past,high school,u62,3,group 1,post test,4,16,1,0.0,B,"After many iterations of learning, what value does the output of the '+' artificial neuron in response to 'x' become closer to? <please select the best answer> A. 1.0 B. 0.0 C. 1.5 D. -1.0",Summary. ANNs work by training the network for samples 'x' and '+' repeatedly. The output of the artificial neuron will become closer and closer to the desired output. It contains a table of relationship between input and neuron.
19d22948-7c58-4267-9f2f-d20197e506ef,test,past,high school,u62,3,group 1,post test,1,2,0,Supervised learning,BC,Which of the following learning methods involves learning from a teacher? <please select the answer> A. Unsupervised learning B. Supervised learning C. Reinforcement learning ,Outline. Supervised learning: learning from a teacher. Computing the output. Comparing the output to the desired output. Changing the connection weight. Backpropagation.
51747367-7cc5-4550-b7fe-e2c2257bc8c7,test,future,high school,u62,3,group 1,post test,8,21,1,0.0,B,"If the inner state is -1, what will the output be after the ReLU (Rectified Linear Unit)? <please select the best answer> A. -1 B. 0 C. 1",Change in the Computation. Rectified Linear Unit (ReLU) is one of the commonly used transformations. Given an inner state Mimics the way how biological neurons are triggered!
9a9a6e10-7c4b-4c0e-9da5-b86bb6b4be9e,test,future,high school,u62,3,group 1,post test,9,5,1,It can't because it extends from the delta rule. The missing thing is the direct contact to the weight. It is instead connected to other neurons.,Desired outputs are not given for these 'in between' neurons,"If there is more than one layer of artificial neurons--- that is, if neurons are between the input and the output neurons--- the delta rule can't be used. Why not? Each artificial neuron has computable inputs and an output. What is missing? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
e4834cfc-ef1a-4c82-a618-63769f2485e8,test,past,high school,u62,3,group 1,post test,2,5,0,desired change;input;connection weight,ABC,Which of the following options are required to determine the change of one connection in the delta rule? <please select the answer> A. learning constant B. desired change C. input D. connection weight,The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
286d72b2-7427-455b-bec2-bbd634abe954,test,future,high school,u62,3,group 1,post test,11,22,0,0.005,"error: 1-(0.5*1)=0.5, weight change: 0.01 *0.5* 1*1 = 0.005","In a supervised ANN, the input is 0.5, the weight is 1, and we use ReLU (Rectified Linear Unit) as the hat of a neuron. The desired output is 1 and we set the learning rate as 0.01. Please calculate the weight change of the process. <please input your answer>",Change in the Computation. The output is 0.05 (not changed by ReLU because it is > 0). The desired output change: 0.95 Error: the deviation of the actual output from the desired output. (the desired change)
28323869-cf86-42c1-a282-608b786b2a6f,test,future,high school,u62,3,group 1,post test,6,5,1,0.2,0.2,"If the target output is 0.5 and the computed output is 0.3, what would the desired change be? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
7f7adb53-813b-4b1e-9cad-685d5a8693f7,test,past,high school,u62,3,group 1,post test,5,15,0,"0,0,1",0.4,"If the input of a single-layer ANN model is 1,0,1; and the weight of inputs is 0.1, 0.2, 0.3; what is the output of the single-layer ANN model? <please input your answer>",Example 3: Weight change for the 'x' neuron. After applying the delta rule the weight pattern of the 'x' artificial neuron will be. It contains a picture of calculation.
1833379e-20ee-4844-a99f-0db8e8c1d83e,test,future,high school,u62,3,group 1,post test,10,23,1,It becomes more precise and it will know for sure if something is 0 or 1.,"As the output becomes closer to the desired output, the desired change will become smaller.","If supervised learning works, the weight change will become smaller and smaller. Why? <please input your answer>",Change in the Computation. contribution ratio: the ratio between the inner state change and the output change. the weight change proportional to: input * contribution ratio * error = 1*1*0.95
33b27b62-1f0d-47c0-8f53-72827d27163e,test,future,high school,u62,3,group 1,post test,12,18,1,It is an extension of neurons to make the output prediction more accurate.,Train incoming connection weights to middle/non-input layers,What was backpropagation developed to do? <please input your answer>,Backpropagation. Backpropagation was developed to train incoming connection weights to hidden layers. It provides a method to train multilayer neural networks.
7723738e-9118-4188-95d7-2c064dbf356a,test,future,high school,u62,3,group 1,post test,7,5,1,0.06,D,"Let the learning constant be 0.2, the desired change to be 0.3, and the input to be 1, then the change of weight will be? <please select the best answer> A. 0.02 B. 0.04 C. 0.05 D. 0.06",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
29dc892d-92a3-4918-83e0-461062982394,test,past,high school,u61,3,group 2,post test,3,12,1,decrease,A,"If the desired change is positive, and the input is -1, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
adee465b-2e2a-412b-bde7-bf2575536ddd,test,past,high school,u61,3,group 2,post test,4,16,1,0.0,B,"After many iterations of learning, what value does the output of the '+' artificial neuron in response to 'x' become closer to? <please select the best answer> A. 1.0 B. 0.0 C. 1.5 D. -1.0",Summary. ANNs work by training the network for samples 'x' and '+' repeatedly. The output of the artificial neuron will become closer and closer to the desired output. It contains a table of relationship between input and neuron.
f07eaf7d-5861-4378-8f6e-6c3f6fd6b146,test,past,high school,u61,3,group 2,post test,1,2,0,Supervised learning,BC,Which of the following learning methods involves learning from a teacher? <please select the answer> A. Unsupervised learning B. Supervised learning C. Reinforcement learning ,Outline. Supervised learning: learning from a teacher. Computing the output. Comparing the output to the desired output. Changing the connection weight. Backpropagation.
70ad1291-cfd3-4bb0-85e6-c3b6c1b2dd34,test,future,high school,u61,3,group 2,post test,8,21,1,0,B,"If the inner state is -1, what will the output be after the ReLU (Rectified Linear Unit)? <please select the best answer> A. -1 B. 0 C. 1",Change in the Computation. Rectified Linear Unit (ReLU) is one of the commonly used transformations. Given an inner state Mimics the way how biological neurons are triggered!
7e4696f1-a64f-49ba-a461-c05d1c3cd69b,test,future,high school,u61,3,group 2,post test,9,5,0,The inner state change will have different values. ,Desired outputs are not given for these 'in between' neurons,"If there is more than one layer of artificial neurons--- that is, if neurons are between the input and the output neurons--- the delta rule can't be used. Why not? Each artificial neuron has computable inputs and an output. What is missing? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
c9f32a5c-315f-4be5-ab60-fa37742a925a,test,past,high school,u61,3,group 2,post test,2,5,0,desired change;connection weight,ABC,Which of the following options are required to determine the change of one connection in the delta rule? <please select the answer> A. learning constant B. desired change C. input D. connection weight,The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
9aae02fb-3b61-4708-8073-6aa730c30720,test,future,high school,u61,3,group 2,post test,11,22,0,"0,005","error: 1-(0.5*1)=0.5, weight change: 0.01 *0.5* 1*1 = 0.005","In a supervised ANN, the input is 0.5, the weight is 1, and we use ReLU (Rectified Linear Unit) as the hat of a neuron. The desired output is 1 and we set the learning rate as 0.01. Please calculate the weight change of the process. <please input your answer>",Change in the Computation. The output is 0.05 (not changed by ReLU because it is > 0). The desired output change: 0.95 Error: the deviation of the actual output from the desired output. (the desired change)
f250a00c-bd52-43ce-98b7-4c02b47552b7,test,future,high school,u61,3,group 2,post test,6,5,1,0.2,0.2,"If the target output is 0.5 and the computed output is 0.3, what would the desired change be? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
d9ad8047-788c-47d1-954a-4f828607a5e7,test,past,high school,u61,3,group 2,post test,5,15,0,"0.9, 0.8, 0.7",0.4,"If the input of a single-layer ANN model is 1,0,1; and the weight of inputs is 0.1, 0.2, 0.3; what is the output of the single-layer ANN model? <please input your answer>",Example 3: Weight change for the 'x' neuron. After applying the delta rule the weight pattern of the 'x' artificial neuron will be. It contains a picture of calculation.
befc935d-f75e-43b5-b3c0-1e5e027b4e87,test,future,high school,u61,3,group 2,post test,10,23,1,The desired change will be smaller. ,"As the output becomes closer to the desired output, the desired change will become smaller.","If supervised learning works, the weight change will become smaller and smaller. Why? <please input your answer>",Change in the Computation. contribution ratio: the ratio between the inner state change and the output change. the weight change proportional to: input * contribution ratio * error = 1*1*0.95
29f90d6c-1796-4315-ba22-6d68fff980c6,test,future,high school,u61,3,group 2,post test,12,18,1,It is developed to train incoming connection weights to hidden layers. It provides a method to trian mulitlayer neural networks. ,Train incoming connection weights to middle/non-input layers,What was backpropagation developed to do? <please input your answer>,Backpropagation. Backpropagation was developed to train incoming connection weights to hidden layers. It provides a method to train multilayer neural networks.
78fd916b-35ae-47c4-8a4f-da61762d7806,test,future,high school,u61,3,group 2,post test,7,5,1,0.06,D,"Let the learning constant be 0.2, the desired change to be 0.3, and the input to be 1, then the change of weight will be? <please select the best answer> A. 0.02 B. 0.04 C. 0.05 D. 0.06",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
15278821-e4b9-4ace-89de-fe995d5315a4,train,past,high school,u68,3,group 2,post test,3,12,1,decrease,A,"If the desired change is positive, and the input is -1, will the weight decrease or increase? <please select the best answer> A. decrease B. increase",Changing the connection weight. The delta rule states that the change of weight depends on both the input and the desired change. Learning constant: if it is smaller than 1 adjust the weight little by little. It contains a table describing the input and weight change.
633c1efd-fee4-4c08-89d6-7a053f23965b,train,past,high school,u68,3,group 2,post test,4,16,1,0.0,B,"After many iterations of learning, what value does the output of the '+' artificial neuron in response to 'x' become closer to? <please select the best answer> A. 1.0 B. 0.0 C. 1.5 D. -1.0",Summary. ANNs work by training the network for samples 'x' and '+' repeatedly. The output of the artificial neuron will become closer and closer to the desired output. It contains a table of relationship between input and neuron.
1c2433d8-feef-49f1-b350-dc5ffe2e732f,train,past,high school,u68,3,group 2,post test,1,2,0,Supervised learning,BC,Which of the following learning methods involves learning from a teacher? <please select the answer> A. Unsupervised learning B. Supervised learning C. Reinforcement learning ,Outline. Supervised learning: learning from a teacher. Computing the output. Comparing the output to the desired output. Changing the connection weight. Backpropagation.
35d40c8b-23c7-4c02-998b-2d57961e8234,train,future,high school,u68,3,group 2,post test,8,21,0,-1,B,"If the inner state is -1, what will the output be after the ReLU (Rectified Linear Unit)? <please select the best answer> A. -1 B. 0 C. 1",Change in the Computation. Rectified Linear Unit (ReLU) is one of the commonly used transformations. Given an inner state Mimics the way how biological neurons are triggered!
bf5d49dc-b325-4a2a-9b89-be4f35415c32,train,future,high school,u68,3,group 2,post test,9,5,0,The learning rate is changed,Desired outputs are not given for these 'in between' neurons,"If there is more than one layer of artificial neurons--- that is, if neurons are between the input and the output neurons--- the delta rule can't be used. Why not? Each artificial neuron has computable inputs and an output. What is missing? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
281789df-d9aa-43a6-8bf3-2ac72dd302d8,train,past,high school,u68,3,group 2,post test,2,5,0,desired change;input,ABC,Which of the following options are required to determine the change of one connection in the delta rule? <please select the answer> A. learning constant B. desired change C. input D. connection weight,The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
eea5c37e-d3ac-4d6a-a03a-289d0bb610d1,train,future,high school,u68,3,group 2,post test,11,22,0,0.05,"error: 1-(0.5*1)=0.5, weight change: 0.01 *0.5* 1*1 = 0.005","In a supervised ANN, the input is 0.5, the weight is 1, and we use ReLU (Rectified Linear Unit) as the hat of a neuron. The desired output is 1 and we set the learning rate as 0.01. Please calculate the weight change of the process. <please input your answer>",Change in the Computation. The output is 0.05 (not changed by ReLU because it is > 0). The desired output change: 0.95 Error: the deviation of the actual output from the desired output. (the desired change)
f7a04dd8-6ab0-4ddc-911c-ea5655aa9abc,train,future,high school,u68,3,group 2,post test,6,5,1,0.2,0.2,"If the target output is 0.5 and the computed output is 0.3, what would the desired change be? <please input your answer>",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
9e067055-4627-404b-a74c-7e2d0669aee6,train,past,high school,u68,3,group 2,post test,5,15,1,0.4,0.4,"If the input of a single-layer ANN model is 1,0,1; and the weight of inputs is 0.1, 0.2, 0.3; what is the output of the single-layer ANN model? <please input your answer>",Example 3: Weight change for the 'x' neuron. After applying the delta rule the weight pattern of the 'x' artificial neuron will be. It contains a picture of calculation.
245e084e-7293-4774-b30f-7207668fb04a,train,future,high school,u68,3,group 2,post test,10,23,1,The error is being minmized,"As the output becomes closer to the desired output, the desired change will become smaller.","If supervised learning works, the weight change will become smaller and smaller. Why? <please input your answer>",Change in the Computation. contribution ratio: the ratio between the inner state change and the output change. the weight change proportional to: input * contribution ratio * error = 1*1*0.95
e533dd90-567b-40c3-929e-25d98d813bf8,train,future,high school,u68,3,group 2,post test,12,18,1,Train incoming connection weights to hidden layers; provides a method to train multilayer neural networks,Train incoming connection weights to middle/non-input layers,What was backpropagation developed to do? <please input your answer>,Backpropagation. Backpropagation was developed to train incoming connection weights to hidden layers. It provides a method to train multilayer neural networks.
4f3312cb-ceaf-4a2d-8133-ad43cc6eb366,train,future,high school,u68,3,group 2,post test,7,5,1,0.06,D,"Let the learning constant be 0.2, the desired change to be 0.3, and the input to be 1, then the change of weight will be? <please select the best answer> A. 0.02 B. 0.04 C. 0.05 D. 0.06",The delta rule. Delta: symbolizes a change or difference. Uppercase: Δ and lowercase: 𝛿. The delta rule for linear artificial neuron is. It contains a picture of formula.
af3982e9-ead5-4308-aa2a-b8e42af35e79,train,past,high school,u74,7,group 1,post test,3,4,1,C,C,"Please select one of the following which falls into the framework of reinforcement learning. <please select the best answer> A. A computer calculates the digits of π, a mathematical constant which is close to 3.14. B. A neural network learns to distinguish images with known categories as cars or bicycles. C. An autonomous car tries to adapt to changing road conditions without causing accidents. D. A software collects user information and provides personalized recommendations automatically.",The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
6a1f1be0-00ec-4441-8417-7d83dd82ff0e,train,past,high school,u74,7,group 1,post test,4,8,1,pac man,pac-man,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the agent of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
e4a5b02d-58a1-4f93-875f-3632f6a0966f,train,past,high school,u74,7,group 1,post test,1,5,1,B,B,True or False: Reinforcement learning gets inputs as well as produces outputs? <please select the best answer> A. True   B. False,"Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
dae5f913-36a9-45bd-b05e-d05a96b19f7f,train,future,high school,u74,7,group 1,post test,8,17,0,17.5,35,"An agent receives 3 different rewards from the same state in 3 attempts. The 3 rewards are 20, 40, 45 respectively. Please use the formula V = Vold + 0.5 ✕ (r - Vold) and the initial V as 0 (Hint: Vold is 0 in the first calculation.) to calculate the final V of this state. <please input your answer>","The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. However, r is not always consistent in real world. new state = s. reward = r. Value of s: V = V_old + α * (r - V_old). Averaging the old value with new reward. A picture showing a mouse going through a maze where each cell is a state."
0f8adb0b-7c62-43eb-83e9-0f0b4507fc3c,train,future,high school,u74,7,group 1,post test,9,16,1,D,D,"An agent is at state (1,1). The possible next states are (1,2), (2,1) and (2,2). We have a lookup dictionary as follows. Which of the following is the V_next? A table of State (1,1), (1,2), (2,1), (2,2) with Value 10, 25, -10, 30 respectively. <please select the best answer> A. 10 B. 25 C.-10 D.30",The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. state = s. reward = r. Value of s: V_s = r. A table of that has a row of states and another row of value that correspond to each state. A picture showing a mouse going through a maze where each cell is a state.
f9f34f61-0184-479e-b7d2-3251c593adb1,train,past,high school,u74,7,group 1,post test,2,5,1,D,D,"In reinforcement learning, which two kinds of response does the agent get from its environment? <please select the best answer> A. Action, Reward B. Value, State C. Action, Value D. State, Reward","Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
63c5d9f5-eb9f-4b6b-b9cd-b8f1f052f811,train,future,high school,u74,7,group 1,post test,6,19,0,B,C,"If the value (V) in the current state is only indicated by the current reward (r), what is the relationship between them if we consider the future effect but a consistent reward (i.e. the reward does not change for a state)? <please select the best answer> A. V = r B. V = V_old + 0.1 * (r - V_old) C. V = 0.1 * (r + 0.5 * V_next) D. V = V_old + 0.1 * ((r + 0.5 * V_next) - V_old)","The value function considering future effect. Values: g: the degree of the effect of the future situation. (0<g<1, we assume 0.5). V_next : the value of the best possibe situation next (s’). Note: V_next is looked up from the current table. updated value: V_new = V_old + α *((r + g*V_next) - V_old). Note: we use r + 0.5*V_next instead of r. A picture showing a mouse going through a maze where each cell is a state and it illustrates the formula."
c4c2aad5-7225-4c82-ae54-29e23eb69e9a,train,past,high school,u74,7,group 1,post test,5,8,1,the ghosts are catching up to pac-man.,location,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the state of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
8ba9450c-99e8-4b9e-91cf-bf750df51d08,train,future,high school,u74,7,group 1,post test,10,20,1,B,B,"If a problem or a game has a lot of states, like the Go game, then we will need a neural network. What relationship do we expect the neural network to capture? <please select the best answer> A. The reward an agent receive after action  B. The value of a given state of the environment C. The action to take under a state of the environment D. The next state of the environment after agent takes an action",Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
360fbbcd-0335-453c-9648-fe348ed711c5,train,future,high school,u74,7,group 1,post test,7,19,0,For a changing reward.,the degree of the effect of the future situation,"In the formula V = V_old + α * ((r + g * V_next) - V_old), why do we introduce g? <please input your answer>","The value function considering future effect. Values: g: the degree of the effect of the future situation. (0<g<1, we assume 0.5). V_next : the value of the best possibe situation next (s’). Note: V_next is looked up from the current table. updated value: V_new = V_old + α *((r + g*V_next) - V_old). Note: we use r + 0.5*V_next instead of r. A picture showing a mouse going through a maze where each cell is a state and it illustrates the formula."
5f3d42dd-4a33-440e-9f07-6942d5d13c1d,train,past,high school,u75,7,group 1,post test,3,4,1,C,C,"Please select one of the following which falls into the framework of reinforcement learning. <please select the best answer> A. A computer calculates the digits of π, a mathematical constant which is close to 3.14. B. A neural network learns to distinguish images with known categories as cars or bicycles. C. An autonomous car tries to adapt to changing road conditions without causing accidents. D. A software collects user information and provides personalized recommendations automatically.",The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
c1906c5a-c678-44ee-ae34-23687ef2aa9d,train,past,high school,u75,7,group 1,post test,4,8,1,pac-man,pac-man,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the agent of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
aa65b53f-622f-4b56-92c1-2f8dc327f77e,train,past,high school,u75,7,group 1,post test,1,5,1,B,B,True or False: Reinforcement learning gets inputs as well as produces outputs? <please select the best answer> A. True   B. False,"Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
236b3d60-df24-494a-ab01-8f9f286dfa69,train,future,high school,u75,7,group 1,post test,8,17,1,35,35,"An agent receives 3 different rewards from the same state in 3 attempts. The 3 rewards are 20, 40, 45 respectively. Please use the formula V = Vold + 0.5 ✕ (r - Vold) and the initial V as 0 (Hint: Vold is 0 in the first calculation.) to calculate the final V of this state. <please input your answer>","The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. However, r is not always consistent in real world. new state = s. reward = r. Value of s: V = V_old + α * (r - V_old). Averaging the old value with new reward. A picture showing a mouse going through a maze where each cell is a state."
97e6bbb9-3b9b-487f-a95f-67611b02bff3,train,future,high school,u75,7,group 1,post test,9,16,1,D,D,"An agent is at state (1,1). The possible next states are (1,2), (2,1) and (2,2). We have a lookup dictionary as follows. Which of the following is the V_next? A table of State (1,1), (1,2), (2,1), (2,2) with Value 10, 25, -10, 30 respectively. <please select the best answer> A. 10 B. 25 C.-10 D.30",The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. state = s. reward = r. Value of s: V_s = r. A table of that has a row of states and another row of value that correspond to each state. A picture showing a mouse going through a maze where each cell is a state.
e43174ae-56a1-4af4-8dc6-dbe1aa91e621,train,past,high school,u75,7,group 1,post test,2,5,1,D,D,"In reinforcement learning, which two kinds of response does the agent get from its environment? <please select the best answer> A. Action, Reward B. Value, State C. Action, Value D. State, Reward","Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
07d0e47d-7c98-4155-9f60-49b24b432e46,train,future,high school,u75,7,group 1,post test,6,19,0,D,C,"If the value (V) in the current state is only indicated by the current reward (r), what is the relationship between them if we consider the future effect but a consistent reward (i.e. the reward does not change for a state)? <please select the best answer> A. V = r B. V = V_old + 0.1 * (r - V_old) C. V = 0.1 * (r + 0.5 * V_next) D. V = V_old + 0.1 * ((r + 0.5 * V_next) - V_old)","The value function considering future effect. Values: g: the degree of the effect of the future situation. (0<g<1, we assume 0.5). V_next : the value of the best possibe situation next (s’). Note: V_next is looked up from the current table. updated value: V_new = V_old + α *((r + g*V_next) - V_old). Note: we use r + 0.5*V_next instead of r. A picture showing a mouse going through a maze where each cell is a state and it illustrates the formula."
50b63fd3-090f-41a1-b24f-96314e14fffb,train,past,high school,u75,7,group 1,post test,5,8,1,the location in the maze,location,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the state of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
c705d853-e24d-4b35-bffa-0bdd9e0c2cc4,train,future,high school,u75,7,group 1,post test,10,20,1,B,B,"If a problem or a game has a lot of states, like the Go game, then we will need a neural network. What relationship do we expect the neural network to capture? <please select the best answer> A. The reward an agent receive after action  B. The value of a given state of the environment C. The action to take under a state of the environment D. The next state of the environment after agent takes an action",Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
792e76a0-9148-42b6-87a5-85aafcb15c23,train,future,high school,u75,7,group 1,post test,7,19,0,to deal with it not being consistent.,the degree of the effect of the future situation,"In the formula V = V_old + α * ((r + g * V_next) - V_old), why do we introduce g? <please input your answer>","The value function considering future effect. Values: g: the degree of the effect of the future situation. (0<g<1, we assume 0.5). V_next : the value of the best possibe situation next (s’). Note: V_next is looked up from the current table. updated value: V_new = V_old + α *((r + g*V_next) - V_old). Note: we use r + 0.5*V_next instead of r. A picture showing a mouse going through a maze where each cell is a state and it illustrates the formula."
cfc8fd81-15fa-4ca6-aaa2-2bafbb1768fe,train,past,high school,u64,7,group 2,post test,3,4,1,C,C,"Please select one of the following which falls into the framework of reinforcement learning. <please select the best answer> A. A computer calculates the digits of π, a mathematical constant which is close to 3.14. B. A neural network learns to distinguish images with known categories as cars or bicycles. C. An autonomous car tries to adapt to changing road conditions without causing accidents. D. A software collects user information and provides personalized recommendations automatically.",The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
6d961e61-027f-4eca-9b6b-1c8d5b42a9fa,train,past,high school,u64,7,group 2,post test,4,8,1,pacman,pac-man,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the agent of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
00f8a38c-41f2-46a3-9251-ad05e7f755fd,train,past,high school,u64,7,group 2,post test,1,5,0,A,B,True or False: Reinforcement learning gets inputs as well as produces outputs? <please select the best answer> A. True   B. False,"Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
45ba269a-47a2-4f7c-9fd0-2d235bafa78c,train,future,high school,u64,7,group 2,post test,8,17,1,35,35,"An agent receives 3 different rewards from the same state in 3 attempts. The 3 rewards are 20, 40, 45 respectively. Please use the formula V = Vold + 0.5 ✕ (r - Vold) and the initial V as 0 (Hint: Vold is 0 in the first calculation.) to calculate the final V of this state. <please input your answer>","The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. However, r is not always consistent in real world. new state = s. reward = r. Value of s: V = V_old + α * (r - V_old). Averaging the old value with new reward. A picture showing a mouse going through a maze where each cell is a state."
e43df61e-15d6-446f-9f17-3a278df3a75e,train,future,high school,u64,7,group 2,post test,9,16,0,B,D,"An agent is at state (1,1). The possible next states are (1,2), (2,1) and (2,2). We have a lookup dictionary as follows. Which of the following is the V_next? A table of State (1,1), (1,2), (2,1), (2,2) with Value 10, 25, -10, 30 respectively. <please select the best answer> A. 10 B. 25 C.-10 D.30",The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. state = s. reward = r. Value of s: V_s = r. A table of that has a row of states and another row of value that correspond to each state. A picture showing a mouse going through a maze where each cell is a state.
28dc7d91-86f3-4225-9453-208c21bc52ce,train,past,high school,u64,7,group 2,post test,2,5,1,D,D,"In reinforcement learning, which two kinds of response does the agent get from its environment? <please select the best answer> A. Action, Reward B. Value, State C. Action, Value D. State, Reward","Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
9e16869b-571b-4173-8213-7e33a5d91994,train,future,high school,u64,7,group 2,post test,6,19,0,B,C,"If the value (V) in the current state is only indicated by the current reward (r), what is the relationship between them if we consider the future effect but a consistent reward (i.e. the reward does not change for a state)? <please select the best answer> A. V = r B. V = V_old + 0.1 * (r - V_old) C. V = 0.1 * (r + 0.5 * V_next) D. V = V_old + 0.1 * ((r + 0.5 * V_next) - V_old)","The value function considering future effect. Values: g: the degree of the effect of the future situation. (0<g<1, we assume 0.5). V_next : the value of the best possibe situation next (s’). Note: V_next is looked up from the current table. updated value: V_new = V_old + α *((r + g*V_next) - V_old). Note: we use r + 0.5*V_next instead of r. A picture showing a mouse going through a maze where each cell is a state and it illustrates the formula."
7f497894-4a52-41f4-aecf-11c3df1f5ceb,train,past,high school,u64,7,group 2,post test,5,8,1,location in the maze,location,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the state of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
5cb4eb4f-69b7-4f53-a3c1-83515f144474,train,future,high school,u64,7,group 2,post test,10,20,0,C,B,"If a problem or a game has a lot of states, like the Go game, then we will need a neural network. What relationship do we expect the neural network to capture? <please select the best answer> A. The reward an agent receive after action  B. The value of a given state of the environment C. The action to take under a state of the environment D. The next state of the environment after agent takes an action",Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
d1fbd6fa-e627-49e4-9b84-95c78fa3713e,train,future,high school,u64,7,group 2,post test,7,19,1,g is introduced to account for the degree of the effect on the future situation,the degree of the effect of the future situation,"In the formula V = V_old + α * ((r + g * V_next) - V_old), why do we introduce g? <please input your answer>","The value function considering future effect. Values: g: the degree of the effect of the future situation. (0<g<1, we assume 0.5). V_next : the value of the best possibe situation next (s’). Note: V_next is looked up from the current table. updated value: V_new = V_old + α *((r + g*V_next) - V_old). Note: we use r + 0.5*V_next instead of r. A picture showing a mouse going through a maze where each cell is a state and it illustrates the formula."
6ead0b59-d953-413f-9026-09e195a53e5c,train,past,high school,u77,7,group 2,post test,3,4,0,B,C,"Please select one of the following which falls into the framework of reinforcement learning. <please select the best answer> A. A computer calculates the digits of π, a mathematical constant which is close to 3.14. B. A neural network learns to distinguish images with known categories as cars or bicycles. C. An autonomous car tries to adapt to changing road conditions without causing accidents. D. A software collects user information and provides personalized recommendations automatically.",The limitation of supervised / unsupervised learning. Context: A baby is learning to walk. Supervised learning. Tell the baby which muscles should be used? A picture of big red X besides supervised learning. Unsupervised learning. Observe sensory inputs or feedback from the feet and legs alone? A picture of big red X besides unsupervised learning. Randomly generate movements and remember how they work in each situation. A picture of big green check mark besides the last sentence. A picture of a crawling baby.
5635efae-8022-4cb8-988e-c1975571c69f,train,past,high school,u77,7,group 2,post test,4,8,1,pacman,pac-man,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the agent of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
9f085127-fa78-43bc-b0c6-4b439e7eeb61,train,past,high school,u77,7,group 2,post test,1,5,0,A,B,True or False: Reinforcement learning gets inputs as well as produces outputs? <please select the best answer> A. True   B. False,"Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
846d0ec8-2e67-4000-ad0c-bf545550b918,train,future,high school,u77,7,group 2,post test,8,17,0,10,35,"An agent receives 3 different rewards from the same state in 3 attempts. The 3 rewards are 20, 40, 45 respectively. Please use the formula V = Vold + 0.5 ✕ (r - Vold) and the initial V as 0 (Hint: Vold is 0 in the first calculation.) to calculate the final V of this state. <please input your answer>","The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. However, r is not always consistent in real world. new state = s. reward = r. Value of s: V = V_old + α * (r - V_old). Averaging the old value with new reward. A picture showing a mouse going through a maze where each cell is a state."
6e0ac95a-c234-47bc-81ed-666f3156510b,train,future,high school,u77,7,group 2,post test,9,16,0,B,D,"An agent is at state (1,1). The possible next states are (1,2), (2,1) and (2,2). We have a lookup dictionary as follows. Which of the following is the V_next? A table of State (1,1), (1,2), (2,1), (2,2) with Value 10, 25, -10, 30 respectively. <please select the best answer> A. 10 B. 25 C.-10 D.30",The details of V-learning. A simple situation: The current reward is the only indicator of the value in the current situation. state = s. reward = r. Value of s: V_s = r. A table of that has a row of states and another row of value that correspond to each state. A picture showing a mouse going through a maze where each cell is a state.
3cbf8670-811b-44ed-93ae-9c2dc79502fd,train,past,high school,u77,7,group 2,post test,2,5,0,A,D,"In reinforcement learning, which two kinds of response does the agent get from its environment? <please select the best answer> A. Action, Reward B. Value, State C. Action, Value D. State, Reward","Reinforcement learning. Reinforcement: When you try something and then get rewarded, you will increase the chance of repeating the action. Reinforcement learning: Operating in a dynamic environment and learning from collected experiences to act correctly. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent."
3c0f2cca-0eaa-4e34-8e7a-4b0445a89cf1,train,future,high school,u77,7,group 2,post test,6,19,0,B,C,"If the value (V) in the current state is only indicated by the current reward (r), what is the relationship between them if we consider the future effect but a consistent reward (i.e. the reward does not change for a state)? <please select the best answer> A. V = r B. V = V_old + 0.1 * (r - V_old) C. V = 0.1 * (r + 0.5 * V_next) D. V = V_old + 0.1 * ((r + 0.5 * V_next) - V_old)","The value function considering future effect. Values: g: the degree of the effect of the future situation. (0<g<1, we assume 0.5). V_next : the value of the best possibe situation next (s’). Note: V_next is looked up from the current table. updated value: V_new = V_old + α *((r + g*V_next) - V_old). Note: we use r + 0.5*V_next instead of r. A picture showing a mouse going through a maze where each cell is a state and it illustrates the formula."
bad28a1e-6ad2-431b-89b9-98e87ad399fa,train,past,high school,u77,7,group 2,post test,5,8,1,where pac-man can see,location,"In the game Pac-Man, the pac-man aims to eat as many beans in the maze as possible without getting caught by the ghosts (blue and pink avatars in the picture). A picture of the game Pac-Man. What is the state of this game? <please input your answer>",An example of reinforcement learning. A mouse tries to get some cheese located at the end of a maze. Agent: learner. The mouse. Environment: The maze. Action: agent produces an output. Turning/running. State: the situation of the world observable by the agent. Location in the maze. Reward: cheese. A picture that illustrate this example of reinforcement learning.
34940304-21a2-4387-b223-cc5aa9973ad4,train,future,high school,u77,7,group 2,post test,10,20,1,B,B,"If a problem or a game has a lot of states, like the Go game, then we will need a neural network. What relationship do we expect the neural network to capture? <please select the best answer> A. The reward an agent receive after action  B. The value of a given state of the environment C. The action to take under a state of the environment D. The next state of the environment after agent takes an action",Neural network: a more complicated situation. A few states: (3 * 6 = 18 states in the mouse-maze example). We only need a table that stores the average evaluation for each state. Large members of states: (chess has possibly 7.7*10^45 states/arrangments). We need a neural network.We train a neural network to output r (reward) when the input is s (state). A picture of chess.
db62702c-e3b9-47ab-80ed-eba21cb2cdc6,train,future,high school,u77,7,group 2,post test,7,19,0,because it is multiplied by alpha to create a value ,the degree of the effect of the future situation,"In the formula V = V_old + α * ((r + g * V_next) - V_old), why do we introduce g? <please input your answer>","The value function considering future effect. Values: g: the degree of the effect of the future situation. (0<g<1, we assume 0.5). V_next : the value of the best possibe situation next (s’). Note: V_next is looked up from the current table. updated value: V_new = V_old + α *((r + g*V_next) - V_old). Note: we use r + 0.5*V_next instead of r. A picture showing a mouse going through a maze where each cell is a state and it illustrates the formula."
6fbde87c-e72d-4cc8-ae61-891aceccb4a2,test,past,high school,u66,11,group 1,post test,3,8,1,Nodes represent something that is a number or can be labeled. Lines represent the correlation between two nodes. ,"numbers/labels, the statistical relationships among them","In graphic models, what does nodes and lines represent? <please input your answer>",Graphical model. Graphical model is a new kind of fast-learning algorithm. Nodes: describe anything that can be represented by numbers or labels. Arrows and lines: show one node’s value ends up with the given value of another node. A picture of an example graph.
54bdcf78-7c44-4616-b41f-782db14841e8,test,past,high school,u66,11,group 1,post test,4,10,1,FSL,few shot learning,What is the name of the method that enables ANNs to learn from limited examples? <please input your answer>,Few-shot learning. Few-shot learning aims to build accurate machine learning models with less training data. A picture highlighting the difference between large data training and few-shot training.
2a60945a-0701-44af-9f81-69f37863957f,test,past,high school,u66,11,group 1,post test,1,4,0,?,backpropagation,Please give an example of mechanism that neurons do not have but neural networks have? <please input your answer>,"The interaction has decreased. A real neuron is made of tiny electrochemical processes that are only roughly approximated in an artificial neuron model. It is unlikely that backpropagation is going on in the brain when people learn, while backpropagation is a powerful algorithm for training ANNs. A picture of backpropagation."
1bd7191e-9576-4fd0-8db1-39729d86c8cd,test,future,high school,u66,11,group 1,post test,8,13,0,?,Generator/Discriminator,What are names of the two smaller models in the the neural network that can generate examples of what it has learned but has not yet seen <please input your answer>,GAN in details. A picture of the GAN architecture (random noise to generator to generate a fake image and a discriminator trying to discriminate that from the training image)
558d7551-1b86-43db-a429-768d56cc2be5,test,future,high school,u66,11,group 1,post test,9,20,1,6,Six,How many layers does the cortex of the human big brain have? <please input your answer>,"The structure of human brain. The “big brain” of humans is made of six layers organized into columns. We don’t precisely understand how the layers and columns work although we know how these cell types are distributed in the layers. Once we find out, the understanding of brain may change and impact ANN technology. A picture showing the six layers of a human brain."
cf482e12-f590-4996-af49-9e4859c2db92,test,past,high school,u66,11,group 1,post test,2,5,1,We should watch for developments so we can improve ANNs and understand more about the brain.,There are still areas where people perform much better than AI,Why should we watch for developments in neuroscience? Please list one reason. <please input your answer>,We should watch for developments in neuroscience. There are still areas where people perform much better than AI. There may be a different operating principle we can learn from biological neural networks. Two pictures that show the similarty between a biological neuron and the one in ANN.
281c1590-63cb-4fde-93bf-3729c618d4a5,test,future,high school,u66,11,group 1,post test,6,14,1,Transfer learning can take an existing large sample and transfer it to another neural network.,The original task and the applied task have some common features,In which condition can transfer learning reduce the time to train for the new task? (Hint: not a exact example like CNN.) <please input your answer>,Transfer learning to new areas. Humans also seem to have the ability to transfer learning to new areas. A network trained for one task may be able to be trained for another task faster if the original task and the applied task have some common features. A picture showing transfer learning where the source data/labels are larger than the target data/labels.
9f8c78c2-c0e5-4458-b067-f30efccb3794,test,past,high school,u66,11,group 1,post test,5,14,1,It is possible because it can use the knowledge it already knows. ,It is possible because it can use the knowledge it already knows.,Why it is possible for ANNs to solve the task with very limited data? <please input your answer>,Transfer learning to new areas. Humans also seem to have the ability to transfer learning to new areas. A network trained for one task may be able to be trained for another task faster if the original task and the applied task have some common features. A picture showing transfer learning where the source data/labels are larger than the target data/labels.
f1fda47f-c722-4e18-b20a-ead11b412d0e,test,future,high school,u66,11,group 1,post test,7,12,1,GAN,Generative model,What is the name of the neural network that can generate new examples of what it has learned but has not yet seen? <please input your answer>,Generative model. Another thing that humans have but machines seem to lack is creativity. ANN models called the generative model can create examples after learning. Generative adversarial network (GAN) learns to generate outputs indistinguishable from the real data. Images generated by GAN.
952619c6-a257-42a7-9bc7-6e7e21d8bd3f,test,past,high school,u76,11,group 1,post test,3,8,0,The amounts ,"numbers/labels, the statistical relationships among them","In graphic models, what does nodes and lines represent? <please input your answer>",Graphical model. Graphical model is a new kind of fast-learning algorithm. Nodes: describe anything that can be represented by numbers or labels. Arrows and lines: show one node’s value ends up with the given value of another node. A picture of an example graph.
f11b3d07-fcd2-4a34-907b-11574bb14ec8,test,past,high school,u76,11,group 1,post test,4,10,0,CNN,few shot learning,What is the name of the method that enables ANNs to learn from limited examples? <please input your answer>,Few-shot learning. Few-shot learning aims to build accurate machine learning models with less training data. A picture highlighting the difference between large data training and few-shot training.
82195476-aebb-43dd-a7a2-b565fa7b7be9,test,past,high school,u76,11,group 1,post test,1,4,0,ANN,backpropagation,Please give an example of mechanism that neurons do not have but neural networks have? <please input your answer>,"The interaction has decreased. A real neuron is made of tiny electrochemical processes that are only roughly approximated in an artificial neuron model. It is unlikely that backpropagation is going on in the brain when people learn, while backpropagation is a powerful algorithm for training ANNs. A picture of backpropagation."
1e1625d1-7668-45be-a1a5-5de446a9ba77,test,future,high school,u76,11,group 1,post test,8,13,0,CNN ,Generator/Discriminator,What are names of the two smaller models in the the neural network that can generate examples of what it has learned but has not yet seen <please input your answer>,GAN in details. A picture of the GAN architecture (random noise to generator to generate a fake image and a discriminator trying to discriminate that from the training image)
ea48113e-ec1f-4bd2-bacd-1fdc3f792ab8,test,future,high school,u76,11,group 1,post test,9,20,0,4,Six,How many layers does the cortex of the human big brain have? <please input your answer>,"The structure of human brain. The “big brain” of humans is made of six layers organized into columns. We don’t precisely understand how the layers and columns work although we know how these cell types are distributed in the layers. Once we find out, the understanding of brain may change and impact ANN technology. A picture showing the six layers of a human brain."
919b287a-f898-43e0-b9c6-594d870b696e,test,past,high school,u76,11,group 1,post test,2,5,1,To understand it more,There are still areas where people perform much better than AI,Why should we watch for developments in neuroscience? Please list one reason. <please input your answer>,We should watch for developments in neuroscience. There are still areas where people perform much better than AI. There may be a different operating principle we can learn from biological neural networks. Two pictures that show the similarty between a biological neuron and the one in ANN.
057a9225-70e1-495e-bc8e-1a1387b9a965,test,future,high school,u76,11,group 1,post test,6,14,0,ANN,The original task and the applied task have some common features,In which condition can transfer learning reduce the time to train for the new task? (Hint: not a exact example like CNN.) <please input your answer>,Transfer learning to new areas. Humans also seem to have the ability to transfer learning to new areas. A network trained for one task may be able to be trained for another task faster if the original task and the applied task have some common features. A picture showing transfer learning where the source data/labels are larger than the target data/labels.
214e446a-258d-4c53-af29-aa2e9fe8318b,test,past,high school,u76,11,group 1,post test,5,14,0,Dont know ,It is possible because it can use the knowledge it already knows.,Why it is possible for ANNs to solve the task with very limited data? <please input your answer>,Transfer learning to new areas. Humans also seem to have the ability to transfer learning to new areas. A network trained for one task may be able to be trained for another task faster if the original task and the applied task have some common features. A picture showing transfer learning where the source data/labels are larger than the target data/labels.
13b876b6-2d55-422b-9d76-26eff9027454,test,future,high school,u76,11,group 1,post test,7,12,0,EEG,Generative model,What is the name of the neural network that can generate new examples of what it has learned but has not yet seen? <please input your answer>,Generative model. Another thing that humans have but machines seem to lack is creativity. ANN models called the generative model can create examples after learning. Generative adversarial network (GAN) learns to generate outputs indistinguishable from the real data. Images generated by GAN.
4c89886a-abd9-4434-a96b-3846b24a659e,train,past,high school,u64,11,group 2,post test,3,8,1,ideas and how they're connected,"numbers/labels, the statistical relationships among them","In graphic models, what does nodes and lines represent? <please input your answer>",Graphical model. Graphical model is a new kind of fast-learning algorithm. Nodes: describe anything that can be represented by numbers or labels. Arrows and lines: show one node’s value ends up with the given value of another node. A picture of an example graph.
3c2f6132-313b-4a25-a6e7-73a636006d1c,train,past,high school,u64,11,group 2,post test,4,10,1,few shot learning,few shot learning,What is the name of the method that enables ANNs to learn from limited examples? <please input your answer>,Few-shot learning. Few-shot learning aims to build accurate machine learning models with less training data. A picture highlighting the difference between large data training and few-shot training.
f2b626a0-422f-4b10-918a-9373c5114eb4,train,past,high school,u64,11,group 2,post test,1,4,1,neural networks can combine information from many neurons,backpropagation,Please give an example of mechanism that neurons do not have but neural networks have? <please input your answer>,"The interaction has decreased. A real neuron is made of tiny electrochemical processes that are only roughly approximated in an artificial neuron model. It is unlikely that backpropagation is going on in the brain when people learn, while backpropagation is a powerful algorithm for training ANNs. A picture of backpropagation."
26b19cbe-0300-44f2-8ebd-7678865ecc1c,train,future,high school,u64,11,group 2,post test,8,13,0,not sure,Generator/Discriminator,What are names of the two smaller models in the the neural network that can generate examples of what it has learned but has not yet seen <please input your answer>,GAN in details. A picture of the GAN architecture (random noise to generator to generate a fake image and a discriminator trying to discriminate that from the training image)
77f1c93b-0a6e-42b8-8282-92fdf6da247c,train,future,high school,u64,11,group 2,post test,9,20,1,6,Six,How many layers does the cortex of the human big brain have? <please input your answer>,"The structure of human brain. The “big brain” of humans is made of six layers organized into columns. We don’t precisely understand how the layers and columns work although we know how these cell types are distributed in the layers. Once we find out, the understanding of brain may change and impact ANN technology. A picture showing the six layers of a human brain."
77dbf7fb-1c99-44fd-a4dd-5926483264f9,train,past,high school,u64,11,group 2,post test,2,5,1,many areas where people perform better than AI; different operating principles can learn from the brain,There are still areas where people perform much better than AI,Why should we watch for developments in neuroscience? Please list one reason. <please input your answer>,We should watch for developments in neuroscience. There are still areas where people perform much better than AI. There may be a different operating principle we can learn from biological neural networks. Two pictures that show the similarty between a biological neuron and the one in ANN.
d2fb49a8-15b9-4a1b-a179-f8a29eef75d0,train,future,high school,u64,11,group 2,post test,6,14,1,if there are some common features,The original task and the applied task have some common features,In which condition can transfer learning reduce the time to train for the new task? (Hint: not a exact example like CNN.) <please input your answer>,Transfer learning to new areas. Humans also seem to have the ability to transfer learning to new areas. A network trained for one task may be able to be trained for another task faster if the original task and the applied task have some common features. A picture showing transfer learning where the source data/labels are larger than the target data/labels.
9513a81a-f940-4573-b59f-5c78a08c923c,train,past,high school,u64,11,group 2,post test,5,14,0,generative models can create examples after learning,It is possible because it can use the knowledge it already knows.,Why it is possible for ANNs to solve the task with very limited data? <please input your answer>,Transfer learning to new areas. Humans also seem to have the ability to transfer learning to new areas. A network trained for one task may be able to be trained for another task faster if the original task and the applied task have some common features. A picture showing transfer learning where the source data/labels are larger than the target data/labels.
d9dc2071-9411-4d8c-83ac-c0ed52032611,train,future,high school,u64,11,group 2,post test,7,12,1,GAN,Generative model,What is the name of the neural network that can generate new examples of what it has learned but has not yet seen? <please input your answer>,Generative model. Another thing that humans have but machines seem to lack is creativity. ANN models called the generative model can create examples after learning. Generative adversarial network (GAN) learns to generate outputs indistinguishable from the real data. Images generated by GAN.
7c93dcf5-5676-403e-84e0-85703cd2d9f7,train,past,high school,u79,1,group 1,post test,3,21,1,Supervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
532748d7-9b76-4cfe-a9d5-6ae0501e9945,train,past,high school,u79,1,group 1,post test,4,23,0,Unsupervised learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Reinforcement learning is learning from a teacher who lets you try and then tells you how well you did. Takes a long time sometimes the only way. It contains a picture of reinforcement learning.
7e524af3-4203-45e5-93ee-8a315ef8fd08,train,past,high school,u79,1,group 1,post test,1,5,0,Machine Learning,A,Which of the following three concepts appeared first? <please select the best answer> A. Artificial Intelligence B. Machine Learning C. Deep Learning,Artificial Intelligence. According to Wikipedia AI is 'intelligence demonstrated by machines in contrast to the natural intelligence displayed by humans and other animals'. It contains a picture of the development of AI.
e50b7ab9-0875-4270-98ae-0d4b1ddb2d85,train,future,high school,u79,1,group 1,post test,8,18,1,Synapses,Synapses,What are the connections between the cells in the brains called? <please input your answer>,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
bf10c037-2809-4fe6-90c0-aa84bb7e9d72,train,future,high school,u79,1,group 1,post test,9,9,1,The sum of three of a right triangle is 180 degrees.,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of commonsense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
1a63e484-cb6e-464f-9ea7-492663d31548,train,past,high school,u79,1,group 1,post test,2,8,0,Deduction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. necessity and probability (model logic) time (temporal logic). Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
59c59288-4b4e-4fce-8cf0-31cab9d08371,train,future,high school,u79,1,group 1,post test,6,11,1,1/6,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
b3d8bbf9-2ef0-4794-9ea7-0c650ca48192,train,past,high school,u79,1,group 1,post test,5,2,0,"AI, Deep Learning, Neural Learning","Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
56001564-ba42-47a0-a0d4-74a78b34716a,train,future,high school,u79,1,group 1,post test,10,7,0,8%,P(A|B) = (0.07*0.1)/0.05 = 0.14,"We have known 10% of patients have liver disease, and 5% of the patients are alcoholics. And we know that among those patients diagnosed with liver disease, 7% are alcoholics. What is the patient's probability of having liver disease if they are an alcoholic? <please input your answer>",Logic. Logic: a method of using facts and rules to decide on the truth of a statement. e.g. 'Candies are sweet' and 'A lollipop is a candy' we can infer 'A lollipop is sweet'. 'All humans are mortal' and 'Socrates is a human' we can infer 'Socrates dies'. It contains a picture of an example of logic.
4cd1653f-5a32-43ce-ae6d-a109f7966741,train,future,high school,u79,1,group 1,post test,7,18,1,Neurons,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
67799737-f053-4ffb-9dbb-24564393dbcb,train,past,high school,u70,1,group 1,post test,3,21,1,Supervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
3e591d88-6e5e-4b08-bd33-bff93f5ef913,train,past,high school,u70,1,group 1,post test,4,23,0,Unsupervised learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Reinforcement learning is learning from a teacher who lets you try and then tells you how well you did. Takes a long time sometimes the only way. It contains a picture of reinforcement learning.
b3a48c8d-a005-4223-ac25-c79318f3505c,train,past,high school,u70,1,group 1,post test,1,5,1,Artificial Intelligence,A,Which of the following three concepts appeared first? <please select the best answer> A. Artificial Intelligence B. Machine Learning C. Deep Learning,Artificial Intelligence. According to Wikipedia AI is 'intelligence demonstrated by machines in contrast to the natural intelligence displayed by humans and other animals'. It contains a picture of the development of AI.
dd5bcc13-85bc-4815-8473-4895d3a3c03e,train,future,high school,u70,1,group 1,post test,8,18,1,synapses,Synapses,What are the connections between the cells in the brains called? <please input your answer>,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
a1a0f9e5-b8a3-40ef-be1d-83381570e9e2,train,future,high school,u70,1,group 1,post test,9,9,0,dont know,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of commonsense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
98872b2e-d457-4f6e-a706-0ed1325277a4,train,past,high school,u70,1,group 1,post test,2,8,1,Induction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. necessity and probability (model logic) time (temporal logic). Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
afa80d67-fc44-461c-8167-60b951303d93,train,future,high school,u70,1,group 1,post test,6,11,1,1/6,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
98e800a3-f68d-4d91-9058-3855e3b58c7f,train,past,high school,u70,1,group 1,post test,5,2,0,Dont know ,"Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
373e115d-eee7-4cca-989d-aac168f204ae,train,future,high school,u70,1,group 1,post test,10,7,0,dont know,P(A|B) = (0.07*0.1)/0.05 = 0.14,"We have known 10% of patients have liver disease, and 5% of the patients are alcoholics. And we know that among those patients diagnosed with liver disease, 7% are alcoholics. What is the patient's probability of having liver disease if they are an alcoholic? <please input your answer>",Logic. Logic: a method of using facts and rules to decide on the truth of a statement. e.g. 'Candies are sweet' and 'A lollipop is a candy' we can infer 'A lollipop is sweet'. 'All humans are mortal' and 'Socrates is a human' we can infer 'Socrates dies'. It contains a picture of an example of logic.
775bddb8-5146-4dc5-bcf2-b202f2429284,train,future,high school,u70,1,group 1,post test,7,18,1,neurons,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
327b3411-e025-418f-a364-d8cbc881f5eb,test,past,high school,u62,1,group 1,post test,3,21,1,Supervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
f89c9b81-85e4-4fa0-af67-6af9d983f793,test,past,high school,u62,1,group 1,post test,4,23,1,Reinforcement learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Reinforcement learning is learning from a teacher who lets you try and then tells you how well you did. Takes a long time sometimes the only way. It contains a picture of reinforcement learning.
0c93d225-cb8f-417e-b135-d457662c19c0,test,past,high school,u62,1,group 1,post test,1,5,1,Artificial Intelligence,A,Which of the following three concepts appeared first? <please select the best answer> A. Artificial Intelligence B. Machine Learning C. Deep Learning,Artificial Intelligence. According to Wikipedia AI is 'intelligence demonstrated by machines in contrast to the natural intelligence displayed by humans and other animals'. It contains a picture of the development of AI.
83be79ae-87f3-449e-9469-39993ba48beb,test,future,high school,u62,1,group 1,post test,8,18,1,synapses,Synapses,What are the connections between the cells in the brains called? <please input your answer>,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
5af3c6e1-4529-4bd8-80e7-833b684d7b3a,test,future,high school,u62,1,group 1,post test,9,9,1,A right triangle has a sum of 180 degrees.,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of commonsense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
618a3b38-68cb-407c-b2e9-428c8e58722c,test,past,high school,u62,1,group 1,post test,2,8,0,Deduction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. necessity and probability (model logic) time (temporal logic). Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
451a0caf-c3eb-4ee8-8520-c1c5e95e7cf1,test,future,high school,u62,1,group 1,post test,6,11,1,1/6,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
0d9f78de-0813-42cc-89af-e6b5e95c5bec,test,past,high school,u62,1,group 1,post test,5,2,0,"Artificial neural network, logic, learning","Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
8a607011-501c-42bf-a9cd-dc8fc6a4eef3,test,future,high school,u62,1,group 1,post test,10,7,1,3.5%,P(A|B) = (0.07*0.1)/0.05 = 0.14,"We have known 10% of patients have liver disease, and 5% of the patients are alcoholics. And we know that among those patients diagnosed with liver disease, 7% are alcoholics. What is the patient's probability of having liver disease if they are an alcoholic? <please input your answer>",Logic. Logic: a method of using facts and rules to decide on the truth of a statement. e.g. 'Candies are sweet' and 'A lollipop is a candy' we can infer 'A lollipop is sweet'. 'All humans are mortal' and 'Socrates is a human' we can infer 'Socrates dies'. It contains a picture of an example of logic.
7c665354-644a-4027-af42-f4b28d52b8df,test,future,high school,u62,1,group 1,post test,7,18,1,neurons,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
c634e49e-9a40-4e07-9f91-0699b58765eb,train,past,high school,u73,1,group 2,post test,3,21,1,Supervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
1f0d6716-6bce-4cf2-9ea8-fafd7316bb16,train,past,high school,u73,1,group 2,post test,4,23,1,Reinforcement learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Reinforcement learning is learning from a teacher who lets you try and then tells you how well you did. Takes a long time sometimes the only way. It contains a picture of reinforcement learning.
63dda4d1-dd20-41c0-a6b3-d546f2970948,train,past,high school,u73,1,group 2,post test,1,5,1,Artificial Intelligence,A,Which of the following three concepts appeared first? <please select the best answer> A. Artificial Intelligence B. Machine Learning C. Deep Learning,Artificial Intelligence. According to Wikipedia AI is 'intelligence demonstrated by machines in contrast to the natural intelligence displayed by humans and other animals'. It contains a picture of the development of AI.
abd5bdb6-fcc8-4656-81d0-1cc7f9455eb6,train,future,high school,u73,1,group 2,post test,8,18,1,Synapses,Synapses,What are the connections between the cells in the brains called? <please input your answer>,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
535faf1e-33fa-4226-b596-cdb38309ee3e,train,future,high school,u73,1,group 2,post test,9,9,1,The sum of three angles of a right triangle is also 180 degrees,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of commonsense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
7e02706d-5158-4cb0-8207-cf1a5390480a,train,past,high school,u73,1,group 2,post test,2,8,0,Deduction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. necessity and probability (model logic) time (temporal logic). Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
5f3ff047-1f9e-4ff3-8306-9dfd0fb08d7e,train,future,high school,u73,1,group 2,post test,6,11,0,I don't know,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
7040b818-3e17-4d34-9acf-bd11bee774d2,train,past,high school,u73,1,group 2,post test,5,2,0,I'm not sure,"Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
21481310-e4f9-46fa-881e-add708476935,train,future,high school,u73,1,group 2,post test,10,7,1,7/50,P(A|B) = (0.07*0.1)/0.05 = 0.14,"We have known 10% of patients have liver disease, and 5% of the patients are alcoholics. And we know that among those patients diagnosed with liver disease, 7% are alcoholics. What is the patient's probability of having liver disease if they are an alcoholic? <please input your answer>",Logic. Logic: a method of using facts and rules to decide on the truth of a statement. e.g. 'Candies are sweet' and 'A lollipop is a candy' we can infer 'A lollipop is sweet'. 'All humans are mortal' and 'Socrates is a human' we can infer 'Socrates dies'. It contains a picture of an example of logic.
849a2082-d13c-49e8-a3cb-4305ffb9996e,train,future,high school,u73,1,group 2,post test,7,18,1,Neurons,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
1727a940-01ea-44d7-aebf-a9a474d81acc,train,past,high school,u68,1,group 2,post test,3,21,1,Supervised learning,A,Which of the three ways of learning requires all input data to be paired with correct answers? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Supervised learning neural networks are given training data and then compute an output which they compare to the desired output provided by the teacher. effective but requires that all input data are paired with correct answers. It contains a picture of supervised learning.
5f1e6cb6-1cac-4408-b5e6-9e7f64a073e3,train,past,high school,u68,1,group 2,post test,4,23,1,Reinforcement learning,C,Which of the three ways of learning is sometimes the only way we can use? <please select the best answer> A. Supervised learning B. Unsupervised learning C. Reinforcement learning,Three ways of learning. Reinforcement learning is learning from a teacher who lets you try and then tells you how well you did. Takes a long time sometimes the only way. It contains a picture of reinforcement learning.
e69939b3-04bb-4614-9c94-2f451b1da4fa,train,past,high school,u68,1,group 2,post test,1,5,1,Artificial Intelligence,A,Which of the following three concepts appeared first? <please select the best answer> A. Artificial Intelligence B. Machine Learning C. Deep Learning,Artificial Intelligence. According to Wikipedia AI is 'intelligence demonstrated by machines in contrast to the natural intelligence displayed by humans and other animals'. It contains a picture of the development of AI.
89307b06-d63a-4208-b80f-0e006483d906,train,future,high school,u68,1,group 2,post test,8,18,1,synapses,Synapses,What are the connections between the cells in the brains called? <please input your answer>,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
e5a281ac-7d63-461b-8e07-2c8b4fc30d4d,train,future,high school,u68,1,group 2,post test,9,9,1,the other 2 angles in a right triangle must sum to 180,The sum of the three angles of a right triangle is 180 degrees,The sum of three angles of any triangle is 180 degrees. A right triangle is a triangle. What can you conclude from these? <please input your answer>,Problems with logic-based AI. A lot of commonsense knowledge is required and it’s almost impossible to gather a sufficient amount of this knowledge. The computer must know the real-world meaning of words. Simple symbolic logic does not work well when things are uncertain. It contains two pictures of the problems with logic-based AI. One is chocolate and the other is about the weather.
1f92e660-c06b-4552-a91e-f9f6b9e9c21a,train,past,high school,u68,1,group 2,post test,2,8,1,Induction,B,Which of the following two concepts means 'learning by generating rules from known facts'? <please select the best answer> A. Deduction B. Induction,Logic used in AI. necessity and probability (model logic) time (temporal logic). Deduction infer new facts from already known facts and rules. Induction learn by generating rules from known facts. store the knowledge. computer can think. Logic.
e65445b3-9c7d-4b0c-bd57-1f47d6376403,train,future,high school,u68,1,group 2,post test,6,11,1,1/6,1/6,The probability that the number of dice rolls is 1 is? <please input your answer>,Statistics. Statistics talks about the probability of something happening deals with uncertainties. The probability of an event is a number between 0 and 1. It contains a picture demonstrating the probability.
7ebe976d-20ca-474a-9b06-3004f08d6bff,train,past,high school,u68,1,group 2,post test,5,2,0,"learning, reasoning, problem solving","Logic, statistics, ANNs",What are the three components of AI? <please input your answer>,Outline. Artificial intelligence everywhere. Logic. Statistics. Artificial neural networks.
ad440594-a00b-47f4-ad45-f40a81d0597f,train,future,high school,u68,1,group 2,post test,10,7,0,0.035,P(A|B) = (0.07*0.1)/0.05 = 0.14,"We have known 10% of patients have liver disease, and 5% of the patients are alcoholics. And we know that among those patients diagnosed with liver disease, 7% are alcoholics. What is the patient's probability of having liver disease if they are an alcoholic? <please input your answer>",Logic. Logic: a method of using facts and rules to decide on the truth of a statement. e.g. 'Candies are sweet' and 'A lollipop is a candy' we can infer 'A lollipop is sweet'. 'All humans are mortal' and 'Socrates is a human' we can infer 'Socrates dies'. It contains a picture of an example of logic.
f3470802-e2b3-47ee-9b97-3d5c19259cfd,train,future,high school,u68,1,group 2,post test,7,18,1,neurons,Neurons,What are the cells in the brain that are used for thinking called? <please input your answer>,Brain. A human brain is made of 100 billion tiny cells called neurons. (1) inputs that collect signals from other neurons. (2) a decision-making section. (3) output that sends out its decision. A neuron learns by changing the connection weight to a synaptic weight. It contains two pictures of neurons.
fa498efa-cdca-4b52-a6ca-280a470dc762,train,past,high school,u64,8,group 1,post test,3,6,1,C,C,Q-Table is the main aim of steps of Q-Learning. Q-table records the long rewards for? <please select the best answer> A. different actions B. different states C. different actions taken in each state,The steps of Q-Learning. Initialize Q table. Choose an action a. Perform action. Measure reward. Update Q. Go back to Choose an action a. At the end of the training: Good Q* table. Q-table is a table that records Q-values. Q-value: the maximum expectation of long-term rewards for different actions taken in each state. Value: the total reward that an agent can expect to collect from that state and onwards into the future.
8753cf4c-d8da-4089-9dca-6f32df508f4a,train,past,high school,u64,8,group 1,post test,4,9,1,B,B,"If the value in the current state is only indicated by the current reward, but reward (r) is not always consistent, which of these formulas should we use to calculate Q value? <please select the best answer> A. Q=r B. Q_new = Q_old + 0.1*(r-Q_old) C. Q_old + 0.1* ((r+0.5*Q_next)-Q_old)","Q-learning details. However, r is not always consistent in real world. We can smooth out different evaluations of the same situation-action pair as in V-learning. Action that would result in the best next state = a’. Best next state = s’. Q function of a’ and s’: Q_new = Q_old + α*(r-Q_old). A picture of a real life digital mouse trying to find cheese in a maze. A table with different actions being the columns, different states being the actions, and each cell being the reward corresponding to that state and action which is Q_old + 0.1*(r-Q_old)."
567443f3-e960-40d5-b412-d8519dc12b45,train,past,high school,u64,8,group 1,post test,1,3,1,B,B,True or False: The “reward” in the V-Learning means the total reward that an agent can expect to collect from that state and onwards into the future. <please select the best answer> A. True   B. False,"Quick review: reinforcement learning and V-learning. A picture showing 3 types of machine learning: unsupervised, supervised, and reinforcement. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent. Reward: the instantaneous benefit of being in a specific state, Value: the total reward that an agent can expect to collect from that state and onwards into the future. V-learning learns the value for different situations, i.e. how good the situation is."
5cabeab6-ef06-4a93-a62c-f9bedef35a59,train,future,high school,u64,8,group 1,post test,8,18,1,C,C,Which kind of sensors bounce pulses of light off the car’s surroundings to measure distances? <please select the best answer> A. Radar sensors B. Video cameras C. Lidar sensors D. Ultrasonic sensors,How do autonumous cars work? Lidar (light detection and ranging) sensors bounce pulses of light off the car’s surroundings to measure distances. Ultrasonic sensors in the wheels detect curbs and other vehicles when parking. A picture of lidar. A picture of Ultrasonic sensors.
741a5b41-2c3a-4450-bb18-eea497a0a56e,train,future,high school,u64,8,group 1,post test,9,25,1,D,D,"An agent is at state (1,1), and the Q-table is as follows. Which of the actions should the agent take? Content of Q-table: The rewards of action going right/left/up/down at state (1,1) are 10,25,-10,30 respectively. The rewards of action going right/left/up/down at state (1,2) are 20,-10,15,25 respectively. The rewards of action going right/left/up/down at state (2,1) are 30,10,15,-10 respectively. The rewards of action going right/left/up/down at state (2,2) are 25,30,10,-10 respectively. <please select the best answer> A. going right B. going left C. going up D. going down","Q-table. We learn how good it is to take a specific action a in the situation s. e.g. s is the arrangement of pieces on a chessboard, a is a possible move. We can look up the resultant evaluation r in a lookup table. The table can be used to locate the best action by looking through the entries with the current situation s. A table of rewards corresponding to action/state."
3b153db7-08e0-475e-8b71-9540560bb0e1,train,past,high school,u64,8,group 1,post test,2,4,1,how good it is to perform a given action in a given state,Action,"Both V-learning and Q-learning determine how good the new state is , but Q-learning learns the evaluation specific to something in addition to the state. What is it? <please input your answer>","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
6ff0b3d9-f505-41be-804b-7e7861745f53,train,future,high school,u64,8,group 1,post test,6,20,1,"Bad weather (rain, dust, etc.) can decrease the accuracy of sensors/cameras.",The responsibility for crashes or something else that applies or some else,Can you name one issue or challenge that involves autonomous cars? <please input your answer>,Challenges with autonomous cars. Accident Liability: Who is liable for accidents caused by an autonomous car? Artificial vs. Emotional Intelligence: Human drivers rely on subtle cues and non-verbal communication to make split-second judgment calls and predict behaviors. A picture of a car crash.
b09f28f5-58a6-4386-9022-b381f8dbbf16,train,past,high school,u64,8,group 1,post test,5,15,1,"The automated system, instead of humans, monitors the driving environment","Of the Level 0-2, the human monitors the driving environment, of the level 3-5, the autonomous cars can monitors the driving environment.",The Society of Automotive Engineers (SAE) currently defines 6 levels of driving automation. Please describe the main difference between Level 0-2 and Level 3-5? <please input your answer>,6 levels of driving automation. The Society of Automotive Engineers (SAE) currently defines 6 levels of drving automation ranging from Level 0 (fully manual) to Level 5 (fully autonomous). Level 0-2: The human monitors the driving environment. Level 3-5: The automated system monitors the driving environment. A picture of the 6 levels of driving automation.
1edb1214-5764-4d2a-a616-9c73e537be0f,train,future,high school,u64,8,group 1,post test,10,11,1,B,B,"About how to choose action in the initial state, which of the approaches aim to collect the most reward you already know about? <please select the best answer> A. Exploration   B. Exploitation",A missing point: how to choose action? Exploration: Explore new area in the environment. Exploitation: Collect the most reward you already know about. Two animations showing two different total rewards a agent could get by choosing different actions.
ada28216-6772-4e87-9853-c698dd0d43b7,train,future,high school,u64,8,group 1,post test,7,16,1,"environment: traffic lights, pedestrians, other cars, road signs. state: current location, green/red light, position of pedestrians, speed limit","Environments: Many components. Traffic lights, pedestrian Actions: Brake, accelerate, turn left",Autonomous cars are under the framework. Please list some kinds of “environments” and “actions” in the situation of autonomous cars? <please input your answer>,"Under the framework of reinforcement learning. Agent: The car or the computer inside the car. Environment: Many components. Traffic lights, pedestrian, other cars, road signs... State: Current location, green/red light, position of pedstrain, speed limit... Action: Brake, accelerate, turn left... Reward: No accident. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent where the agent is the car and the environment is the world."
4722dee3-15ab-4674-be42-415b0e5b9e75,test,past,high school,u66,8,group 1,post test,3,6,1,C,C,Q-Table is the main aim of steps of Q-Learning. Q-table records the long rewards for? <please select the best answer> A. different actions B. different states C. different actions taken in each state,The steps of Q-Learning. Initialize Q table. Choose an action a. Perform action. Measure reward. Update Q. Go back to Choose an action a. At the end of the training: Good Q* table. Q-table is a table that records Q-values. Q-value: the maximum expectation of long-term rewards for different actions taken in each state. Value: the total reward that an agent can expect to collect from that state and onwards into the future.
c57d9b05-bfc0-4dea-bcbd-d9c520492e93,test,past,high school,u66,8,group 1,post test,4,9,1,B,B,"If the value in the current state is only indicated by the current reward, but reward (r) is not always consistent, which of these formulas should we use to calculate Q value? <please select the best answer> A. Q=r B. Q_new = Q_old + 0.1*(r-Q_old) C. Q_old + 0.1* ((r+0.5*Q_next)-Q_old)","Q-learning details. However, r is not always consistent in real world. We can smooth out different evaluations of the same situation-action pair as in V-learning. Action that would result in the best next state = a’. Best next state = s’. Q function of a’ and s’: Q_new = Q_old + α*(r-Q_old). A picture of a real life digital mouse trying to find cheese in a maze. A table with different actions being the columns, different states being the actions, and each cell being the reward corresponding to that state and action which is Q_old + 0.1*(r-Q_old)."
0215878c-758d-4f2d-adcd-4e37f0d09b87,test,past,high school,u66,8,group 1,post test,1,3,1,B,B,True or False: The “reward” in the V-Learning means the total reward that an agent can expect to collect from that state and onwards into the future. <please select the best answer> A. True   B. False,"Quick review: reinforcement learning and V-learning. A picture showing 3 types of machine learning: unsupervised, supervised, and reinforcement. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent. Reward: the instantaneous benefit of being in a specific state, Value: the total reward that an agent can expect to collect from that state and onwards into the future. V-learning learns the value for different situations, i.e. how good the situation is."
945a18d3-587e-4198-84db-c9d3766593fe,test,future,high school,u66,8,group 1,post test,8,18,1,C,C,Which kind of sensors bounce pulses of light off the car’s surroundings to measure distances? <please select the best answer> A. Radar sensors B. Video cameras C. Lidar sensors D. Ultrasonic sensors,How do autonumous cars work? Lidar (light detection and ranging) sensors bounce pulses of light off the car’s surroundings to measure distances. Ultrasonic sensors in the wheels detect curbs and other vehicles when parking. A picture of lidar. A picture of Ultrasonic sensors.
417458a1-5c61-4041-be8b-313fd5cfd631,test,future,high school,u66,8,group 1,post test,9,25,1,D,D,"An agent is at state (1,1), and the Q-table is as follows. Which of the actions should the agent take? Content of Q-table: The rewards of action going right/left/up/down at state (1,1) are 10,25,-10,30 respectively. The rewards of action going right/left/up/down at state (1,2) are 20,-10,15,25 respectively. The rewards of action going right/left/up/down at state (2,1) are 30,10,15,-10 respectively. The rewards of action going right/left/up/down at state (2,2) are 25,30,10,-10 respectively. <please select the best answer> A. going right B. going left C. going up D. going down","Q-table. We learn how good it is to take a specific action a in the situation s. e.g. s is the arrangement of pieces on a chessboard, a is a possible move. We can look up the resultant evaluation r in a lookup table. The table can be used to locate the best action by looking through the entries with the current situation s. A table of rewards corresponding to action/state."
189cbb46-f64c-47c6-b1f9-d1bbab839642,test,past,high school,u66,8,group 1,post test,2,4,1,an action,Action,"Both V-learning and Q-learning determine how good the new state is , but Q-learning learns the evaluation specific to something in addition to the state. What is it? <please input your answer>","Q-learning. V-learning: how good it is for the agent to be in a given state. Q-learning: how good it is to perform a given action in a given state. Breakdown of the interaction between the agent and the environment: Agent collects the initial state S0 of the robot from the environment. Based on S0 state, take action A0. Get reward R1 from the environment. Transition to the new evironment---state S1. A: action  S: state  R: reward. A picture of a robot crossing a thin bridge."
f2422b72-9dfc-4b5d-8b19-0d715b1ebcc2,test,future,high school,u66,8,group 1,post test,6,20,1,The cost of the cars. ,The responsibility for crashes or something else that applies or some else,Can you name one issue or challenge that involves autonomous cars? <please input your answer>,Challenges with autonomous cars. Accident Liability: Who is liable for accidents caused by an autonomous car? Artificial vs. Emotional Intelligence: Human drivers rely on subtle cues and non-verbal communication to make split-second judgment calls and predict behaviors. A picture of a car crash.
1d2f2c90-5706-4f82-b7f3-0f7af3c7db60,test,past,high school,u66,8,group 1,post test,5,15,1,The level of monitorization.,"Of the Level 0-2, the human monitors the driving environment, of the level 3-5, the autonomous cars can monitors the driving environment.",The Society of Automotive Engineers (SAE) currently defines 6 levels of driving automation. Please describe the main difference between Level 0-2 and Level 3-5? <please input your answer>,6 levels of driving automation. The Society of Automotive Engineers (SAE) currently defines 6 levels of drving automation ranging from Level 0 (fully manual) to Level 5 (fully autonomous). Level 0-2: The human monitors the driving environment. Level 3-5: The automated system monitors the driving environment. A picture of the 6 levels of driving automation.
a3408efb-f394-4be0-aa8c-2c2739ccf289,test,future,high school,u66,8,group 1,post test,10,11,1,B,B,"About how to choose action in the initial state, which of the approaches aim to collect the most reward you already know about? <please select the best answer> A. Exploration   B. Exploitation",A missing point: how to choose action? Exploration: Explore new area in the environment. Exploitation: Collect the most reward you already know about. Two animations showing two different total rewards a agent could get by choosing different actions.
d614ed70-63d2-495f-964e-4188e8a98676,test,future,high school,u66,8,group 1,post test,7,16,1,"Pedestrians, traffic lights, lanes, braking, turning, switching lanes.","Environments: Many components. Traffic lights, pedestrian Actions: Brake, accelerate, turn left",Autonomous cars are under the framework. Please list some kinds of “environments” and “actions” in the situation of autonomous cars? <please input your answer>,"Under the framework of reinforcement learning. Agent: The car or the computer inside the car. Environment: Many components. Traffic lights, pedestrian, other cars, road signs... State: Current location, green/red light, position of pedstrain, speed limit... Action: Brake, accelerate, turn left... Reward: No accident. A picture of an agent doing action to the environment and environment returns rewards and observations to the agent where the agent is the car and the environment is the world."
7b3c45f8-8a7e-460e-8407-fe76a62be471,test,past,high school,u66,9,group 1,post test,3,4,1,Speech Recognition,Linguistic analysis / Database / Web content retrieval,Please cite a component of voice-controlled assistant that it needs for normal work. <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
54de8b7b-e9e4-4860-b077-10404f2137c9,test,past,high school,u66,9,group 1,post test,4,6,1,No,No,Is the accuracy of 95% enough for voice recognition? <please input your answer>,Recognition Accuracy. We first need a system to recognize speech when creating a voice-controlled personal assistant. The accuracy of speech recognition is very demanding. 95% is not good. 99% is good. A picture of The Telephone Game to show the importance of speech recongition accuracy.
65a3774a-32c9-432a-bbee-cc8aa0cf5a86,test,past,high school,u66,9,group 1,post test,1,4,1,Speech Recognition,Speech recognition,What is the first main component of a virtual assistant? <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
1cbe7bbc-d7ac-4d18-812e-376fd21cc08d,test,future,high school,u66,9,group 1,post test,8,15,0,?,Unfolding,What should we do when we want to train an RNN? <please input your answer>,"Training an RNN. Training an RNN by using backpropagation is more complicated than training an ANN with no loops. Unfolding: The loops are removed by duplicating parts of the neural network whenever they represent different parts of the sentence. After unfolding, we can train the RNN the way we train ANNs without loops. A picture illustrating the concept of unfolding."
6fbc4839-8fc0-4416-824c-ed098d2d4f83,test,future,high school,u66,9,group 1,post test,9,16,1,Long Short-term memory,Long Short-Term Memory,What does LSTM stand for? <please input your answer>,The Long Short-Term Memory (LSTM) Model. Humans are thought to have two kinds of memory: Short-Term Memory and Long-Term Memory. E.g. 'Memorizing a phone number to make a phone call' uses your Short-Term Memory. 'Memorizing your friend's name' uses your Long-Term Memory. A picture showing repitition of short-term memory could convert to long-term memory.
42b055c6-7680-447b-b9d9-45abadb7a987,test,past,high school,u66,9,group 1,post test,2,23,1,Speech Synthesis,Speech generation,What is the last main component of a virtual assistant? <please input your answer>,Voice Synthesis. Voice Synthesis is the final stage of a voice-controlled personal assistant. Speech synthesis is accomplished using an RNN that converts a series of linguistic sounds into a series of spectrum. A picture of chat history of a human with a bot.
06f1234e-0029-4623-80e1-71e54e3ad556,test,future,high school,u66,9,group 1,post test,6,11,1,"(0,0,1,0,1)","(0,0,1,0,1)","Take five words {Cats, Dogs, bark, meow, eat} Take three sentences, “Dogs bark” “Cats eat” “Dogs eat” How to express the words after the “Dogs”? <please input your answer>","Words Representation. Method: finding out how often the word appears after which words and before which words by going through a huge data set. E.g. Words: {Cats, Dogs, Bark, Meow, Eat}. Phrases: {'Cats meow,' 'Dogs bark,' 'Cats eat,' 'Dogs eat'}. Result:'Cats' is often before 'meow' and 'eat', which can be expressed as (0,0,0,1,1). 'Cats' doesn’t often appear after any words, which can be expressed as (0,0,0,0,0). 'Cat” = (0,0,0,0,0, 0,0,0,1,1). A table illustrating this method."
304d09f7-0f72-403a-a529-8da681098417,test,past,high school,u66,9,group 1,post test,5,10,0,Words are represented by numbers,Assigning different neurons to different words,How are the words represented in an ANN? <please input your answer>,"How Should the Words be Represented in an ANN? Question: Why not type the words into a computer as a string of the alphabet for input? Assigning different neurons to different words. Then, add more information relating to each word: Represent a word with a group of words the original word is often used with. E.g. 'Cats' with 'meow' 'walk'. A picture of word cloud. A picture of a word connected to other words that it is related to."
cb8f62d0-2ded-4b00-9ca2-3de4aaf6646d,test,future,high school,u66,9,group 1,post test,10,18,1,"input, output, memory","The input, the short-term memory, and the output","Compared to regular RNN, LSTM has better control over its three components. What are they? <please input your answer>","The Long Short-Term Memory (LSTM) Model. The short-term memory in the LSTM can be kept unchanged as several inputs are processed. Short-Term Memory of LSTM: can be kept or rewritten, depending on the current short-term memory, input, and connection weights. LSTM can control how long it holds the current memory. A picture illustrating how short term memory is manipulated in LSTM."
a1d38ef3-79b4-49ee-bec2-cae8bd6a1137,test,future,high school,u66,9,group 1,post test,7,14,1,a loop,A loop,What does an RNN have that a simple three-layer neural network doesn’t have? <please input your answer>,Recurrent Neural Network. The network is called a Recurrent Neural Network (RNN) because it has a loop in the connection to feed the previous activations back to the input. This network receives one word at a time and is trained to generate an output each time using supervised learning with additional 'desired outputs'. Another usage: They can also be trained to represent phrases and sentences. A picture of RNN.
cb554ad4-26a4-41d0-9187-0e21b89b246a,test,past,high school,u76,9,group 1,post test,3,4,0,Alexa,Linguistic analysis / Database / Web content retrieval,Please cite a component of voice-controlled assistant that it needs for normal work. <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
65606e09-1d39-4517-9f01-74f0dad84c3a,test,past,high school,u76,9,group 1,post test,4,6,1,No,No,Is the accuracy of 95% enough for voice recognition? <please input your answer>,Recognition Accuracy. We first need a system to recognize speech when creating a voice-controlled personal assistant. The accuracy of speech recognition is very demanding. 95% is not good. 99% is good. A picture of The Telephone Game to show the importance of speech recongition accuracy.
79dccc81-73a3-4a2b-a250-b8fd9fee8d99,test,past,high school,u76,9,group 1,post test,1,4,0,Dont know,Speech recognition,What is the first main component of a virtual assistant? <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
50ca20dd-1772-418a-9159-d2006715ffe9,test,future,high school,u76,9,group 1,post test,8,15,1,"How do you train an RNN? Start training by creating a new session. After running the variable initializer, set the training loop according to the number of steps predefined in point C. Iterate through the training data and feed these into the model, batch by batch, to optimize the model and minimize loss.",Unfolding,What should we do when we want to train an RNN? <please input your answer>,"Training an RNN. Training an RNN by using backpropagation is more complicated than training an ANN with no loops. Unfolding: The loops are removed by duplicating parts of the neural network whenever they represent different parts of the sentence. After unfolding, we can train the RNN the way we train ANNs without loops. A picture illustrating the concept of unfolding."
5b55f2e2-3e65-45a9-b42c-00ebcafe99a0,test,future,high school,u76,9,group 1,post test,9,16,1,Long short term memory,Long Short-Term Memory,What does LSTM stand for? <please input your answer>,The Long Short-Term Memory (LSTM) Model. Humans are thought to have two kinds of memory: Short-Term Memory and Long-Term Memory. E.g. 'Memorizing a phone number to make a phone call' uses your Short-Term Memory. 'Memorizing your friend's name' uses your Long-Term Memory. A picture showing repitition of short-term memory could convert to long-term memory.
99259e46-3ad9-4ecf-ae0e-66ca580ac845,test,past,high school,u76,9,group 1,post test,2,23,0,Dont know,Speech generation,What is the last main component of a virtual assistant? <please input your answer>,Voice Synthesis. Voice Synthesis is the final stage of a voice-controlled personal assistant. Speech synthesis is accomplished using an RNN that converts a series of linguistic sounds into a series of spectrum. A picture of chat history of a human with a bot.
a737ebfa-e632-4569-8049-e886444d756a,test,future,high school,u76,9,group 1,post test,6,11,0,Dont know,"(0,0,1,0,1)","Take five words {Cats, Dogs, bark, meow, eat} Take three sentences, “Dogs bark” “Cats eat” “Dogs eat” How to express the words after the “Dogs”? <please input your answer>","Words Representation. Method: finding out how often the word appears after which words and before which words by going through a huge data set. E.g. Words: {Cats, Dogs, Bark, Meow, Eat}. Phrases: {'Cats meow,' 'Dogs bark,' 'Cats eat,' 'Dogs eat'}. Result:'Cats' is often before 'meow' and 'eat', which can be expressed as (0,0,0,1,1). 'Cats' doesn’t often appear after any words, which can be expressed as (0,0,0,0,0). 'Cat” = (0,0,0,0,0, 0,0,0,1,1). A table illustrating this method."
dc3a0750-c7dd-4e17-a3bf-3dea7e75209e,test,past,high school,u76,9,group 1,post test,5,10,1,An Artificial Neural Network consists of large number of ?euron??like processing elements. All these processing elements have a large number of weighted connections between them. The connections between the elements provide a distributed representation of data.,Assigning different neurons to different words,How are the words represented in an ANN? <please input your answer>,"How Should the Words be Represented in an ANN? Question: Why not type the words into a computer as a string of the alphabet for input? Assigning different neurons to different words. Then, add more information relating to each word: Represent a word with a group of words the original word is often used with. E.g. 'Cats' with 'meow' 'walk'. A picture of word cloud. A picture of a word connected to other words that it is related to."
d2e2d4a1-c998-4d80-b592-4cf332275f77,test,future,high school,u76,9,group 1,post test,10,18,0,Dont know,"The input, the short-term memory, and the output","Compared to regular RNN, LSTM has better control over its three components. What are they? <please input your answer>","The Long Short-Term Memory (LSTM) Model. The short-term memory in the LSTM can be kept unchanged as several inputs are processed. Short-Term Memory of LSTM: can be kept or rewritten, depending on the current short-term memory, input, and connection weights. LSTM can control how long it holds the current memory. A picture illustrating how short term memory is manipulated in LSTM."
6878b00d-ac9a-46bd-ac12-323f5890dce9,test,future,high school,u76,9,group 1,post test,7,14,0,Dont know,A loop,What does an RNN have that a simple three-layer neural network doesn’t have? <please input your answer>,Recurrent Neural Network. The network is called a Recurrent Neural Network (RNN) because it has a loop in the connection to feed the previous activations back to the input. This network receives one word at a time and is trained to generate an output each time using supervised learning with additional 'desired outputs'. Another usage: They can also be trained to represent phrases and sentences. A picture of RNN.
776a4af7-4080-4fe9-ad29-7287676c1d8b,train,past,high school,u64,9,group 2,post test,3,4,1,linguistic analysis,Linguistic analysis / Database / Web content retrieval,Please cite a component of voice-controlled assistant that it needs for normal work. <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
28f806c6-b0ea-44e5-917b-5ff881501b4d,train,past,high school,u64,9,group 2,post test,4,6,1,No,No,Is the accuracy of 95% enough for voice recognition? <please input your answer>,Recognition Accuracy. We first need a system to recognize speech when creating a voice-controlled personal assistant. The accuracy of speech recognition is very demanding. 95% is not good. 99% is good. A picture of The Telephone Game to show the importance of speech recongition accuracy.
952a5d6d-f86b-4f30-a721-82451e5cf4d2,train,past,high school,u64,9,group 2,post test,1,4,1,Voice recognition,Speech recognition,What is the first main component of a virtual assistant? <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
db953b96-797b-48ca-b209-18a21de04c33,train,future,high school,u64,9,group 2,post test,8,15,1,supervised learning; backpropagation,Unfolding,What should we do when we want to train an RNN? <please input your answer>,"Training an RNN. Training an RNN by using backpropagation is more complicated than training an ANN with no loops. Unfolding: The loops are removed by duplicating parts of the neural network whenever they represent different parts of the sentence. After unfolding, we can train the RNN the way we train ANNs without loops. A picture illustrating the concept of unfolding."
d3eb06b4-50d5-4321-9493-bcf4bce431c6,train,future,high school,u64,9,group 2,post test,9,16,1,long short term memory,Long Short-Term Memory,What does LSTM stand for? <please input your answer>,The Long Short-Term Memory (LSTM) Model. Humans are thought to have two kinds of memory: Short-Term Memory and Long-Term Memory. E.g. 'Memorizing a phone number to make a phone call' uses your Short-Term Memory. 'Memorizing your friend's name' uses your Long-Term Memory. A picture showing repitition of short-term memory could convert to long-term memory.
a7c6d373-2c87-4a0c-bc06-5d55ac618eac,train,past,high school,u64,9,group 2,post test,2,23,1,voice synthesis,Speech generation,What is the last main component of a virtual assistant? <please input your answer>,Voice Synthesis. Voice Synthesis is the final stage of a voice-controlled personal assistant. Speech synthesis is accomplished using an RNN that converts a series of linguistic sounds into a series of spectrum. A picture of chat history of a human with a bot.
f7ba867b-5627-45fe-a54c-52708ed10a50,train,future,high school,u64,9,group 2,post test,6,11,1,"0, 0, 1, 0, 1","(0,0,1,0,1)","Take five words {Cats, Dogs, bark, meow, eat} Take three sentences, “Dogs bark” “Cats eat” “Dogs eat” How to express the words after the “Dogs”? <please input your answer>","Words Representation. Method: finding out how often the word appears after which words and before which words by going through a huge data set. E.g. Words: {Cats, Dogs, Bark, Meow, Eat}. Phrases: {'Cats meow,' 'Dogs bark,' 'Cats eat,' 'Dogs eat'}. Result:'Cats' is often before 'meow' and 'eat', which can be expressed as (0,0,0,1,1). 'Cats' doesn’t often appear after any words, which can be expressed as (0,0,0,0,0). 'Cat” = (0,0,0,0,0, 0,0,0,1,1). A table illustrating this method."
093e6302-c7ee-4870-94c3-c488ab01dda7,train,past,high school,u64,9,group 2,post test,5,10,1,assigning different neurons to different words; a word is represented with a group of words that the original word is often used with,Assigning different neurons to different words,How are the words represented in an ANN? <please input your answer>,"How Should the Words be Represented in an ANN? Question: Why not type the words into a computer as a string of the alphabet for input? Assigning different neurons to different words. Then, add more information relating to each word: Represent a word with a group of words the original word is often used with. E.g. 'Cats' with 'meow' 'walk'. A picture of word cloud. A picture of a word connected to other words that it is related to."
ca992df2-4480-4594-bcf6-c598d2f593ff,train,future,high school,u64,9,group 2,post test,10,18,0,"cells, input, and output","The input, the short-term memory, and the output","Compared to regular RNN, LSTM has better control over its three components. What are they? <please input your answer>","The Long Short-Term Memory (LSTM) Model. The short-term memory in the LSTM can be kept unchanged as several inputs are processed. Short-Term Memory of LSTM: can be kept or rewritten, depending on the current short-term memory, input, and connection weights. LSTM can control how long it holds the current memory. A picture illustrating how short term memory is manipulated in LSTM."
d2d1706b-63f4-45c6-86d1-8d14c7a6d33e,train,future,high school,u64,9,group 2,post test,7,14,1,loop in connection to feed previous activations back to input,A loop,What does an RNN have that a simple three-layer neural network doesn’t have? <please input your answer>,Recurrent Neural Network. The network is called a Recurrent Neural Network (RNN) because it has a loop in the connection to feed the previous activations back to the input. This network receives one word at a time and is trained to generate an output each time using supervised learning with additional 'desired outputs'. Another usage: They can also be trained to represent phrases and sentences. A picture of RNN.
91eadb7d-8939-42a3-9549-66316ce9cb88,train,past,high school,u80,9,group 2,post test,3,4,1,Voice recognition,Linguistic analysis / Database / Web content retrieval,Please cite a component of voice-controlled assistant that it needs for normal work. <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
54622505-1f59-45a2-a826-2445fc18f021,train,past,high school,u80,9,group 2,post test,4,6,1,No,No,Is the accuracy of 95% enough for voice recognition? <please input your answer>,Recognition Accuracy. We first need a system to recognize speech when creating a voice-controlled personal assistant. The accuracy of speech recognition is very demanding. 95% is not good. 99% is good. A picture of The Telephone Game to show the importance of speech recongition accuracy.
50a47ef9-ac9b-42d3-bb8a-f0607572eb22,train,past,high school,u80,9,group 2,post test,1,4,1,Voice recognition,Speech recognition,What is the first main component of a virtual assistant? <please input your answer>,"How Do Voice-Controlled Personal Assistants Work? AI is behind those responses, tackling the very difficult tasks of understanding your speech, judging how to respond, and acting or answering using a natural-sounding voice. Voice recognition. Linguistic analysis. Conversational control. Database. Web content retrieval. A picture of a personal assistant."
0d13dbe7-419a-4bb6-bf04-f8ee37fb39d5,train,future,high school,u80,9,group 2,post test,8,15,0,"The same way you train an ANN, but without loops",Unfolding,What should we do when we want to train an RNN? <please input your answer>,"Training an RNN. Training an RNN by using backpropagation is more complicated than training an ANN with no loops. Unfolding: The loops are removed by duplicating parts of the neural network whenever they represent different parts of the sentence. After unfolding, we can train the RNN the way we train ANNs without loops. A picture illustrating the concept of unfolding."
fac41c45-c8de-45c5-b6e9-eed1c7c28514,train,future,high school,u80,9,group 2,post test,9,16,1,Long Short Term Memory,Long Short-Term Memory,What does LSTM stand for? <please input your answer>,The Long Short-Term Memory (LSTM) Model. Humans are thought to have two kinds of memory: Short-Term Memory and Long-Term Memory. E.g. 'Memorizing a phone number to make a phone call' uses your Short-Term Memory. 'Memorizing your friend's name' uses your Long-Term Memory. A picture showing repitition of short-term memory could convert to long-term memory.
39c115b9-8d2e-4c3d-83e4-fbc8c0ec62d3,train,past,high school,u80,9,group 2,post test,2,23,1,Voice synthesis,Speech generation,What is the last main component of a virtual assistant? <please input your answer>,Voice Synthesis. Voice Synthesis is the final stage of a voice-controlled personal assistant. Speech synthesis is accomplished using an RNN that converts a series of linguistic sounds into a series of spectrum. A picture of chat history of a human with a bot.
5b4084fe-faa3-4e71-a8ee-644f436b2582,train,future,high school,u80,9,group 2,post test,6,11,0,Groups of numbers,"(0,0,1,0,1)","Take five words {Cats, Dogs, bark, meow, eat} Take three sentences, “Dogs bark” “Cats eat” “Dogs eat” How to express the words after the “Dogs”? <please input your answer>","Words Representation. Method: finding out how often the word appears after which words and before which words by going through a huge data set. E.g. Words: {Cats, Dogs, Bark, Meow, Eat}. Phrases: {'Cats meow,' 'Dogs bark,' 'Cats eat,' 'Dogs eat'}. Result:'Cats' is often before 'meow' and 'eat', which can be expressed as (0,0,0,1,1). 'Cats' doesn’t often appear after any words, which can be expressed as (0,0,0,0,0). 'Cat” = (0,0,0,0,0, 0,0,0,1,1). A table illustrating this method."
c8ee05be-5fbc-4c5f-b297-5b46287cdc89,train,past,high school,u80,9,group 2,post test,5,10,0,Groups of other words used with it commonly,Assigning different neurons to different words,How are the words represented in an ANN? <please input your answer>,"How Should the Words be Represented in an ANN? Question: Why not type the words into a computer as a string of the alphabet for input? Assigning different neurons to different words. Then, add more information relating to each word: Represent a word with a group of words the original word is often used with. E.g. 'Cats' with 'meow' 'walk'. A picture of word cloud. A picture of a word connected to other words that it is related to."
4458cfae-627f-4396-bd05-4214c93dc281,train,future,high school,u80,9,group 2,post test,10,18,0,I don't remember,"The input, the short-term memory, and the output","Compared to regular RNN, LSTM has better control over its three components. What are they? <please input your answer>","The Long Short-Term Memory (LSTM) Model. The short-term memory in the LSTM can be kept unchanged as several inputs are processed. Short-Term Memory of LSTM: can be kept or rewritten, depending on the current short-term memory, input, and connection weights. LSTM can control how long it holds the current memory. A picture illustrating how short term memory is manipulated in LSTM."
cf2f9ecd-62c1-45e0-8e92-130a0b0a368c,train,future,high school,u80,9,group 2,post test,7,14,1,A loop,A loop,What does an RNN have that a simple three-layer neural network doesn’t have? <please input your answer>,Recurrent Neural Network. The network is called a Recurrent Neural Network (RNN) because it has a loop in the connection to feed the previous activations back to the input. This network receives one word at a time and is trained to generate an output each time using supervised learning with additional 'desired outputs'. Another usage: They can also be trained to represent phrases and sentences. A picture of RNN.
